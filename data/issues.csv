url,repository_url,labels_url,comments_url,events_url,html_url,id,node_id,number,title,user,labels,state,locked,assignee,assignees,milestone,comments,created_at,updated_at,closed_at,author_association,active_lock_reason,body,closed_by,reactions,timeline_url,performed_via_github_app,state_reason,draft,pull_request
https://api.github.com/repos/ultralytics/yolov5/issues/13473,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13473/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13473/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13473/events,https://github.com/ultralytics/yolov5/issues/13473,2760886144,I_kwDOD8jP_s6kj8eA,13473,Query/Issue with Custom YOLOv5 Model and ONNX Export,"{'login': 'AbhirupSinha1811', 'id': 192977993, 'node_id': 'U_kgDOC4CcSQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/192977993?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AbhirupSinha1811', 'html_url': 'https://github.com/AbhirupSinha1811', 'followers_url': 'https://api.github.com/users/AbhirupSinha1811/followers', 'following_url': 'https://api.github.com/users/AbhirupSinha1811/following{/other_user}', 'gists_url': 'https://api.github.com/users/AbhirupSinha1811/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AbhirupSinha1811/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AbhirupSinha1811/subscriptions', 'organizations_url': 'https://api.github.com/users/AbhirupSinha1811/orgs', 'repos_url': 'https://api.github.com/users/AbhirupSinha1811/repos', 'events_url': 'https://api.github.com/users/AbhirupSinha1811/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AbhirupSinha1811/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,3,2024-12-27T13:28:10Z,2024-12-30T04:24:57Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Detection, Export

### Bug

I am working with a custom-trained YOLOv5 model that was trained on a dataset with 4 classes. After exporting the model to ONNX format, I am facing discrepancies in the output tensor shape and class configurations, which are creating confusion and potential issues in downstream tasks. Below, I outline the details of my observations, potential root causes, and attempts to resolve the issue.

### Environment

yolov5s.pt, ubuntu 22.04, in own system.

### Minimal Reproducible Example

normal detection code from""https://github.com/arindal1/yolov5-onnx-object-recognition/blob/main/yolov5.py""

### Additional

Observations:

Custom Model Details:

The .pt model was trained on a dataset with 4 classes (bird, drone, helicopter, jetplane).

When inspecting the .pt model, the number of classes is confirmed as 4 both in the names field and in the nc parameter from the data.yaml.

The .pt model performs as expected, detecting all 4 classes correctly during inference.

ONNX Export Details:

After exporting the model to ONNX, the output tensor shape is reported as [1, 8, 8400].

The 8 indicates the number of output channels in the detection head, which suggests it is configured for only 3 classes (5 + 3 = 8 instead of 5 + 4 = 9).

This is inconsistent with the .pt model, which was trained on 4 classes.

When checking the ONNX model metadata, the class names (bird, drone, helicopter, jetplane) are correctly stored, indicating 4 classes in the metadata.

Comparison with Default COCO Model:

For reference, the output tensor shape of a YOLOv5 model trained on the COCO dataset (80 classes) is [1, 25200, 85].

Here, 85 = 5 + 80 (5 for bounding box attributes + 80 for classes).

This format aligns with the expected configuration for YOLO models.

Key Issues:

Mismatch in Output Tensor Shape:

The ONNX model’s output tensor shape suggests it is configured for only 3 classes ([1, 8, 8400]), despite the .pt model being trained on 4 classes.

This raises concerns about whether the ONNX model will correctly detect all 4 classes.

Potential Causes of the Issue:

The detection head in the .pt model might have been misconfigured during training or export.

For 4 classes, the detection head’s out_channels should be 5 + 4 = 9, but it appears to be set to 8.

The ONNX export process might not be correctly handling the model’s class configuration.

Implications for Object Detection:

If the ONNX model is truly configured for only 3 classes, it may fail to detect one of the classes or produce incorrect predictions.

Steps Taken to Debug:

Inspected Detection Head of .pt Model:

Verified the out_channels of the detection head (last layer).

The .pt model’s detection head is confirmed to have out_channels = 8, indicating a configuration for 3 classes.

This discrepancy persists despite the model being trained on 4 classes.

Verified ONNX Model Metadata:

Extracted metadata from the ONNX model, which correctly lists 4 class names (bird, drone, helicopter, jetplane).

Tried Re-exporting the Model:

Re-exported the .pt model to ONNX using the official YOLOv5 export script.

The issue with the output tensor shape ([1, 8, 8400]) remains.

Request for Assistance:

Clarification on Detection Head Configuration:

Could this issue arise from a misconfiguration of the detection head during training? If so, how can I fix it without retraining the model?

Is there a way to manually adjust the detection head’s out_channels in the .pt model and re-export it to ONNX?

ONNX Export Process:

Are there known issues with the YOLOv5 ONNX export script that could cause this mismatch?

How can I ensure the ONNX model’s detection head is correctly configured for 4 classes?

General Guidance:

What steps can I take to verify that the ONNX model will correctly detect all 4 classes?

Are there tools or scripts you recommend for validating the ONNX model’s outputs?

Additional Context:

ultralytics - 2.4.1
PyTorch Version: 2.4.1

ONNX Runtime Version:1.16.3

Thank you for your assistance in resolving this issue!

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13473/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13473/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13472,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13472/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13472/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13472/events,https://github.com/ultralytics/yolov5/pull/13472,2760165188,PR_kwDOD8jP_s6GRrE7,13472,Update detect.py (Fix save-csv: Ensure header is written to CSV),"{'login': 'aligh993', 'id': 48443743, 'node_id': 'MDQ6VXNlcjQ4NDQzNzQz', 'avatar_url': 'https://avatars.githubusercontent.com/u/48443743?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/aligh993', 'html_url': 'https://github.com/aligh993', 'followers_url': 'https://api.github.com/users/aligh993/followers', 'following_url': 'https://api.github.com/users/aligh993/following{/other_user}', 'gists_url': 'https://api.github.com/users/aligh993/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/aligh993/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/aligh993/subscriptions', 'organizations_url': 'https://api.github.com/users/aligh993/orgs', 'repos_url': 'https://api.github.com/users/aligh993/repos', 'events_url': 'https://api.github.com/users/aligh993/events{/privacy}', 'received_events_url': 'https://api.github.com/users/aligh993/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,3,2024-12-26T21:41:49Z,2024-12-27T14:22:12Z,,NONE,,"This commit resolves an issue where the save-csv command did not write the CSV header. The code now correctly saves the header in the CSV file.

I have read the CLA Document and I sign the CLA

<!--
Thank you 🙏 for your contribution to [Ultralytics](https://www.ultralytics.com/) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. Check for Existing Contributions: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. Link Related Issues: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. Elaborate Your Changes: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. Ultralytics Contributor License Agreement (CLA): To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    I have read the CLA Document and I sign the CLA

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing/). Your adherence to these guidelines ensures a faster and more effective review process.
--->
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13472/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13472/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13472', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13472', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13472.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13472.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13469,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13469/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13469/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13469/events,https://github.com/ultralytics/yolov5/issues/13469,2754505622,I_kwDOD8jP_s6kLmuW,13469,How to compute loss using eval mode in val. py file for YOLOv5,"{'login': 'BIT-QiuYu', 'id': 92447916, 'node_id': 'U_kgDOBYKkrA', 'avatar_url': 'https://avatars.githubusercontent.com/u/92447916?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/BIT-QiuYu', 'html_url': 'https://github.com/BIT-QiuYu', 'followers_url': 'https://api.github.com/users/BIT-QiuYu/followers', 'following_url': 'https://api.github.com/users/BIT-QiuYu/following{/other_user}', 'gists_url': 'https://api.github.com/users/BIT-QiuYu/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/BIT-QiuYu/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/BIT-QiuYu/subscriptions', 'organizations_url': 'https://api.github.com/users/BIT-QiuYu/orgs', 'repos_url': 'https://api.github.com/users/BIT-QiuYu/repos', 'events_url': 'https://api.github.com/users/BIT-QiuYu/events{/privacy}', 'received_events_url': 'https://api.github.com/users/BIT-QiuYu/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689369, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqemQ', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/research', 'name': 'research', 'color': '4425C9', 'default': False, 'description': 'Issues requiring substantial research effort'}]",open,False,,[],,2,2024-12-22T06:04:25Z,2024-12-22T19:19:42Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Due to research requirements, I need to calculate the loss function value for each input image in the `eval mode` of the YOLO V5 model
I modified the `run` function in the `val. py` file
The `compute_loss` variable was specified as `ComputeLoss (model)` in it
```python
    # Configure
    model.eval()
    compute_loss = ComputeLoss(model)
    cuda = device.type != ""cpu""
    is_coco = isinstance(data.get(""val""), str) and data[""val""].endswith(f""coco{os.sep}val2017.txt"")  # COCO dataset
    nc = 1 if single_cls else int(data[""nc""])  # number of classes
    iouv = torch.linspace(0.5, 0.95, 10, device=device)  # iou vector for mAP@0.5:0.95
    niou = iouv.numel()
```
The following error will occur：
```python
Traceback (most recent call last):
  File ""val.py"", line 626, in <module>
    main(opt)
  File ""val.py"", line 597, in main
    run(**vars(opt))
  File ""xxxxxxxxx/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py"", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""val.py"", line 299, in run
    compute_loss = ComputeLoss(model)
                   ^^^^^^^^^^^^^^^^^^
  File ""utils/loss.py"", line 115, in __init__
    h = model.hyp  # hyperparameters
        ^^^^^^^^^
  File ""xxxxxxxxxx/.local/lib/python3.12/site-packages/torch/nn/modules/module.py"", line 1931, in __getattr__
    raise AttributeError(
AttributeError: 'DetectMultiBackend' object has no attribute 'hyp'
```
When I imitate the training mode and adding the 'hyp' attribute to the YOLOv5 model using 'data/hyps/hyp.satch-low-yaml' will result in the following error：
```python
Traceback (most recent call last):
  File ""val.py"", line 626, in <module>
    main(opt)
  File ""val.py"", line 597, in main
    run(**vars(opt))
  File ""xxxxxxx/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py"", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""val.py"", line 299, in run
    compute_loss = ComputeLoss(model)
                   ^^^^^^^^^^^^^^^^^^
  File ""utils/loss.py"", line 129, in __init__
    m = de_parallel(model).model[-1]  # Detect() module
        ~~~~~~~~~~~~~~~~~~~~~~~~^^^^
TypeError: 'DetectionModel' object is not subscriptable
```
I really need the loss value.I look forward to your reply. I would be extremely grateful
If it's not possible to directly modify `val. py` to achieve the goal, use 
```python
torch.hub.load(""yolo.pt"")
```
 or 
```python
from ultralytics import YOLO
Model=YOLO (""yolo5. pt"")
```
 and other methods can achieve the goal， I also look forward to your reply. I would greatly appreciate it

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13469/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13469/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13467,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13467/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13467/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13467/events,https://github.com/ultralytics/yolov5/issues/13467,2747778718,I_kwDOD8jP_s6jx8ae,13467,Yolov5 model capturing other objects other than the intended or desired object ,"{'login': 'youssef66677', 'id': 133149142, 'node_id': 'U_kgDOB--x1g', 'avatar_url': 'https://avatars.githubusercontent.com/u/133149142?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/youssef66677', 'html_url': 'https://github.com/youssef66677', 'followers_url': 'https://api.github.com/users/youssef66677/followers', 'following_url': 'https://api.github.com/users/youssef66677/following{/other_user}', 'gists_url': 'https://api.github.com/users/youssef66677/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/youssef66677/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/youssef66677/subscriptions', 'organizations_url': 'https://api.github.com/users/youssef66677/orgs', 'repos_url': 'https://api.github.com/users/youssef66677/repos', 'events_url': 'https://api.github.com/users/youssef66677/events{/privacy}', 'received_events_url': 'https://api.github.com/users/youssef66677/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-12-18T13:10:26Z,2024-12-19T10:43:56Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have a YOLO V5 m model for a dataset to detect a certain product but after training a dataset of a variety of pictures for the product in different cases and scenarios and various lighting conditions with no repetition for the cases, on 50 epochs and the Yolo v5 medium architecture and batch size of 16. What I have noticed is that the model is dependent on the color features, meaning that the objects have colors yellow and its shades and graidents. What should I do to fix this problem? Kindly help me, also kindly find the used dataset for training below


The product desired to be detected:

![3](https://github.com/user-attachments/assets/1b3bab93-ddc7-4294-aea8-ec5047b2b870)
![IMG_4712](https://github.com/user-attachments/assets/188f56e7-8ded-4bac-8680-59279e56afde)

The other products that are detected:
![1](https://github.com/user-attachments/assets/3da26693-ccfb-4a70-859c-121bf4941d9e)
![2](https://github.com/user-attachments/assets/4943a0c9-675c-419d-94ef-b90ae659b587)

The dataset used in training (aprox 450 images) in google drive:
https://drive.google.com/file/d/1oBH28fbyhEmabLLx2bPXpEMQ0s2zhg__/view?usp=sharing


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13467/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13467/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13466,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13466/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13466/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13466/events,https://github.com/ultralytics/yolov5/issues/13466,2746995689,I_kwDOD8jP_s6ju9Pp,13466,detect  GPU data-stream,"{'login': 'LZLwoaini', 'id': 104985903, 'node_id': 'U_kgDOBkH1Lw', 'avatar_url': 'https://avatars.githubusercontent.com/u/104985903?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/LZLwoaini', 'html_url': 'https://github.com/LZLwoaini', 'followers_url': 'https://api.github.com/users/LZLwoaini/followers', 'following_url': 'https://api.github.com/users/LZLwoaini/following{/other_user}', 'gists_url': 'https://api.github.com/users/LZLwoaini/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/LZLwoaini/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/LZLwoaini/subscriptions', 'organizations_url': 'https://api.github.com/users/LZLwoaini/orgs', 'repos_url': 'https://api.github.com/users/LZLwoaini/repos', 'events_url': 'https://api.github.com/users/LZLwoaini/events{/privacy}', 'received_events_url': 'https://api.github.com/users/LZLwoaini/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,10,2024-12-18T07:18:38Z,2024-12-30T03:30:30Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

How to check the data-stream during GPU environment inference, such as which data is parallel and which data is serial. In other words, which part of the data is accelerated by GPU. Thanks！！

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13466/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13466/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13465,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13465/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13465/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13465/events,https://github.com/ultralytics/yolov5/issues/13465,2745721846,I_kwDOD8jP_s6jqGP2,13465,Inconsistent TFLite Model Results Between detect.py and Custom Inference Code,"{'login': 'yAlqubati', 'id': 131190230, 'node_id': 'U_kgDOB9HN1g', 'avatar_url': 'https://avatars.githubusercontent.com/u/131190230?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/yAlqubati', 'html_url': 'https://github.com/yAlqubati', 'followers_url': 'https://api.github.com/users/yAlqubati/followers', 'following_url': 'https://api.github.com/users/yAlqubati/following{/other_user}', 'gists_url': 'https://api.github.com/users/yAlqubati/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/yAlqubati/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/yAlqubati/subscriptions', 'organizations_url': 'https://api.github.com/users/yAlqubati/orgs', 'repos_url': 'https://api.github.com/users/yAlqubati/repos', 'events_url': 'https://api.github.com/users/yAlqubati/events{/privacy}', 'received_events_url': 'https://api.github.com/users/yAlqubati/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,4,2024-12-17T18:32:43Z,2024-12-18T16:09:30Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Description:

Hi,
I've converted a YOLOV5s model to a Tflite model using the export.py script provided in YOLOv5. The output came with the name `(best-fp16.tflite).` It works well when used with the official `detect.py` script. The predictions are accurate, with good bounding box alignment and confidence scores.

However, when I perform inference using my custom Python code, the results are noticeably worse:
- Bounding boxes are misaligned.
- Confidence scores are significantly lower.

here is the detect.py output
![test](https://github.com/user-attachments/assets/463e0bca-837b-46f9-a297-3c50e4ce28d8)

here is the custom code output:
![detection_original](https://github.com/user-attachments/assets/940c72ee-c841-4102-a837-5196b4e54e6c)

know the labels in the output are incorrect (e.g., ""person"") because I forgot to update coco.yaml, but the main issue lies in the quality of the detections.

**the input shape is [1, 640, 640, 3]
the output shape is [1, 25200, 7]**


here is my custom code for detection:

```
`
import cv2
import numpy as np
import tensorflow as tf

# Load TFLite model
interpreter = tf.lite.Interpreter(model_path=""best-fp16.tflite"")
interpreter.allocate_tensors()

# Get input and output details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Function to preprocess the image
def preprocess_image(image_path, input_size=(640, 640)):
    # Load the image
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(""Image not found or could not be loaded"")
    
    # Convert image to RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # Resize image to the model input size (640x640)
    image_resized = cv2.resize(image, input_size)
    
    # Normalize pixel values to [0, 1]
    image_resized = image_resized / 255.0

    # Add batch dimension (shape becomes [1, 640, 640, 3])
    input_image = np.expand_dims(image_resized, axis=0).astype(np.float32)
    
    return input_image, image  # Return processed image and original image

# Function to decode raw YOLOv5 output
def decode_output(output_data, input_size, confidence_threshold=0.2, iou_threshold=0.4):
    boxes = output_data[..., :4]  # Extract bounding box data
    confidence = output_data[..., 4]  # Extract confidence scores
    class_probs = output_data[..., 5:]  # Extract class probabilities

    # Compute final confidence scores
    scores = confidence[..., np.newaxis] * class_probs

    # Filter predictions based on confidence threshold
    valid_detections = np.where(scores.max(axis=-1) > confidence_threshold)
    boxes = boxes[valid_detections]
    scores = scores[valid_detections]
    class_ids = np.argmax(scores, axis=-1)
    
    # Scale boxes to input size (assumes input_size is square)
    input_h, input_w = input_size
    boxes[:, 0] *= input_w  # Scale x_center
    boxes[:, 1] *= input_h  # Scale y_center
    boxes[:, 2] *= input_w  # Scale width
    boxes[:, 3] *= input_h  # Scale height
    
    # Convert boxes from (x_center, y_center, width, height) to (xmin, ymin, xmax, ymax)
    boxes[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # xmin
    boxes[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # ymin
    boxes[:, 2] = boxes[:, 0] + boxes[:, 2]      # xmax
    boxes[:, 3] = boxes[:, 1] + boxes[:, 3]      # ymax

    # Perform Non-Maximum Suppression (NMS)
    nms_indices = tf.image.non_max_suppression(
        boxes,
        scores.max(axis=-1),
        max_output_size=50,  # Max number of detections
        iou_threshold=iou_threshold,
        score_threshold=confidence_threshold
    ).numpy()

    # Return final filtered boxes, scores, and class IDs
    return boxes[nms_indices], scores[nms_indices].max(axis=-1), class_ids[nms_indices]

# Function to draw bounding boxes on an image
def draw_boxes(image, boxes, scores, class_ids, input_size, rescale=False):
    image_draw = image.copy()
    if rescale:
        # Rescale boxes to input size
        original_h, original_w = image.shape[:2]
        boxes[:, [0, 2]] *= (original_w / input_size[0])  # Scale X coordinates
        boxes[:, [1, 3]] *= (original_h / input_size[1])  # Scale Y coordinates

    # Draw bounding boxes
    for box, score, class_id in zip(boxes, scores, class_ids):
        if score > 0.2:  # Debug: Lower threshold for easier testing
            xmin, ymin, xmax, ymax = box.astype(int)
            label = f""Class {int(class_id)}: {score:.2f}""
            
            # Draw bounding box
            cv2.rectangle(image_draw, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
            
            # Draw label
            cv2.putText(image_draw, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    return image_draw

## Function to run inference and draw bounding boxes
def predict_and_draw_boxes(image_path, interpreter, input_size=(640, 640)):
    # Preprocess the image
    input_image, original_image = preprocess_image(image_path, input_size)
    print(""Input image shape:"", input_image.shape)  # Debugging info
    print(""Original image shape:"", original_image.shape)  # Debugging info

    # Set input tensor
    interpreter.set_tensor(input_details[0]['index'], input_image)
    
    # Run inference
    interpreter.invoke()
    
    # Get output tensor
    output_data = interpreter.get_tensor(output_details[0]['index'])
    print(""Output data shape:"", output_data.shape)  # Debugging info
    
    # Decode output
    boxes, scores, class_ids = decode_output(output_data[0], input_size, confidence_threshold=0.2)

    # Draw bounding boxes on the original image
    original_boxes_image = draw_boxes(original_image, boxes, scores, class_ids, input_size, rescale=True)
    
    # Save the image with the bounding boxes
    original_output_path = ""detection_original.jpg""
    cv2.imwrite(original_output_path, original_boxes_image)
    
    print(f""Image with detections saved as {original_output_path}"")

# Run prediction and draw bounding boxes
predict_and_draw_boxes(""test2.jpg"", interpreter)
`
```

how can I get the same result as the detect.py, do I need to include any preprocessing for the image or postprocessing for the output?

I want to have the same result as the detect.py so that I can convert it to flutter and make detections from phones 

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13465/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13465/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13463,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13463/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13463/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13463/events,https://github.com/ultralytics/yolov5/issues/13463,2744429892,I_kwDOD8jP_s6jlK1E,13463,onnxruntime inference,"{'login': 'ZCzzzzzz', 'id': 115411382, 'node_id': 'U_kgDOBuEJtg', 'avatar_url': 'https://avatars.githubusercontent.com/u/115411382?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ZCzzzzzz', 'html_url': 'https://github.com/ZCzzzzzz', 'followers_url': 'https://api.github.com/users/ZCzzzzzz/followers', 'following_url': 'https://api.github.com/users/ZCzzzzzz/following{/other_user}', 'gists_url': 'https://api.github.com/users/ZCzzzzzz/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ZCzzzzzz/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ZCzzzzzz/subscriptions', 'organizations_url': 'https://api.github.com/users/ZCzzzzzz/orgs', 'repos_url': 'https://api.github.com/users/ZCzzzzzz/repos', 'events_url': 'https://api.github.com/users/ZCzzzzzz/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ZCzzzzzz/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,2,2024-12-17T09:44:42Z,2024-12-17T15:06:48Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I've converted yolov5s.pt to yolov5s.onnx,Now I want to use onnxruntime for inference,but all the final result is 0,like this:
""Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000""


### Additional

the python code is :
import os
import cv2
import numpy as np
import onnxruntime as ort
from pathlib import Path
from tqdm import tqdm
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
from utils.general import coco80_to_coco91_class
import json

DATASET_PATH = '/COCO2017'  
MODEL_PATH = './yolov5s.onnx'  
IMG_SIZE = 640  
CONF_THRESH = 0.1  
IOU_THRESH = 0.6  


data_paths = {
    ""train_images"": os.path.join(DATASET_PATH, ""train2017.txt""),
    ""val_images"": os.path.join(DATASET_PATH, ""val2017.txt""),
    ""annotations_train"": os.path.join(DATASET_PATH, ""annotations"", ""instances_train2017.json""),
    ""annotations_val"": os.path.join(DATASET_PATH, ""annotations"", ""instances_val2017.json""),
}


def xywh2xyxy(x):
    y = np.copy(x)
    y[..., 0] = x[..., 0] - x[..., 2] / 2
    y[..., 1] = x[..., 1] - x[..., 3] / 2
    y[..., 2] = x[..., 0] + x[..., 2] / 2
    y[..., 3] = x[..., 1] + x[..., 3] / 2
    return y

def xyxy2xywh(x):
    y = np.copy(x)
    y[..., 0] = (x[..., 0] + x[..., 2]) / 2
    y[..., 1] = (x[..., 1] + x[..., 3]) / 2
    y[..., 2] = x[..., 2] - x[..., 0]
    y[..., 3] = x[..., 3] - x[..., 1]
    return y


def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, max_det=300):
    xc = prediction[..., 4] > conf_thres
    output = [np.zeros((0, 6))] * prediction.shape[0]
    for xi, x in enumerate(prediction):
        x = x[xc[xi]]
        if not x.shape[0]:
            continue
        x[:, 5:] *= x[:, 4:5]
        box = xywh2xyxy(x[:, :4])
        conf = x[:, 4]
        j = np.argmax(x[:, 5:], axis=1)
        x = np.concatenate((box, conf[:, None], j[:, None]), axis=1)[conf > conf_thres]

        if not x.shape[0]:
            continue
        c = x[:, 5:6] * 4096
        boxes, scores = x[:, :4] + c, x[:, 4]
        i = cv2.dnn.NMSBoxes(boxes.tolist(), scores.tolist(), conf_thres, iou_thres)
        output[xi] = x[i].reshape(-1, 6)[:max_det]
    return output


def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)
    img = img.transpose(2, 0, 1).astype(np.float32)
    img /= 255.0
    return np.expand_dims(img, axis=0)


def infer_with_onnxruntime(session, img_tensor):
    input_name = session.get_inputs()[0].name
    outputs = session.run(None, {input_name: img_tensor})
    return outputs[0]


def save_coco_results(predictions, image_ids, coco, output_file):
    results = []
#    class_map = {i: cat_id for i, cat_id in enumerate(sorted(coco.getCatIds()))}  
    class_map = coco80_to_coco91_class()  
#    print(""Class map:"", class_map)  
    
    for preds, img_id in zip(predictions, image_ids):
        for pred in preds[0]:
#            print(""Shape of pred:"", pred.shape)
            box = pred[:4]
            conf = pred[4]
#            print(""Value of pred[5]:"", pred[5])
            cls = int(pred[5])
            if cls >= len(class_map):
                print(f""Skipping invalid class index: {cls}"")
                continue
#            category_id = class_map.get(cls, None)
            category_id = class_map[cls]
#            if category_id is None:
#                print(f""Unknown class ID: {cls}, skipping..."")
#                continue
            print(f""Image ID: {img_id}, Category ID: {category_id}, Box: {box}, Score: {conf}"")
            print(f""Predicted COCO80 cls: {cls}, Mapped COCO91 category_id: {category_id}"")
            box = xyxy2xywh(np.array(box).reshape(1, 4))[0]
            box = [max(0, round(x, 3)) for x in box]
            results.append({
                ""image_id"": int(img_id),
                ""category_id"": category_id,
                ""bbox"": box,
                ""score"": round(conf, 5)
            })
    with open(output_file, 'w') as f:
        json.dump(results, f)


def run_inference(images_file, annotations_file, session, dataset_name):
    coco = COCO(annotations_file)
    with open(images_file) as f:
        image_paths = [line.strip() for line in f.readlines()]
    predictions, image_ids = [], []


    for img_path in tqdm(image_paths, desc=f""inference: {dataset_name}""):
        img_tensor = preprocess_image(os.path.join(DATASET_PATH, img_path))
        preds = infer_with_onnxruntime(session, img_tensor)
        preds = non_max_suppression(preds, conf_thres=CONF_THRESH, iou_thres=IOU_THRESH)

        predictions.append(preds)
        image_ids.append(Path(img_path).stem)

    output_file = f""coco_predictions_{dataset_name}.json""
    save_coco_results(predictions, image_ids, coco, output_file)
    coco_dt = coco.loadRes(output_file)
    coco_eval = COCOeval(coco, coco_dt, iouType=""bbox"")
    coco_eval.evaluate()
    coco_eval.accumulate()
    coco_eval.summarize()

def main():
    session = ort.InferenceSession(MODEL_PATH, providers=[""CUDAExecutionProvider""])


#    run_inference(data_paths[""train_images""], data_paths[""annotations_train""], session, ""train2017"")
    run_inference(data_paths[""val_images""], data_paths[""annotations_val""], session, ""val2017"")

if __name__ == ""__main__"":
    main()",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13463/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13463/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13462,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13462/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13462/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13462/events,https://github.com/ultralytics/yolov5/issues/13462,2742946359,I_kwDOD8jP_s6jfgo3,13462,UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 233: illegal multibyte sequence,"{'login': 'zhangsiying2001', 'id': 77012495, 'node_id': 'MDQ6VXNlcjc3MDEyNDk1', 'avatar_url': 'https://avatars.githubusercontent.com/u/77012495?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/zhangsiying2001', 'html_url': 'https://github.com/zhangsiying2001', 'followers_url': 'https://api.github.com/users/zhangsiying2001/followers', 'following_url': 'https://api.github.com/users/zhangsiying2001/following{/other_user}', 'gists_url': 'https://api.github.com/users/zhangsiying2001/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/zhangsiying2001/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/zhangsiying2001/subscriptions', 'organizations_url': 'https://api.github.com/users/zhangsiying2001/orgs', 'repos_url': 'https://api.github.com/users/zhangsiying2001/repos', 'events_url': 'https://api.github.com/users/zhangsiying2001/events{/privacy}', 'received_events_url': 'https://api.github.com/users/zhangsiying2001/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 7663689142, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdtg', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/devops', 'name': 'devops', 'color': 'FF64DA', 'default': False, 'description': 'GitHub Devops or MLops'}]",open,False,,[],,2,2024-12-16T17:13:08Z,2024-12-17T06:52:36Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

D:\0_yyyzt\AIM\yolo\yolov5> python train.py --weights yolov5s.pt --epochs 300 --batch-size 16 --workers 8 --data   D:\0_yyyzt\AIM\yolo\datasets\zhengtu\zhengtu.yaml
train: weights=yolov5s.pt, cfg=, data=D:\0_yyyzt\AIM\yolo\datasets\zhengtu\zhengtu.yaml, hyp=data\hyps\hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github: up to date with https://github.com/ultralytics/yolov5
YOLOv5  v7.0-389-ge62a31b6 Python-3.11.9 torch-2.5.1+cpu CPU

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
TensorBoard: Start with 'tensorboard --logdir runs\train', view at http://localhost:6006/
COMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.
COMET INFO: Using 'D:\\0_yyyzt\\AIM\\yolo\\yolov5\\.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.
Traceback (most recent call last):
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 986, in <module>
    main(opt)
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 688, in main
    train(opt.hyp, opt, device, callbacks)
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 180, in train
    loggers = Loggers(
              ^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\__init__.py"", line 153, in __init__
    self.comet_logger = CometLogger(self.opt, self.hyp)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\comet\__init__.py"", line 102, in __init__
    self.data_dict = self.check_dataset(self.opt.data)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\comet\__init__.py"", line 252, in check_dataset
    data_config = yaml.safe_load(f)
                  ^^^^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\__init__.py"", line 125, in safe_load
    return load(stream, SafeLoader)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\__init__.py"", line 79, in load
    loader = Loader(stream)
             ^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\loader.py"", line 34, in __init__
    Reader.__init__(self, stream)
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 85, in __init__
    self.determine_encoding()
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 124, in determine_encoding
    self.update_raw()
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 178, in update_raw
    data = self.stream.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^
UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 233: illegal multibyte sequence
COMET INFO: The process of logging environment details (conda environment, git patch) is underway. Please be patient as this may take some time.
COMET INFO: ---------------------------------------------------------------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ---------------------------------------------------------------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     name                  : exp
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Others:
COMET INFO:     Name               : exp
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details : 1
COMET INFO:     git metadata        : 1
COMET INFO:     installed packages  : 1
COMET INFO:
COMET INFO: Still saving offline stats to messages file before program termination (may take up to 120 seconds)
COMET INFO: Begin archiving the offline data.
COMET INFO: To upload this offline experiment, run:
    comet upload D:\0_yyyzt\AIM\yolo\yolov5\.cometml-runs\e9b6f27f962c4a25bfeb02399ccf699f.zip

### Environment

OS=win py=3.11.9  use=cpu NoUse NVIDIA

### Minimal Reproducible Example

D:\0_yyyzt\AIM\yolo\yolov5> python train.py --weights yolov5s.pt --epochs 300 --batch-size 16 --workers 8 --data   D:\0_yyyzt\AIM\yolo\datasets\zhengtu\zhengtu.yaml
train: weights=yolov5s.pt, cfg=, data=D:\0_yyyzt\AIM\yolo\datasets\zhengtu\zhengtu.yaml, hyp=data\hyps\hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github: up to date with https://github.com/ultralytics/yolov5
YOLOv5  v7.0-389-ge62a31b6 Python-3.11.9 torch-2.5.1+cpu CPU

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
TensorBoard: Start with 'tensorboard --logdir runs\train', view at http://localhost:6006/
COMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.
COMET INFO: Using 'D:\\0_yyyzt\\AIM\\yolo\\yolov5\\.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.
Traceback (most recent call last):
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 986, in <module>
    main(opt)
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 688, in main
    train(opt.hyp, opt, device, callbacks)
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 180, in train
    loggers = Loggers(
              ^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\__init__.py"", line 153, in __init__
    self.comet_logger = CometLogger(self.opt, self.hyp)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\comet\__init__.py"", line 102, in __init__
    self.data_dict = self.check_dataset(self.opt.data)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\comet\__init__.py"", line 252, in check_dataset
    data_config = yaml.safe_load(f)
                  ^^^^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\__init__.py"", line 125, in safe_load
    return load(stream, SafeLoader)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\__init__.py"", line 79, in load
    loader = Loader(stream)
             ^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\loader.py"", line 34, in __init__
    Reader.__init__(self, stream)
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 85, in __init__
    self.determine_encoding()
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 124, in determine_encoding
    self.update_raw()
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 178, in update_raw
    data = self.stream.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^
UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 233: illegal multibyte sequence
COMET INFO: The process of logging environment details (conda environment, git patch) is underway. Please be patient as this may take some time.
COMET INFO: ---------------------------------------------------------------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ---------------------------------------------------------------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     name                  : exp
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Others:
COMET INFO:     Name               : exp
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details : 1
COMET INFO:     git metadata        : 1
COMET INFO:     installed packages  : 1
COMET INFO:
COMET INFO: Still saving offline stats to messages file before program termination (may take up to 120 seconds)
COMET INFO: Begin archiving the offline data.
COMET INFO: To upload this offline experiment, run:
    comet upload D:\0_yyyzt\AIM\yolo\yolov5\.cometml-runs\e9b6f27f962c4a25bfeb02399ccf699f.zip

### Additional

D:\0_yyyzt\AIM\yolo\yolov5> python train.py --weights yolov5s.pt --epochs 300 --batch-size 16 --workers 8 --data   D:\0_yyyzt\AIM\yolo\datasets\zhengtu\zhengtu.yaml
train: weights=yolov5s.pt, cfg=, data=D:\0_yyyzt\AIM\yolo\datasets\zhengtu\zhengtu.yaml, hyp=data\hyps\hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github: up to date with https://github.com/ultralytics/yolov5
YOLOv5  v7.0-389-ge62a31b6 Python-3.11.9 torch-2.5.1+cpu CPU

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
TensorBoard: Start with 'tensorboard --logdir runs\train', view at http://localhost:6006/
COMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.
COMET INFO: Using 'D:\\0_yyyzt\\AIM\\yolo\\yolov5\\.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.
Traceback (most recent call last):
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 986, in <module>
    main(opt)
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 688, in main
    train(opt.hyp, opt, device, callbacks)
  File ""D:\0_yyyzt\AIM\yolo\yolov5\train.py"", line 180, in train
    loggers = Loggers(
              ^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\__init__.py"", line 153, in __init__
    self.comet_logger = CometLogger(self.opt, self.hyp)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\comet\__init__.py"", line 102, in __init__
    self.data_dict = self.check_dataset(self.opt.data)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\0_yyyzt\AIM\yolo\yolov5\utils\loggers\comet\__init__.py"", line 252, in check_dataset
    data_config = yaml.safe_load(f)
                  ^^^^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\__init__.py"", line 125, in safe_load
    return load(stream, SafeLoader)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\__init__.py"", line 79, in load
    loader = Loader(stream)
             ^^^^^^^^^^^^^^
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\loader.py"", line 34, in __init__
    Reader.__init__(self, stream)
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 85, in __init__
    self.determine_encoding()
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 124, in determine_encoding
    self.update_raw()
  File ""C:\Users\1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\yaml\reader.py"", line 178, in update_raw
    data = self.stream.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^
UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 233: illegal multibyte sequence
COMET INFO: The process of logging environment details (conda environment, git patch) is underway. Please be patient as this may take some time.
COMET INFO: ---------------------------------------------------------------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ---------------------------------------------------------------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     name                  : exp
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Others:
COMET INFO:     Name               : exp
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details : 1
COMET INFO:     git metadata        : 1
COMET INFO:     installed packages  : 1
COMET INFO:
COMET INFO: Still saving offline stats to messages file before program termination (may take up to 120 seconds)
COMET INFO: Begin archiving the offline data.
COMET INFO: To upload this offline experiment, run:
    comet upload D:\0_yyyzt\AIM\yolo\yolov5\.cometml-runs\e9b6f27f962c4a25bfeb02399ccf699f.zip

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13462/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13462/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13461,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13461/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13461/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13461/events,https://github.com/ultralytics/yolov5/issues/13461,2739717020,I_kwDOD8jP_s6jTMOc,13461,val_loss nan,"{'login': 'lqh964165950', 'id': 149365350, 'node_id': 'U_kgDOCOciZg', 'avatar_url': 'https://avatars.githubusercontent.com/u/149365350?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/lqh964165950', 'html_url': 'https://github.com/lqh964165950', 'followers_url': 'https://api.github.com/users/lqh964165950/followers', 'following_url': 'https://api.github.com/users/lqh964165950/following{/other_user}', 'gists_url': 'https://api.github.com/users/lqh964165950/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/lqh964165950/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/lqh964165950/subscriptions', 'organizations_url': 'https://api.github.com/users/lqh964165950/orgs', 'repos_url': 'https://api.github.com/users/lqh964165950/repos', 'events_url': 'https://api.github.com/users/lqh964165950/events{/privacy}', 'received_events_url': 'https://api.github.com/users/lqh964165950/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-12-14T09:04:58Z,2024-12-14T20:25:57Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

对yolov5进行改进，在head和neck之间加了一个特征增强模块，却出现如下问题，验证损失有一段时间为nan，这是为什么呢？
![val_nan](https://github.com/user-attachments/assets/106fa6c5-3ef0-4411-b634-d269b9514104)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13461/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13461/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13460,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13460/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13460/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13460/events,https://github.com/ultralytics/yolov5/issues/13460,2737707697,I_kwDOD8jP_s6jLhqx,13460,Windows Path Error ,"{'login': 'Rahulx911', 'id': 89407171, 'node_id': 'MDQ6VXNlcjg5NDA3MTcx', 'avatar_url': 'https://avatars.githubusercontent.com/u/89407171?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Rahulx911', 'html_url': 'https://github.com/Rahulx911', 'followers_url': 'https://api.github.com/users/Rahulx911/followers', 'following_url': 'https://api.github.com/users/Rahulx911/following{/other_user}', 'gists_url': 'https://api.github.com/users/Rahulx911/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Rahulx911/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Rahulx911/subscriptions', 'organizations_url': 'https://api.github.com/users/Rahulx911/orgs', 'repos_url': 'https://api.github.com/users/Rahulx911/repos', 'events_url': 'https://api.github.com/users/Rahulx911/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Rahulx911/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2597366614, 'node_id': 'MDU6TGFiZWwyNTk3MzY2NjE0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/dependencies', 'name': 'dependencies', 'color': 'C7E824', 'default': False, 'description': 'Dependencies and packages'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-12-13T07:55:15Z,2024-12-13T07:59:32Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

import platform
import pathlib

if platform.system() != 'Windows':
    pathlib.WindowsPath = pathlib.PosixPath

import subprocess
import os
import cv2
import matplotlib.pyplot as plt
import time
from paddleocr import PaddleOCR
import re
from flask import Blueprint, request, jsonify
from werkzeug.utils import secure_filename
from models.database import Box,PackedItem
from app import db
from datetime import datetime
from dotenv import load_dotenv
from pathlib import Path
load_dotenv()
# YOLO_WEIGHTS_PATH = r""C:\Users\tanya\OneDrive\Pictures\web_app\backend\models\best.pt""
# DETECT=r""C:\Users\tanya\OneDrive\Pictures\web_app\backend\yolov5\detect.py""
# DETECT_RUNS=r""C:\Users\tanya\OneDrive\Pictures\web_app\backend\yolov5\runs\detect""

YOLO_WEIGHTS_PATH = ""/root/backend/models/best.pt""
DETECT = ""/root/backend/yolov5/detect.py""
DETECT_RUNS = ""/root/backend/yolov5/runs/detect""

ocr = PaddleOCR(use_angle_cls=True, lang='en', det_db_thresh=0.3, det_db_box_thresh=0.5)

detected_texts = []


# Create Blueprint
detect_front_side_blueprint = Blueprint('detect_front_side', __name__)

def run_yolo_inference(image_path):
""detect_front_side.py"" [dos] 249L, 8997B                                                                                                                 6,0-1         Top

here i want to use poxix path but internal files of yolov5 are runt able to take this

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13460/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13460/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13459,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13459/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13459/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13459/events,https://github.com/ultralytics/yolov5/issues/13459,2737539742,I_kwDOD8jP_s6jK4qe,13459,为什么mac会抛出这个问题,"{'login': 'sj746', 'id': 190457164, 'node_id': 'U_kgDOC1olTA', 'avatar_url': 'https://avatars.githubusercontent.com/u/190457164?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/sj746', 'html_url': 'https://github.com/sj746', 'followers_url': 'https://api.github.com/users/sj746/followers', 'following_url': 'https://api.github.com/users/sj746/following{/other_user}', 'gists_url': 'https://api.github.com/users/sj746/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/sj746/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/sj746/subscriptions', 'organizations_url': 'https://api.github.com/users/sj746/orgs', 'repos_url': 'https://api.github.com/users/sj746/repos', 'events_url': 'https://api.github.com/users/sj746/events{/privacy}', 'received_events_url': 'https://api.github.com/users/sj746/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,8,2024-12-13T06:32:50Z,2024-12-18T04:41:01Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

![上传截屏2024-12-13 14.30.25.png...]()ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)


### Additional

ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13459/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13459/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13458,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13458/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13458/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13458/events,https://github.com/ultralytics/yolov5/issues/13458,2735817654,I_kwDOD8jP_s6jEUO2,13458,detecting objects with (almost) same centercoordinates,"{'login': 'dk-teknologisk-bgd', 'id': 173664301, 'node_id': 'U_kgDOClnoLQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/173664301?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/dk-teknologisk-bgd', 'html_url': 'https://github.com/dk-teknologisk-bgd', 'followers_url': 'https://api.github.com/users/dk-teknologisk-bgd/followers', 'following_url': 'https://api.github.com/users/dk-teknologisk-bgd/following{/other_user}', 'gists_url': 'https://api.github.com/users/dk-teknologisk-bgd/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/dk-teknologisk-bgd/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/dk-teknologisk-bgd/subscriptions', 'organizations_url': 'https://api.github.com/users/dk-teknologisk-bgd/orgs', 'repos_url': 'https://api.github.com/users/dk-teknologisk-bgd/repos', 'events_url': 'https://api.github.com/users/dk-teknologisk-bgd/events{/privacy}', 'received_events_url': 'https://api.github.com/users/dk-teknologisk-bgd/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,1,2024-12-12T12:51:46Z,2024-12-12T12:52:49Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I am wondering, how the yolov8 (or 11) would handle detecting e.g. two objects (of different class) with the same center-coordinates? 
I remember when I back in the days implemented part of the yolo3 training loop in Keras, that each output ""pixel"" would be encoded to only detect a single object. The output grid was always 1/32 the size of the input, and hence this could occur from time to time, but rarely.
Today I am considering using the yolov8 for a new project, in which two objects would often have roughly the same center. More often if the output grid is still 1/32 of the input res, then for a 640x640 network, any two objects within 20x20pixels would end up in the same output grid cell.

Does anyone know, if this is still an issue today for yolov8 / 11, or only for the ""old"" yolov3?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13458/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13458/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13457,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13457/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13457/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13457/events,https://github.com/ultralytics/yolov5/issues/13457,2735630731,I_kwDOD8jP_s6jDmmL,13457,Example images always inferred when running detect.py - how can I stop this? ,"{'login': 'essair', 'id': 72929112, 'node_id': 'MDQ6VXNlcjcyOTI5MTEy', 'avatar_url': 'https://avatars.githubusercontent.com/u/72929112?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/essair', 'html_url': 'https://github.com/essair', 'followers_url': 'https://api.github.com/users/essair/followers', 'following_url': 'https://api.github.com/users/essair/following{/other_user}', 'gists_url': 'https://api.github.com/users/essair/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/essair/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/essair/subscriptions', 'organizations_url': 'https://api.github.com/users/essair/orgs', 'repos_url': 'https://api.github.com/users/essair/repos', 'events_url': 'https://api.github.com/users/essair/events{/privacy}', 'received_events_url': 'https://api.github.com/users/essair/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,1,2024-12-12T11:27:56Z,2024-12-12T11:28:51Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Detection

### Bug

This is the output I get when running detect.py - each single time it runs the example images with the default model and then infers on my images with my model!


detect: weights=../../yolov5/yolov5s.pt, source=../../yolov5/data/images, data=../../yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.10 torch-2.4.1+cu121 CPU

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs
image 1/2 /home/name/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 37.6ms
image 2/2 /home/name/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 32.2ms
Speed: 0.2ms pre-process, 34.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)
Results saved to ../../yolov5/runs/detect/exp418
YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.10 torch-2.4.1+cu121 CPU

Fusing layers... 
Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs
image 1/2 /dev/shm/2024-12-09/0299/3f2a3b04-70d0-4c88-a17d-9dec8fbfe9fb_00000000f6acf5d2_Z2EnnHkxxRg_day_2024-12-09T120039.jpg: 384x640 (no detections), 34.0ms
image 2/2 /dev/shm/2024-12-09/0299/9425430e-21f5-435c-a613-1dc4d0d60585_00000000f6acf5d2_G1yv3N-8gWM_night_2024-12-09T000035.jpg: 384x640 (no detections), 30.6ms

### Environment

YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.10 torch-2.4.1+cu121 CPU
OS: Pop OS 20.04

### Minimal Reproducible Example

I'm running detect.py as part of a pipeline processing many images. The pipeline is in R, here is where I call detect.py:

reticulate::use_virtualenv(virtualenv = file.path(user_path, ""yolov5/venv""), required=TRUE)

reticulate::source_python(file.path(user_path, ""yolov5/detect.py""))
run(source = image_folder, weights = model,
    save_csv = TRUE, save_conf = TRUE, save_crop = TRUE, save_txt = TRUE,
    exist_ok = FALSE, name= results_temp_folder, nosave = nosave_settings)


Every single time I run this line for each batch of images - thats several thousand times! - it first runs the detection on the example images, saving the results to the nth run in the yolov5 folder and then it runs on my images. Its costing me time and space on my computer! And I would be very grateful if someone can help me to prevent it from running!

### Additional

I've tried running my script on another computer with a more up to date OS: Ubuntu 24 and Python 3.12 the exact same things happens! 

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13457/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13457/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13456,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13456/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13456/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13456/events,https://github.com/ultralytics/yolov5/issues/13456,2735033888,I_kwDOD8jP_s6jBU4g,13456,Add LSTM at the beginning,"{'login': 'RayDu111', 'id': 184456710, 'node_id': 'U_kgDOCv6WBg', 'avatar_url': 'https://avatars.githubusercontent.com/u/184456710?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/RayDu111', 'html_url': 'https://github.com/RayDu111', 'followers_url': 'https://api.github.com/users/RayDu111/followers', 'following_url': 'https://api.github.com/users/RayDu111/following{/other_user}', 'gists_url': 'https://api.github.com/users/RayDu111/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/RayDu111/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/RayDu111/subscriptions', 'organizations_url': 'https://api.github.com/users/RayDu111/orgs', 'repos_url': 'https://api.github.com/users/RayDu111/repos', 'events_url': 'https://api.github.com/users/RayDu111/events{/privacy}', 'received_events_url': 'https://api.github.com/users/RayDu111/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,3,2024-12-12T06:59:20Z,2024-12-13T00:59:09Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi, my data includes the time information. So I tried to add LSTM in yolo to extract  the time information. I want to concat the  image and LSTM result, then put it to the layer 0 which is 'Conv' in yolov5s.yaml. But I have no idea which layer or API presents the image. Because only layer  0 could get the image as the input which is 'Conv' in yolov5s.yaml. Could you please give me some advice? Thank you.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13456/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13456/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13454,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13454/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13454/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13454/events,https://github.com/ultralytics/yolov5/issues/13454,2729531408,I_kwDOD8jP_s6isVgQ,13454,autolabel objects,"{'login': 'BitStrawber', 'id': 170590982, 'node_id': 'U_kgDOCisDBg', 'avatar_url': 'https://avatars.githubusercontent.com/u/170590982?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/BitStrawber', 'html_url': 'https://github.com/BitStrawber', 'followers_url': 'https://api.github.com/users/BitStrawber/followers', 'following_url': 'https://api.github.com/users/BitStrawber/following{/other_user}', 'gists_url': 'https://api.github.com/users/BitStrawber/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/BitStrawber/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/BitStrawber/subscriptions', 'organizations_url': 'https://api.github.com/users/BitStrawber/orgs', 'repos_url': 'https://api.github.com/users/BitStrawber/repos', 'events_url': 'https://api.github.com/users/BitStrawber/events{/privacy}', 'received_events_url': 'https://api.github.com/users/BitStrawber/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-12-10T09:27:04Z,2024-12-10T16:32:29Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

It's a large work to label the object one by one, especially when the datatset is pretty large. Maybe there could be something ued to generate label initially

### Use case

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13454/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13454/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13453,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13453/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13453/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13453/events,https://github.com/ultralytics/yolov5/issues/13453,2725239287,I_kwDOD8jP_s6ib9n3,13453,conv2d() received an invalid combination of arguments,"{'login': 'niusme', 'id': 58981284, 'node_id': 'MDQ6VXNlcjU4OTgxMjg0', 'avatar_url': 'https://avatars.githubusercontent.com/u/58981284?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/niusme', 'html_url': 'https://github.com/niusme', 'followers_url': 'https://api.github.com/users/niusme/followers', 'following_url': 'https://api.github.com/users/niusme/following{/other_user}', 'gists_url': 'https://api.github.com/users/niusme/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/niusme/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/niusme/subscriptions', 'organizations_url': 'https://api.github.com/users/niusme/orgs', 'repos_url': 'https://api.github.com/users/niusme/repos', 'events_url': 'https://api.github.com/users/niusme/events{/privacy}', 'received_events_url': 'https://api.github.com/users/niusme/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,3,2024-12-08T13:24:11Z,2024-12-13T10:18:27Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

## environment
windows10
python3.8

## question
I used the trained model to detect. The following code throws an error
```
import pathlib

import torch
from PIL import Image
import numpy as np
from pathlib import Path

pathlib.PosixPath = pathlib.WindowsPath
model = torch.load(r'D:\py\yolo\yolov5\mymodel\testbest.pt', map_location=torch.device('cpu'))['model'].float()
model.eval()


results = model(r'D:\py\code\dnfm-yolo-tutorial\naima\28.png')  


results.print()  
results.show()   

```

the error 
```
Traceback (most recent call last):
  File ""D:/py/PyCharm 2024.1.6/plugins/python/helpers/pydev/pydevd.py"", line 1551, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""D:\py\PyCharm 2024.1.6\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""D:\py\yolo\yolov5\test.py"", line 13, in <module>
    results = model(r'D:\py\code\dnfm-yolo-tutorial\naima\28.png')  
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File ""D:\py\yolo\yolov5\models\yolo.py"", line 267, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File ""D:\py\yolo\yolov5\models\yolo.py"", line 167, in _forward_once
    x = m(x)  # run
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File ""D:\py\yolo\yolov5\models\common.py"", line 86, in forward
    return self.act(self.bn(self.conv(x)))
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\conv.py"", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""D:\py\yolo\yolov5\venv\lib\site-packages\torch\nn\modules\conv.py"", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
TypeError: conv2d() received an invalid combination of arguments - got (str, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = ""valid"", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)
```

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13453/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13453/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13452,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13452/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13452/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13452/events,https://github.com/ultralytics/yolov5/pull/13452,2724831746,PR_kwDOD8jP_s6Ea4QW,13452,[Snyk] Fix for 5 vulnerabilities,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2597366614, 'node_id': 'MDU6TGFiZWwyNTk3MzY2NjE0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/dependencies', 'name': 'dependencies', 'color': 'C7E824', 'default': False, 'description': 'Dependencies and packages'}]",open,False,,[],,1,2024-12-07T22:05:22Z,2024-12-07T22:05:58Z,,MEMBER,,"![snyk-top-banner](https://redirect.github.com/andygongea/OWASP-Benchmark/assets/818805/c518c423-16fe-447e-b67f-ad5a49b5d123)

### Snyk has created this PR to fix 5 vulnerabilities in the pip dependencies of this project.

#### Snyk changed the following file(s):

- `requirements.txt`






---

> [!IMPORTANT]
>
> - Check the changes in this PR to ensure they won't cause issues with your project.
> - Max score is 1000. Note that the real score may have changed since the PR was raised.
> - This PR was automatically created by Snyk using the credentials of a real user.
> - Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded.

---

**Note:** _You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs._

For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmMTM5YzM5YS05ZTgzLTQ5YmEtYjZhOC1iNWM0MDYxOGQyNDQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImYxMzljMzlhLTllODMtNDliYS1iNmE4LWI1YzQwNjE4ZDI0NCJ9fQ=="" width=""0"" height=""0""/>
🧐 [View latest project report](https://app.snyk.io/org/glenn-jocher/project/b49ff501-40a6-42c7-ab7e-b98a30f3409e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)
📜 [Customise PR templates](https://docs.snyk.io/scan-using-snyk/pull-requests/snyk-fix-pull-or-merge-requests/customize-pr-templates?utm_source=github&utm_content=fix-pr-template)
🛠 [Adjust project settings](https://app.snyk.io/org/glenn-jocher/project/b49ff501-40a6-42c7-ab7e-b98a30f3409e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)
📚 [Read about Snyk's upgrade logic](https://docs.snyk.io/scan-with-snyk/snyk-open-source/manage-vulnerabilities/upgrade-package-versions-to-fix-vulnerabilities?utm_source=github&utm_content=fix-pr-template)

---

**Learn how to fix vulnerabilities with free interactive lessons:**

🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)
🦉 [Improper Control of Generation of Code (&#x27;Code Injection&#x27;)](https://learn.snyk.io/lesson/malicious-code-injection/?loc&#x3D;fix-pr)
🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr)

[//]: # 'snyk:metadata:{""customTemplate"":{""variablesUsed"":[],""fieldsUsed"":[]},""dependencies"":[{""name"":""setuptools"",""from"":""40.5.0"",""to"":""70.0.0""},{""name"":""torch"",""from"":""1.13.1"",""to"":""2.2.0""},{""name"":""wheel"",""from"":""0.32.2"",""to"":""0.38.0""}],""env"":""prod"",""issuesToFix"":[""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SETUPTOOLS-7448482"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SETUPTOOLS-7448482"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SETUPTOOLS-7448482"",""SNYK-PYTHON-TORCH-6619806"",""SNYK-PYTHON-TORCH-6649934"",""SNYK-PYTHON-WHEEL-3180413"",""SNYK-PYTHON-WHEEL-3180413"",""SNYK-PYTHON-WHEEL-3180413""],""prId"":""f139c39a-9e83-49ba-b6a8-b5c40618d244"",""prPublicId"":""f139c39a-9e83-49ba-b6a8-b5c40618d244"",""packageManager"":""pip"",""priorityScoreList"":[509,696,599,629,589],""projectPublicId"":""b49ff501-40a6-42c7-ab7e-b98a30f3409e"",""projectUrl"":""https://app.snyk.io/org/glenn-jocher/project/b49ff501-40a6-42c7-ab7e-b98a30f3409e?utm_source=github&utm_medium=referral&page=fix-pr"",""prType"":""fix"",""templateFieldSources"":{""branchName"":""default"",""commitMessage"":""default"",""description"":""default"",""title"":""default""},""templateVariants"":[""priorityScore""],""type"":""auto"",""upgrade"":[],""vulns"":[""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SETUPTOOLS-7448482"",""SNYK-PYTHON-TORCH-6619806"",""SNYK-PYTHON-TORCH-6649934"",""SNYK-PYTHON-WHEEL-3180413""],""patch"":[],""isBreakingChange"":false,""remediationStrategy"":""vuln""}'


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary  
Updated dependencies to improve compatibility, security, and performance 🔄📦.  

### 📊 Key Changes  
- **Torch updated**: Minimum required version of PyTorch increased to `2.2.0` (from `1.8.0`).  
- **Wheel added**: Pinned `wheel>=0.38.0` to address a security vulnerability flagged by Snyk.  

### 🎯 Purpose & Impact  
- **Compatibility**: Updating PyTorch ensures compatibility with modern hardware and features, improving overall performance. 🚀  
- **Security**: Fixing vulnerabilities by pinning `wheel` helps ensure a safer environment for users. 🔒  
- **Efficiency**: These updates likely lead to faster training and inference for YOLOv5 models under newer hardware and optimized libraries. ⚡",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13452/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13452/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13452', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13452', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13452.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13452.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13450,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13450/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13450/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13450/events,https://github.com/ultralytics/yolov5/issues/13450,2723586195,I_kwDOD8jP_s6iVqCT,13450,Calculating a 'Detection Rate' | YOLOv5,"{'login': 'kyrangraves', 'id': 93775303, 'node_id': 'U_kgDOBZblxw', 'avatar_url': 'https://avatars.githubusercontent.com/u/93775303?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/kyrangraves', 'html_url': 'https://github.com/kyrangraves', 'followers_url': 'https://api.github.com/users/kyrangraves/followers', 'following_url': 'https://api.github.com/users/kyrangraves/following{/other_user}', 'gists_url': 'https://api.github.com/users/kyrangraves/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/kyrangraves/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/kyrangraves/subscriptions', 'organizations_url': 'https://api.github.com/users/kyrangraves/orgs', 'repos_url': 'https://api.github.com/users/kyrangraves/repos', 'events_url': 'https://api.github.com/users/kyrangraves/events{/privacy}', 'received_events_url': 'https://api.github.com/users/kyrangraves/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-12-06T17:33:19Z,2024-12-07T04:21:37Z,,NONE,,"Hi All, 

I have trained a bunch of YOLOv5 models with varying parameters to detect different coral morphologies from ROV imagery. I want to modify the val.py script to create an evaluation metric that determines the % of ground truth objects that have been correctly detected, irrespective of whether the assigned label (classification) is correct. If I'm correct, the out-the-box val.py script determines a true positive when your defined IoU threshold **and** correct classification are met. I'm essentially wanting to remove the classification element of this.

Before I try, has anybody written a bit of script like this before or know of another simpler way of calculating this metric?

All the best - Kyran

_Originally posted by @kyrangraves in https://github.com/ultralytics/yolov5/discussions/13449_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13450/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13450/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13448,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13448/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13448/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13448/events,https://github.com/ultralytics/yolov5/issues/13448,2722240939,I_kwDOD8jP_s6iQhmr,13448,Keeping track of transformations in YOLOWorld,"{'login': 'toobatehreem', 'id': 51713056, 'node_id': 'MDQ6VXNlcjUxNzEzMDU2', 'avatar_url': 'https://avatars.githubusercontent.com/u/51713056?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/toobatehreem', 'html_url': 'https://github.com/toobatehreem', 'followers_url': 'https://api.github.com/users/toobatehreem/followers', 'following_url': 'https://api.github.com/users/toobatehreem/following{/other_user}', 'gists_url': 'https://api.github.com/users/toobatehreem/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/toobatehreem/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/toobatehreem/subscriptions', 'organizations_url': 'https://api.github.com/users/toobatehreem/orgs', 'repos_url': 'https://api.github.com/users/toobatehreem/repos', 'events_url': 'https://api.github.com/users/toobatehreem/events{/privacy}', 'received_events_url': 'https://api.github.com/users/toobatehreem/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-12-06T07:13:27Z,2024-12-07T05:57:33Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I want to keep track of what and how the transformations are applied to an image. For example, after mosaic, when 4 images are stitched together, I want to know which images were stitched together, what are the pixel values for each part (like the starting and ending pixel values of each sub-image in the image so I know that this part of the mosaic sample belongs to this original image), and which bounding boxes belong to which sub-image. How can I keep track of these?

Also, in yoloworld, keeping a track of only mosaic augmentation will be enough or the bounding boxes are transformed somewhere further as well?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13448/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13448/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13445,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13445/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13445/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13445/events,https://github.com/ultralytics/yolov5/issues/13445,2721864249,I_kwDOD8jP_s6iPFo5,13445,Problem converting Yolov5n .pt to .tflite,"{'login': 'juliermeSilva', 'id': 13656615, 'node_id': 'MDQ6VXNlcjEzNjU2NjE1', 'avatar_url': 'https://avatars.githubusercontent.com/u/13656615?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/juliermeSilva', 'html_url': 'https://github.com/juliermeSilva', 'followers_url': 'https://api.github.com/users/juliermeSilva/followers', 'following_url': 'https://api.github.com/users/juliermeSilva/following{/other_user}', 'gists_url': 'https://api.github.com/users/juliermeSilva/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/juliermeSilva/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/juliermeSilva/subscriptions', 'organizations_url': 'https://api.github.com/users/juliermeSilva/orgs', 'repos_url': 'https://api.github.com/users/juliermeSilva/repos', 'events_url': 'https://api.github.com/users/juliermeSilva/events{/privacy}', 'received_events_url': 'https://api.github.com/users/juliermeSilva/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,9,2024-12-06T01:58:09Z,2024-12-16T13:57:49Z,,NONE,,"Hello everyone.
I converted a Yolov5 nano network from **_.pt_** format to **_.tflite_** format. The network only has two classes (**Black Ball** and **Silver Ball**). When using the .tflite file, the network stopped detecting Silver Ball. It only detects Black Ball. This behavior does not occur when I use the .pt format.
The code used for training is this:
```
!pip install ultralytics

from ultralytics import YOLO
model = YOLO(""yolov5n.yaml"")

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb_api"")
wandb.login(key=secret_value_0)

results = model.train(
    data='/kaggle/input/dataset/ball-black-silver-yolov5n/data.yaml', 
    epochs=100, 
    patience=30, 
    device='0,1', 
    model='yolov5n.pt', 
    lr0=0.001, 
    freeze=10,
    hsv_h=0.015,      
    hsv_s=0.7,        
    hsv_v=0.4,        
    degrees=10.0,     
    translate=0.1,    
    scale=0.5,        
    shear=2.0,        
    fliplr=0.5,       
    mosaic=1.0,       
    mixup=0.2,        
    warmup_epochs=3.0,
    cos_lr=True,
    weight_decay=0.0001
)

#Export from .pt to .onnx
model.export(format='onnx')
```

My file data.yaml:
```
train: /kaggle/input/dataset/ball-black-silver-yolov5n/train/images
val: /kaggle/input/dataset/ball-black-silver-yolov5n/valid/images
test: /kaggle/input/dataset/ball-black-silver-yolov5n/test/images

nc: 2
names: ['Black Ball', 'Silver Ball']


roboflow:
  workspace: testingai-dfp2w
  project: testing-ai-obr
  version: 2
  license: CC BY 4.0
  url: https://universe.roboflow.com/testingai-dfp2w/testing-ai-obr/dataset/2
```


The yolov5n.pt and yolov5n.onnx formats worked perfectly on a more robust computer (e.g. a university laptop).
I now need to embed the Yolov5n network on a Raspberry Pi 3B.
I then converted the network from the .pt format to the .tflite format.
The conversion code used was this:
```
!pip install ultralytics

from ultralytics import YOLO
print(""Sucess load python libs!"")

!cp /kaggle/input/models-obr/yolov5n-obr.pt /kaggle/working
pt_model_path = ""/kaggle/working/yolov5n-obr.pt""
model = YOLO(pt_model_path)
print(""Sucess load yolov5n-obr!"")

model = YOLO(pt_model_path)
print(model.names)

model.export(format=""tflite"", imgsz=640, optimize=None)

!yolo val task=detect model=/kaggle/working/yolov5n-obr_saved_model/yolov5n-obr_float32.tflite imgsz=640 data=/kaggle/input/dataset/ball-black-silver-yolov5n/data.yaml
```
Validation results:
```
Ultralytics 8.3.43 🚀 Python-3.10.14 torch-2.4.0 CPU (Intel Xeon 2.00GHz)
Loading /kaggle/working/yolov5n-obr_saved_model/yolov5n-obr_float32.tflite for TensorFlow Lite inference...
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
Setting batch=1 input of shape (1, 3, 640, 640)
Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...
100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 17.2MB/s]
val: Scanning /kaggle/input/dataset/ball-black-silver-yolov5n/valid/labels... 71
val: WARNING ⚠️ Cache directory /kaggle/input/dataset/ball-black-silver-yolov5n/valid is not writeable, cache not saved.
                 Class     Images  Instances      Box(P          R      mAP50  m
                   all        710       1891      0.997       0.98      0.993      0.871
            Black Ball        571        690      0.996      0.974      0.992      0.868
           Silver Ball        673       1201      0.998      0.986      0.994      0.875
Speed: 0.9ms preprocess, 129.1ms inference, 0.0ms loss, 0.8ms postprocess per image
Results saved to runs/detect/val
💡 Learn more at https://docs.ultralytics.com/modes/val
```

The training code and the conversion code were all run on the Kaggle platform.
Everything was going perfectly until I tried to detect silver balls.
This is my test image (**img1.jpg**):
![img1](https://github.com/user-attachments/assets/e37a4c96-3e2a-4c05-8377-5da8ad9dd887)

This is the code I am using to perform inferences using the yolov5n-obr_float32_v2.tflite network (**tflite_black_silver_test_3.py**):
```
import tflite_runtime.interpreter as tflite
import cv2
import numpy as np

id_img = 1

# Paths to the model and label map
MODEL_PATH = ""yolov5n-obr_float32_v2.tflite""
LABELMAP_PATH = ""labelmap.txt""

def calculate_iou(box1, box2):
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    # Intersection area    
    intersection = max(0, x2 - x1) * max(0, y2 - y1)     
    # Areas of the bounding boxes
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    # Union area        
    union = box1_area + box2_area - intersection     
    return intersection / union if union > 0 else 0


def nms(boxes, confidences, iou_threshold=0.5):    
    indices = np.argsort(confidences)[::-1]  # Sort by confidence (descending)
    keep = []
    while len(indices) > 0:
        current = indices[0]
        keep.append(current)
        others = indices[1:]        
        # Calculate IoU of the current box with the others
        ious = [calculate_iou(boxes[current], boxes[idx]) for idx in others]
        # Keep only boxes with IoU below the threshold
        indices = [idx for i, idx in enumerate(others) if ious[i] <= iou_threshold]    
    return keep


if __name__ == '__main__':
    # Load the label map
    with open(LABELMAP_PATH, ""r"") as f:
        labels = [line.strip() for line in f.readlines()]

    # Load the model
    interpreter = tflite.Interpreter(model_path=MODEL_PATH)
    interpreter.allocate_tensors()

    # Get tensor details
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    # Load a test image with OpenCV
    image_path = ""img"" + str(id_img) + "".jpg""
    image = cv2.imread(image_path)
    original_height, original_width, _ = image.shape

    # Resize the image to match the model's input size
    input_size = input_details[0]['shape'][1:3]
    resized_image = cv2.resize(image, (input_size[1], input_size[0]))

    # Check the expected type of the input tensor
    if input_details[0]['dtype'] == np.uint8:
        input_data = np.expand_dims(resized_image, axis=0).astype(np.uint8)
    else:
        input_data = np.expand_dims(resized_image.astype(np.float32) / 255.0, axis=0)  # Normalization

    # Perform inference
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    # Get the results
    output_data = interpreter.get_tensor(output_details[0]['index'])

    # Reshape for easier manipulation
    output_data = np.squeeze(output_data)  # Remove dimensions of size 1 (e.g., batch size)
    
    # Store predictions for NMS
    all_boxes = []
    all_confidences = []
    all_labels = []

    # Iterate through the predictions
    for i in range(output_data.shape[1]):  # Iterate through 8400 predictions
        x_center, y_center, width, height, confidence, class_id = output_data[:, i]
        # Filter by confidence
        if confidence >= 0.65:  # Adjust confidence threshold as needed
            # Calculate normalized coordinates (x_min, y_min, x_max, y_max)
            x_min = x_center - (width / 2)
            y_min = y_center - (height / 2)
            x_max = x_center + (width / 2)
            y_max = y_center + (height / 2)
            # Convert normalized coordinates to absolute (denormalization)
            y_min_abs = int(y_min * original_height)
            x_min_abs = int(x_min * original_width)
            y_max_abs = int(y_max * original_height)
            x_max_abs = int(x_max * original_width)
            all_boxes.append([x_min_abs, y_min_abs, x_max_abs, y_max_abs])
            all_confidences.append(confidence)
            all_labels.append(int(class_id))

    # Apply Non-Maximum Suppression (NMS)
    nms_indices = nms(all_boxes, all_confidences, iou_threshold=0.5)

    # Display results filtered by NMS
    for idx in nms_indices:
        box = all_boxes[idx]
        confidence = all_confidences[idx]
        label = all_labels[idx]
        cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
        cv2.putText(image, f""{labels[label]}: {confidence:.2f}"", (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Save the image with bounding boxes
    output_path = ""result.jpg""
    cv2.imwrite(output_path, image)
```

The **resulting image** from running the tflite_black_silver_test_3.py code is the one below. Note that the silver balls are not being detected, only the black ball.
![result4](https://github.com/user-attachments/assets/06174278-79ef-4066-a879-4626e22e3553)


**Kaggle settings for conversion:**
ultralytics-8.3.43
Installed dependencies:
```
Ultralytics 8.3.43 🚀 Python-3.10.14 torch-2.4.0 CPU (Intel Xeon 2.00GHz)
YOLOv5n summary (fused): 211 layers, 2,182,054 parameters, 0 gradients, 5.8 GFLOPs

PyTorch: starting from '/kaggle/working/yolov5n-obr.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (4.4 MB)
requirements: Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx2tf>1.17.5,<=1.22.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...
Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com/
Collecting sng4onnx>=1.0.1
  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)
Collecting onnx_graphsurgeon>=0.3.26
  Downloading onnx_graphsurgeon-0.5.2-py2.py3-none-any.whl.metadata (8.1 kB)
Collecting onnx2tf<=1.22.3,>1.17.5
  Downloading onnx2tf-1.22.3-py3-none-any.whl.metadata (136 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 136.6/136.6 kB 6.3 MB/s eta 0:00:00
Collecting onnxslim>=0.1.31
  Downloading onnxslim-0.1.43-py3-none-any.whl.metadata (4.2 kB)
Collecting tflite_support
  Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)
Collecting onnxruntime
  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)
Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from onnx_graphsurgeon>=0.3.26) (1.26.4)
Requirement already satisfied: onnx>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from onnx_graphsurgeon>=0.3.26) (1.17.0)
Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxslim>=0.1.31) (1.13.3)
Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxslim>=0.1.31) (21.3)
Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tflite_support) (1.4.0)
Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tflite_support) (24.3.25)
Requirement already satisfied: protobuf<4,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from tflite_support) (3.20.3)
Collecting sounddevice>=0.4.4 (from tflite_support)
  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)
Requirement already satisfied: pybind11>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from tflite_support) (2.13.6)
Collecting coloredlogs (from onnxruntime)
  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->tflite_support) (1.16.0)
Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)
  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxslim>=0.1.31) (3.1.2)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxslim>=0.1.31) (1.3.0)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.22)
Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)
Downloading onnx_graphsurgeon-0.5.2-py2.py3-none-any.whl (56 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.4/56.4 kB 230.3 MB/s eta 0:00:00
Downloading onnx2tf-1.22.3-py3-none-any.whl (435 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 435.0/435.0 kB 31.3 MB/s eta 0:00:00
Downloading onnxslim-0.1.43-py3-none-any.whl (142 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.9/142.9 kB 300.7 MB/s eta 0:00:00
Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl (60.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 MB 198.1 MB/s eta 0:00:00a 0:00:01
Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 209.2 MB/s eta 0:00:00 0:00:01
Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)
Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 248.4 MB/s eta 0:00:00
Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 282.8 MB/s eta 0:00:00
Installing collected packages: sng4onnx, onnx2tf, humanfriendly, sounddevice, onnxslim, onnx_graphsurgeon, coloredlogs, tflite_support, onnxruntime
Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx2tf-1.22.3 onnx_graphsurgeon-0.5.2 onnxruntime-1.20.1 onnxslim-0.1.43 sng4onnx-1.0.4 sounddevice-0.5.1 tflite_support-0.4.4

requirements: AutoUpdate success ✅ 13.3s, installed 6 packages: ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx2tf>1.17.5,<=1.22.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime']
```
**Settings on the Raspberry PI 3B:**
Python: 3.11.2
tflite-runtime 2.14.0


What could I be doing wrong?

Why does the network work perfectly in the .pt format but this problem occurs in the .tflite format?

I appreciate any help!

_Originally posted by @juliermeSilva in https://github.com/ultralytics/yolov5/discussions/13444_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13445/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13445/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13443,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13443/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13443/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13443/events,https://github.com/ultralytics/yolov5/pull/13443,2719593639,PR_kwDOD8jP_s6EI7KZ,13443,Create animal on road,"{'login': 'vithya270', 'id': 55914364, 'node_id': 'MDQ6VXNlcjU1OTE0MzY0', 'avatar_url': 'https://avatars.githubusercontent.com/u/55914364?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/vithya270', 'html_url': 'https://github.com/vithya270', 'followers_url': 'https://api.github.com/users/vithya270/followers', 'following_url': 'https://api.github.com/users/vithya270/following{/other_user}', 'gists_url': 'https://api.github.com/users/vithya270/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/vithya270/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/vithya270/subscriptions', 'organizations_url': 'https://api.github.com/users/vithya270/orgs', 'repos_url': 'https://api.github.com/users/vithya270/repos', 'events_url': 'https://api.github.com/users/vithya270/events{/privacy}', 'received_events_url': 'https://api.github.com/users/vithya270/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-12-05T07:27:37Z,2024-12-05T07:28:21Z,,NONE,,"<!--
Thank you 🙏 for your contribution to [Ultralytics](https://www.ultralytics.com/) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. Check for Existing Contributions: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. Link Related Issues: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. Elaborate Your Changes: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. Ultralytics Contributor License Agreement (CLA): To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    I have read the CLA Document and I sign the CLA

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing/). Your adherence to these guidelines ensures a faster and more effective review process.
--->


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

It seems the provided PR diff contains minimal information, as it only indicates the creation of a new file (`animal on road`) but does not show any content or additional details. Based on this, here's a generic summary:

---

### 🌟 Summary
A new file named ""animal on road"" has been added to the repository.

### 📊 Key Changes
- Introduced a new file called `animal on road`.
- The file is currently empty (no content in the provided diff).

### 🎯 Purpose & Impact
- **Purpose**: Likely a placeholder or setup for future additions related to detecting animals on roads.
- **Impact**: No immediate effect, but could signal upcoming developments for improving model use cases involving road safety or wildlife detection. Stay tuned! 🚧🦌",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13443/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13443/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13443', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13443', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13443.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13443.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13442,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13442/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13442/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13442/events,https://github.com/ultralytics/yolov5/issues/13442,2719188970,I_kwDOD8jP_s6iE4fq,13442,ImportError: cannot import name 'secure filename' from 'utils’ (E:(haut_ codelyoL0v5-flask-masterlutils__init__.py,"{'login': 'serbbda', 'id': 188419277, 'node_id': 'U_kgDOCzsMzQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/188419277?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/serbbda', 'html_url': 'https://github.com/serbbda', 'followers_url': 'https://api.github.com/users/serbbda/followers', 'following_url': 'https://api.github.com/users/serbbda/following{/other_user}', 'gists_url': 'https://api.github.com/users/serbbda/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/serbbda/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/serbbda/subscriptions', 'organizations_url': 'https://api.github.com/users/serbbda/orgs', 'repos_url': 'https://api.github.com/users/serbbda/repos', 'events_url': 'https://api.github.com/users/serbbda/events{/privacy}', 'received_events_url': 'https://api.github.com/users/serbbda/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,3,2024-12-05T02:54:52Z,2024-12-05T19:41:11Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

ImportError: cannot import name 'secure filename' from 'utils’ (E:(haut_ codelyoL0v5-flask-masterlutils__init__.py

### Environment

OS：pycharm，windows

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13442/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13442/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13439,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13439/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13439/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13439/events,https://github.com/ultralytics/yolov5/issues/13439,2703902643,I_kwDOD8jP_s6hKkez,13439,How to save model (export) upon program exit,"{'login': 'Mitutoyum', 'id': 176998187, 'node_id': 'U_kgDOCozHKw', 'avatar_url': 'https://avatars.githubusercontent.com/u/176998187?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Mitutoyum', 'html_url': 'https://github.com/Mitutoyum', 'followers_url': 'https://api.github.com/users/Mitutoyum/followers', 'following_url': 'https://api.github.com/users/Mitutoyum/following{/other_user}', 'gists_url': 'https://api.github.com/users/Mitutoyum/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Mitutoyum/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Mitutoyum/subscriptions', 'organizations_url': 'https://api.github.com/users/Mitutoyum/orgs', 'repos_url': 'https://api.github.com/users/Mitutoyum/repos', 'events_url': 'https://api.github.com/users/Mitutoyum/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Mitutoyum/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,2,2024-11-29T04:59:54Z,2024-11-29T14:21:47Z,,NONE,,"### Search before asking

- [x] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

How can i make yolo to automically export when the program exits? or atleast save it after each epoch

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13439/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13439/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13436,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13436/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13436/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13436/events,https://github.com/ultralytics/yolov5/issues/13436,2699078622,I_kwDOD8jP_s6g4Kve,13436,Guidance/Libary Needed for ONNX Model Post-Processing,"{'login': 'Throws100', 'id': 87039742, 'node_id': 'MDQ6VXNlcjg3MDM5NzQy', 'avatar_url': 'https://avatars.githubusercontent.com/u/87039742?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Throws100', 'html_url': 'https://github.com/Throws100', 'followers_url': 'https://api.github.com/users/Throws100/followers', 'following_url': 'https://api.github.com/users/Throws100/following{/other_user}', 'gists_url': 'https://api.github.com/users/Throws100/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Throws100/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Throws100/subscriptions', 'organizations_url': 'https://api.github.com/users/Throws100/orgs', 'repos_url': 'https://api.github.com/users/Throws100/repos', 'events_url': 'https://api.github.com/users/Throws100/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Throws100/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,4,2024-11-27T16:14:09Z,2024-12-07T10:11:09Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I've trained a custom YOLOv5 model that performs well, and I've exported it as an ONNX file. However, the output from the ONNX model differs from my expectations. After researching, I understand that ONNX outputs require additional post-processing to match the results seen with the PyTorch model.

Unfortunately, I'm struggling to implement this post-processing manually. Since deploying models in other languages is a common task, I was wondering if anyone could point me to an existing component or library that handles YOLOv5 ONNX post-processing.

Any guidance or resources would be greatly appreciated!
Thank you, Seb

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13436/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13436/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13434,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13434/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13434/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13434/events,https://github.com/ultralytics/yolov5/issues/13434,2698417975,I_kwDOD8jP_s6g1pc3,13434,WARNING ⚠️ NMS time limit 2.100s exceeded,"{'login': 'lqh964165950', 'id': 149365350, 'node_id': 'U_kgDOCOciZg', 'avatar_url': 'https://avatars.githubusercontent.com/u/149365350?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/lqh964165950', 'html_url': 'https://github.com/lqh964165950', 'followers_url': 'https://api.github.com/users/lqh964165950/followers', 'following_url': 'https://api.github.com/users/lqh964165950/following{/other_user}', 'gists_url': 'https://api.github.com/users/lqh964165950/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/lqh964165950/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/lqh964165950/subscriptions', 'organizations_url': 'https://api.github.com/users/lqh964165950/orgs', 'repos_url': 'https://api.github.com/users/lqh964165950/repos', 'events_url': 'https://api.github.com/users/lqh964165950/events{/privacy}', 'received_events_url': 'https://api.github.com/users/lqh964165950/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-11-27T12:43:48Z,2024-11-27T21:13:23Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

为什么训练的每一轮都会出现这个警告？该怎么解决这个问题。
![image](https://github.com/user-attachments/assets/0f61b8bb-91fb-460d-9dd3-772deeb1b004)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13434/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13434/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13433,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13433/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13433/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13433/events,https://github.com/ultralytics/yolov5/issues/13433,2697612303,I_kwDOD8jP_s6gykwP,13433,No speed improvement between FP16 and INT8 TensorRT models,"{'login': 'ingtommi', 'id': 75271898, 'node_id': 'MDQ6VXNlcjc1MjcxODk4', 'avatar_url': 'https://avatars.githubusercontent.com/u/75271898?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ingtommi', 'html_url': 'https://github.com/ingtommi', 'followers_url': 'https://api.github.com/users/ingtommi/followers', 'following_url': 'https://api.github.com/users/ingtommi/following{/other_user}', 'gists_url': 'https://api.github.com/users/ingtommi/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ingtommi/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ingtommi/subscriptions', 'organizations_url': 'https://api.github.com/users/ingtommi/orgs', 'repos_url': 'https://api.github.com/users/ingtommi/repos', 'events_url': 'https://api.github.com/users/ingtommi/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ingtommi/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,10,2024-11-27T08:26:11Z,2024-11-28T09:39:04Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Validation

### Bug

![yolov5-issue](https://github.com/user-attachments/assets/b09333a7-8b9d-45ff-896b-188fcf0d8769)

When validating my YOLOv5n both in **FP16** and **INT8** precision I see **no performance improvement for the INT8 version**, while accuracy and model size drop (which is ok!). I then checked with _trtexec_ and I again get the same latency: 
[yolov5n.txt](https://github.com/user-attachments/files/17931339/yolov5n.txt). 

Since this does not happens for latest YOLOs (where I see around 20% latency improvement), I was thinking that YOLOv5 does not have operations that benefit from INT8 on my current architecture (i.e. 16-bit is already fully optimized). 
Can you help me understanding if this is true or I am making any mistake?


### Environment

- YOLO: YOLOv5n v7.0 fine-tuned on custom dataset
- TensorRT: 8.6.2.3
- Device: NVIDIA Jetson Orin Nano 8GB

### Minimal Reproducible Example

```
python val.py --weights yolo5n.engine --data data.yaml --batch 16 --task test
python val.py --weights yolo5n-int8.engine --data data.yaml --batch 16 --task test

trtexec --loadEngine=yolo5n.engine --batch=1 --fp16
trtexec --loadEngine=yolo5n-int8.engine --batch=1 --best
```

### Additional

Model files: [models.zip](https://github.com/user-attachments/files/17931436/models.zip)

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13433/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13433/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13430,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13430/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13430/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13430/events,https://github.com/ultralytics/yolov5/issues/13430,2685089787,I_kwDOD8jP_s6gCzf7,13430,How to evaluate VisDrone-VID dataset? ,"{'login': 'Wzh10032', 'id': 78578726, 'node_id': 'MDQ6VXNlcjc4NTc4NzI2', 'avatar_url': 'https://avatars.githubusercontent.com/u/78578726?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Wzh10032', 'html_url': 'https://github.com/Wzh10032', 'followers_url': 'https://api.github.com/users/Wzh10032/followers', 'following_url': 'https://api.github.com/users/Wzh10032/following{/other_user}', 'gists_url': 'https://api.github.com/users/Wzh10032/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Wzh10032/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Wzh10032/subscriptions', 'organizations_url': 'https://api.github.com/users/Wzh10032/orgs', 'repos_url': 'https://api.github.com/users/Wzh10032/repos', 'events_url': 'https://api.github.com/users/Wzh10032/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Wzh10032/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,4,2024-11-23T01:38:43Z,2024-11-24T20:44:05Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

How to evaluate Task 2: Object Detection in Videos in VisDrone-Dataset? The existing [VisDrone.yaml](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml) seems to only support VisDrone-DET dataset.
![image](https://github.com/user-attachments/assets/0ee5fb09-9d08-43e5-bb2a-e08b103ef2ad)



### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13430/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13430/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13428,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13428/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13428/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13428/events,https://github.com/ultralytics/yolov5/issues/13428,2682083542,I_kwDOD8jP_s6f3VjW,13428,"What is the difference between ""SPPF/SPP -> C3"" and ""C3 -> SPPF/SPP"" in backbone ?","{'login': 'sunshanlu', 'id': 78467062, 'node_id': 'MDQ6VXNlcjc4NDY3MDYy', 'avatar_url': 'https://avatars.githubusercontent.com/u/78467062?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/sunshanlu', 'html_url': 'https://github.com/sunshanlu', 'followers_url': 'https://api.github.com/users/sunshanlu/followers', 'following_url': 'https://api.github.com/users/sunshanlu/following{/other_user}', 'gists_url': 'https://api.github.com/users/sunshanlu/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/sunshanlu/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/sunshanlu/subscriptions', 'organizations_url': 'https://api.github.com/users/sunshanlu/orgs', 'repos_url': 'https://api.github.com/users/sunshanlu/repos', 'events_url': 'https://api.github.com/users/sunshanlu/events{/privacy}', 'received_events_url': 'https://api.github.com/users/sunshanlu/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-11-22T07:11:39Z,2024-11-22T13:16:35Z,,NONE,,"### Search before asking

- [x] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I found that the last two layers of the backbone of the configuration file of version v5.0 of YOLOv5 use ""C3 -> SPP"", while the configuration file of version v6.0 uses ""C3-> SPPF"". I would like to ask what is the reason for this? Thank you.

![image](https://github.com/user-attachments/assets/8f1386f2-1986-432e-971f-cea8849b534d)

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13428/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13428/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13427,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13427/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13427/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13427/events,https://github.com/ultralytics/yolov5/issues/13427,2681582368,I_kwDOD8jP_s6f1bMg,13427,如何在yolov5中添加FPS和mAPs评价指标？,"{'login': 'lqh964165950', 'id': 149365350, 'node_id': 'U_kgDOCOciZg', 'avatar_url': 'https://avatars.githubusercontent.com/u/149365350?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/lqh964165950', 'html_url': 'https://github.com/lqh964165950', 'followers_url': 'https://api.github.com/users/lqh964165950/followers', 'following_url': 'https://api.github.com/users/lqh964165950/following{/other_user}', 'gists_url': 'https://api.github.com/users/lqh964165950/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/lqh964165950/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/lqh964165950/subscriptions', 'organizations_url': 'https://api.github.com/users/lqh964165950/orgs', 'repos_url': 'https://api.github.com/users/lqh964165950/repos', 'events_url': 'https://api.github.com/users/lqh964165950/events{/privacy}', 'received_events_url': 'https://api.github.com/users/lqh964165950/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-11-22T03:00:31Z,2024-11-24T10:09:08Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

如何在yolov5中添加FPS和mAPs评价指标？

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13427/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13427/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13425,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13425/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13425/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13425/events,https://github.com/ultralytics/yolov5/issues/13425,2678892114,I_kwDOD8jP_s6frKZS,13425,"using --rect  to train, mAP a little bit low","{'login': 'wzf19947', 'id': 30069226, 'node_id': 'MDQ6VXNlcjMwMDY5MjI2', 'avatar_url': 'https://avatars.githubusercontent.com/u/30069226?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/wzf19947', 'html_url': 'https://github.com/wzf19947', 'followers_url': 'https://api.github.com/users/wzf19947/followers', 'following_url': 'https://api.github.com/users/wzf19947/following{/other_user}', 'gists_url': 'https://api.github.com/users/wzf19947/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/wzf19947/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/wzf19947/subscriptions', 'organizations_url': 'https://api.github.com/users/wzf19947/orgs', 'repos_url': 'https://api.github.com/users/wzf19947/repos', 'events_url': 'https://api.github.com/users/wzf19947/events{/privacy}', 'received_events_url': 'https://api.github.com/users/wzf19947/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-11-21T10:19:18Z,2024-11-22T04:34:16Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I trained with two models, the only difference is using --rect param or not , it turns out using --rect  to train, the mAP is much lower and grow up lower than don't use it, is is normal? 

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13425/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13425/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13422,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13422/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13422/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13422/events,https://github.com/ultralytics/yolov5/issues/13422,2672314432,I_kwDOD8jP_s6fSEhA,13422,Why is there a sudden drop in accuracy?,"{'login': 'lqh964165950', 'id': 149365350, 'node_id': 'U_kgDOCOciZg', 'avatar_url': 'https://avatars.githubusercontent.com/u/149365350?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/lqh964165950', 'html_url': 'https://github.com/lqh964165950', 'followers_url': 'https://api.github.com/users/lqh964165950/followers', 'following_url': 'https://api.github.com/users/lqh964165950/following{/other_user}', 'gists_url': 'https://api.github.com/users/lqh964165950/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/lqh964165950/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/lqh964165950/subscriptions', 'organizations_url': 'https://api.github.com/users/lqh964165950/orgs', 'repos_url': 'https://api.github.com/users/lqh964165950/repos', 'events_url': 'https://api.github.com/users/lqh964165950/events{/privacy}', 'received_events_url': 'https://api.github.com/users/lqh964165950/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,6,2024-11-19T14:11:25Z,2024-11-21T12:02:00Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have made some improvements in yolov5, but when training the improved model，sometimes there is a sudden drop in mAP50, 
precision and recall.I want to know why this happend.
![Uploading 曲线.png…]()


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13422/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13422/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13420,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13420/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13420/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13420/events,https://github.com/ultralytics/yolov5/issues/13420,2671195523,I_kwDOD8jP_s6fNzWD,13420,val.py imgsz issue,"{'login': 'wzf19947', 'id': 30069226, 'node_id': 'MDQ6VXNlcjMwMDY5MjI2', 'avatar_url': 'https://avatars.githubusercontent.com/u/30069226?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/wzf19947', 'html_url': 'https://github.com/wzf19947', 'followers_url': 'https://api.github.com/users/wzf19947/followers', 'following_url': 'https://api.github.com/users/wzf19947/following{/other_user}', 'gists_url': 'https://api.github.com/users/wzf19947/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/wzf19947/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/wzf19947/subscriptions', 'organizations_url': 'https://api.github.com/users/wzf19947/orgs', 'repos_url': 'https://api.github.com/users/wzf19947/repos', 'events_url': 'https://api.github.com/users/wzf19947/events{/privacy}', 'received_events_url': 'https://api.github.com/users/wzf19947/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,5,2024-11-19T08:03:50Z,2024-11-21T10:08:03Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I trained a model with imgsz of 640,  when I val the best.pt, I find imgsz set in val.py got different result,  eg, set imgsz=640, I got mAP=0.95, but when I set imgsz=[640,640], I got mAP=0.86, that's a big difference，if I did sth wrong?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13420/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13420/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13419,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13419/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13419/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13419/events,https://github.com/ultralytics/yolov5/issues/13419,2668697334,I_kwDOD8jP_s6fERb2,13419,How to generate the proper yolo style yaml?,"{'login': 'tobymuller233', 'id': 100904932, 'node_id': 'U_kgDOBgOv5A', 'avatar_url': 'https://avatars.githubusercontent.com/u/100904932?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/tobymuller233', 'html_url': 'https://github.com/tobymuller233', 'followers_url': 'https://api.github.com/users/tobymuller233/followers', 'following_url': 'https://api.github.com/users/tobymuller233/following{/other_user}', 'gists_url': 'https://api.github.com/users/tobymuller233/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/tobymuller233/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/tobymuller233/subscriptions', 'organizations_url': 'https://api.github.com/users/tobymuller233/orgs', 'repos_url': 'https://api.github.com/users/tobymuller233/repos', 'events_url': 'https://api.github.com/users/tobymuller233/events{/privacy}', 'received_events_url': 'https://api.github.com/users/tobymuller233/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-11-18T14:15:23Z,2024-11-18T21:04:29Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Recently I'm working on something with yolo, and I have developed my own model and train it in this framework. When I tried to prune my model, I found that because of the particularity of the framework, everytime you need to train a model, you have to first have a yaml file telling the detailed structures of the network. Since  pruned models have different channels, I have to modify the yaml file manually as discussed in [this issue](https://github.com/ultralytics/yolov5/issues/13077#issuecomment-2479563063). So I'm now trying to design a script to automatically modify the yaml file for the network, though it can only be used for my network. I have tried a lot and failed to dump the correct format that looks same with original yaml format. Here is my code:
```python
import yaml
import torch
import argparse
from models.common import *
from models.yolo import *
from ruamel.yaml import YAML
from ruamel.yaml.comments import CommentedSeq

def make_compact_list(data):
    result = CommentedSeq(data)
    result.fa.set_flow_style()  
    return result

def parse_model(model_dict, model):
# parse the model and generate yaml dict

    for i in range(len(model.model)):
        if i < 22:
            part = ""backbone""
        else:
            part = ""head""
        if isinstance(model.model[i], Conv):
            model_dict[part].append([-1, 1, ""Conv"", [model.model[i].conv.out_channels, model.model[i].conv.kernel_size[0], model.model[i].conv.stride[0]]])
        elif isinstance(model.model[i], DWConv):
            model_dict[part].append([-1, 1, ""DWConv"", [model.model[i].conv.out_channels, model.model[i].conv.kernel_size[0], model.model[i].conv.stride[0]]])
        elif isinstance(model.model[i], Bottleneck3):
            model_dict[part].append([-1, 1, ""Bottleneck3"", [model.model[i].cv3.conv.out_channels, model.model[i].cv1.conv.out_channels]])
        elif isinstance(model.model[i], nn.Sequential):
            for j in range(len(model.model[i])):
                # all Bottleneck3
                model_dict[part].append([-1, 1, ""Bottleneck3"", [model.model[i][j].cv3.conv.out_channels, model.model[i][j].cv1.conv.out_channels]])
        elif isinstance(model.model[i], Concat):
            if i == 23:
                model_dict[part].append([[-1, -5], 1, ""Concat"", [1]])
            elif i == 29:
                model_dict[part].append([[-1, 12], 1, ""Concat"", [1]])
            elif i == 35:
                model_dict[part].append([[-1, 7], 1, ""Concat"", [1]])
            else:
                # error
                print(f""Error: Concat layer position ({i}) is wrong"")
        elif isinstance(model.model[i], nn.Upsample):
            model_dict[part].append([-5, 1, ""nn.Upsample"", [None, 2, ""nearest""]])
        elif isinstance(model.model[i], Detect):
            model_dict[part].append([[44, 38, 32], 1, ""Detect"", [""nc"", ""anchors""]])
        else:
            # error
            print(f""Error: Layer type is not supported: {model.model[i]}"")
    model_dict['backbone'] = make_compact_list(model_dict['backbone'])
    model_dict['head'] = make_compact_list(model_dict['head'])
    
if __name__ == ""__main__"":
    parser = argparse.ArgumentParser(description=""Generate yaml file for the pruned model"")
    parser.add_argument(""--model"", type=str, help=""Path to the pruned model"")

    opt = parser.parse_args()
    model = torch.load(opt.model)['model']          # Load the pruned model
    print(model)
    # Create the yaml file
    model_dict = {}
    model_dict['nc'] = 1
    model_dict['depth_multiple'] = 1.0
    model_dict['width_multiple'] = 1.0
    anchors = [[4, 6, 7, 10, 11, 15], [16, 24, 33, 25, 26, 41], [47, 60, 83, 97, 141, 149]]
    model_dict['anchors'] = make_compact_list(anchors)
    model_dict['backbone'] = []
    model_dict['head'] = []
    
    parse_model(model_dict, model)
    yaml_save = YAML()
    
    yaml.PreserveAnchor = False
    yaml_save.default_block_style = True
    yaml_save.indent(sequence=4, offset=2)
    with open(""pruned_model.yaml"", ""w"") as f:
        yaml_save.dump(model_dict, f)
```
Here shows what it looks like:
```yaml
nc: 1
depth_multiple: 1.0
width_multiple: 1.0
anchors: [[4, 6, 7, 10, 11, 15], [16, 24, 33, 25, 26, 41], [47, 60, 83, 97, 141, 149]]
backbone: [[-1, 1, Conv, [2, 3, 2]], [-1, 1, Conv, [2, 3, 1]], [-1, 1, Conv, [7, 1,
          1]], [-1, 1, Conv, [19, 1, 1]], [-1, 1, Conv, [6, 1, 1]], [-1, 1, Bottleneck3,
      [6, 34]], [-1, 1, Conv, [32, 1, 1]], [-1, 1, Conv, [32, 3, 2]], [-1, 1, Conv,
      [8, 1, 1]], [-1, 1, Bottleneck3, [8, 33]], [-1, 1, Bottleneck3, [8, 44]], [
      -1, 1, Conv, [38, 1, 1]], [-1, 1, Conv, [38, 3, 2]], [-1, 1, Conv, [12, 1, 1]],
   [-1, 1, Bottleneck3, [12, 78]], [-1, 1, Bottleneck3, [12, 89]], [-1, 1, Bottleneck3,
      [12, 88]], [-1, 1, Conv, [83, 1, 1]], [-1, 1, Conv, [83, 3, 1]], [-1, 1, Conv,
      [24, 1, 1]], [-1, 1, Bottleneck3, [24, 113]], [-1, 1, Bottleneck3, [24, 132]],
   [-1, 1, Conv, [115, 1, 1]], [-1, 1, Conv, [115, 3, 2]], [-1, 1, Conv, [25, 1, 1]],
   [-1, 1, Bottleneck3, [25, 130]], [-1, 1, Bottleneck3, [25, 218]]]
head: [[-1, 1, Conv, [64, 1, 1]], [[-1, -5], 1, Concat, [1]], [-1, 1, Conv, [39, 1,
          1]], [-1, 1, Conv, [39, 3, 1]], [-1, 1, Conv, [33, 1, 1]], [-1, 1, Conv,
      [18, 1, 1]], [-5, 1, nn.Upsample, [null, 2, nearest]], [[-1, 12], 1, Concat,
      [1]], [-1, 1, Conv, [19, 1, 1]], [-1, 1, Conv, [19, 3, 1]], [-1, 1, Conv, [
          21, 1, 1]], [-1, 1, Conv, [18, 1, 1]], [-5, 1, nn.Upsample, [null, 2, nearest]],
   [ [-1, 7], 1, Concat, [1]], [-1, 1, Conv, [13, 1, 1]], [-1, 1, Conv, [13, 3, 1]],
   [-1, 1, Conv, [16, 1, 1]], [-1, 1, Conv, [18, 1, 1]], [[44, 38, 32], 1, Detect,
      [nc, anchors]]]
```
And I just want the members of `backbone` and `head`  be in a single row just like this:
```yaml
nc: 1 # number of classes
depth_multiple: 1.0 # model depth multiple
width_multiple: 1.0 # layer channel multiple
anchors:
  - [4, 6, 7, 10, 11, 15]
  - [16, 24, 33, 25, 26, 41]
  - [47, 60, 83, 97, 141, 149]

backbone:
  # [from, number, module, args]
  # args: out_channels, size, stride
  [
    [-1, 1, Conv, [2, 3, 2]],  # 0  [batch, 8, size/2, size/2]
    [-1, 1, DWConv, [2, 3, 1]], # 1 [320]
    [-1, 1, Conv, [7, 1, 1 ]], # 2  [320]
    [-1, 1, Conv, [19, 1, 1]], # 3 [-1, 1, DWConv, [24, 3, 2]] # 4
    [-1, 1, Conv, [6, 1, 1]], # 4
    [-1, 1, Bottleneck3, [6, 34]], # 5

    [-1, 1, Conv, [32, 1, 1]], # 6  
    [-1, 1, DWConv, [32, 3, 2]], # 7  [160]
    [-1, 1, Conv, [8, 1, 1]], # 8
    [-1, 1, Bottleneck3, [8, 33]], # 9
    [-1, 1, Bottleneck3, [8, 44]], # 10
    
    [-1, 1, Conv, [38, 1, 1]], # 11 
    [-1, 1, DWConv, [38, 3, 2]], # 12 [80] 
    [-1, 1, Conv, [12, 1, 1]], # 13
    [-1, 1, Bottleneck3, [12, 78]], # 14
    [-1, 1, Bottleneck3, [12, 89]], # 15
    [-1, 1, Bottleneck3, [12, 88]], # 16

    [-1, 1, Conv, [83, 1, 1]], # 17
    [-1, 1, DWConv, [83, 3, 1]], # 18
    [-1, 1, Conv, [24, 1, 1]], # 19
    [-1, 1, Bottleneck3, [24, 113]], # 20
    [-1, 1, Bottleneck3, [24, 132]], # 21

    [-1, 1, Conv, [115, 1, 1]], # 22    [80]
    [-1, 1, DWConv, [115, 3, 2]], # 23  [80] -> [40] 
    [-1, 1, Conv, [25, 1, 1]], # 24
    [-1, 1, Bottleneck3, [25, 130]], # 25 [batch, 40, size/16, size/16]
    [-1, 1, Bottleneck3, [25, 218]], # 26 [batch, 40, size/16, size/16]
  ]

head: [
    [-1, 1, Conv, [64, 1, 1]], # 27 [40]
    [[-1, -5], 1, Concat, [1]], # 28  [batch, 224, size/16, size/16]  [40]  # to line 40 # changed from -4 to -5

    [-1, 1, Conv, [39, 1, 1]], # 29
    [-1, 1, DWConv, [39, 3, 1]], # 30
    [-1, 1, Conv, [33, 1, 1]], # 31
    [-1, 1, Conv, [18, 1, 1]], # 32   [batch, 18, size/8, size/8] -> [40] ###
    
    [-5, 1, nn.Upsample, [None, 2, ""nearest""]],  # 33   [80]
    [[-1, 12], 1, Concat, [1]],  # 34   [80]  ch = 272      # to line 27  # changed from 11 to 12
    [-1, 1, Conv, [19, 1, 1]], # 35
    [-1, 1, DWConv, [19, 3, 1]], # 36 
    [-1, 1, Conv, [21, 1, 1]], # 37   
    [-1, 1, Conv, [18, 1, 1]], # 38 [batch, 18, 160, 160] -> [80] ###

    [-5, 1, nn.Upsample, [None, 2, ""nearest""]],  # 39 [1, 272, 320, 320] -> [160]
    [[-1, 7], 1, Concat, [1]],  # 40  # to line 21
    [-1, 1, Conv, [13, 1, 1]], # 41   
    [-1, 1, DWConv, [13, 3, 1]], # 42 
    [-1, 1, Conv, [16, 1, 1]], # 43   
    [-1, 1, Conv, [18, 1, 1]], # 44   [batch, 18, 320, 320] -> [160]  ###

    [[44, 38, 32], 1, Detect, [nc, anchors]], 
  ]
```
FYI, the reason for why I used `ruamel.yaml`  instead of `yaml` is that I tried `yaml` before using:
```python
def dump_yaml(data, file_path):
    class MyDumper(yaml.Dumper):
        def increase_indent(self, flow=False, indentless=False):
            return super(MyDumper, self).increase_indent(flow=flow, indentless=indentless)
    with open(file_path, 'w') as f:
        yaml.dump(data, f, Dumper=MyDumper, default_flow_style=None)
```
But it turns out that this only fits `anchors` since there is only one layer of embedded list instead of two.:
```yaml
anchors:
- [4, 6, 7, 10, 11, 15]
- [16, 24, 33, 25, 26, 41]
- [47, 60, 83, 97, 141, 149]
backbone:
- - -1
  - 1
  - Conv
  - [2, 3, 2]
- - -1
  - 1
  - Conv
  - [2, 3, 1]
...
 ```

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13419/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13419/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13418,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13418/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13418/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13418/events,https://github.com/ultralytics/yolov5/issues/13418,2667985351,I_kwDOD8jP_s6fBjnH,13418,"Objectness loss, class loss and bounding box losses in YOLOv5","{'login': 'Shanky71', 'id': 72705901, 'node_id': 'MDQ6VXNlcjcyNzA1OTAx', 'avatar_url': 'https://avatars.githubusercontent.com/u/72705901?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Shanky71', 'html_url': 'https://github.com/Shanky71', 'followers_url': 'https://api.github.com/users/Shanky71/followers', 'following_url': 'https://api.github.com/users/Shanky71/following{/other_user}', 'gists_url': 'https://api.github.com/users/Shanky71/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Shanky71/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Shanky71/subscriptions', 'organizations_url': 'https://api.github.com/users/Shanky71/orgs', 'repos_url': 'https://api.github.com/users/Shanky71/repos', 'events_url': 'https://api.github.com/users/Shanky71/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Shanky71/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-11-18T10:16:53Z,2024-11-18T21:57:56Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hey @glenn-jocher I hope you are doing well.  I have a small doubt about the objectness loss.

- I have divided my data in 80% training, 15% testing and 5% validation. As shown in the below image, what can be the possible reason of the sudden spike in the initial part and also, why there is higher objectness loss  during validation than training. 

![image](https://github.com/user-attachments/assets/c51ea3d1-7725-4aa6-acfe-4a5d51e54f31)

- Also out of the three losses (class, objectness, box) which loss is more important. If I consider only class loss doesn't it also account for objectness and box loss? 

@pderrenger @UltralyticsAssistant Can you please clarify it?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13418/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13418/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13416,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13416/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13416/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13416/events,https://github.com/ultralytics/yolov5/issues/13416,2661258912,I_kwDOD8jP_s6en5ag,13416,Loss computation sometimes cause nan values,"{'login': 'tobymuller233', 'id': 100904932, 'node_id': 'U_kgDOBgOv5A', 'avatar_url': 'https://avatars.githubusercontent.com/u/100904932?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/tobymuller233', 'html_url': 'https://github.com/tobymuller233', 'followers_url': 'https://api.github.com/users/tobymuller233/followers', 'following_url': 'https://api.github.com/users/tobymuller233/following{/other_user}', 'gists_url': 'https://api.github.com/users/tobymuller233/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/tobymuller233/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/tobymuller233/subscriptions', 'organizations_url': 'https://api.github.com/users/tobymuller233/orgs', 'repos_url': 'https://api.github.com/users/tobymuller233/repos', 'events_url': 'https://api.github.com/users/tobymuller233/events{/privacy}', 'received_events_url': 'https://api.github.com/users/tobymuller233/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,4,2024-11-15T08:42:56Z,2024-12-22T17:30:19Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Training

### Bug

These days when I'm trying to fine tune my model after pruning by training for several epochs, I found that loss value becomes nan from time to time. By setting breakpoints and checking, I found that there's a bug in [metrics.py](https://github.com/ultralytics/yolov5/blob/1435a8eed6b16d125e7808c81969a0c879d6b8a0/utils/metrics.py#L239)
Sometimes, if the prediction of some bounding box has a width or height of 0, it turns out to be nan values! Since in CIoU computation, h2 and h1 are used as dividers [here](https://github.com/ultralytics/yolov5/blob/1435a8eed6b16d125e7808c81969a0c879d6b8a0/utils/metrics.py#L265).

### Environment

_No response_

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [x] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13416/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13416/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13415,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13415/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13415/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13415/events,https://github.com/ultralytics/yolov5/issues/13415,2654347371,I_kwDOD8jP_s6eNiBr,13415,Can --image-weights and DDP training be compatible by building image-weighted dataset?,"{'login': 'Scorbinwen', 'id': 29889669, 'node_id': 'MDQ6VXNlcjI5ODg5NjY5', 'avatar_url': 'https://avatars.githubusercontent.com/u/29889669?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Scorbinwen', 'html_url': 'https://github.com/Scorbinwen', 'followers_url': 'https://api.github.com/users/Scorbinwen/followers', 'following_url': 'https://api.github.com/users/Scorbinwen/following{/other_user}', 'gists_url': 'https://api.github.com/users/Scorbinwen/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Scorbinwen/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Scorbinwen/subscriptions', 'organizations_url': 'https://api.github.com/users/Scorbinwen/orgs', 'repos_url': 'https://api.github.com/users/Scorbinwen/repos', 'events_url': 'https://api.github.com/users/Scorbinwen/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Scorbinwen/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,4,2024-11-13T06:21:26Z,2024-11-14T17:35:01Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) e.g.https://github.com/ultralytics/yolov5/pull/3275 , the lastest official code seems still be incompatible for ""--image-weights"" and DDP training, but it's needed for my task when my dataset is highly class-unbalanced.
So I implement an image-weighted dataset by estimating repeat times for images:
```python
def expand_indices(indices, image_weight):
    expanded_indices = []
    for idx, weight in zip(indices, image_weight):
        # count is repeat times
        count = int(weight)
        expanded_indices.extend([idx] * count)

    return expanded_indices

class LoadImagesAndLabelsAndMasks(LoadImagesAndLabels):  # for training/testing
    def __init__(
            self,
            path,
            img_size=640,
            batch_size=16,
            num_classes=None,
            augment=False,
            hyp=None,
            rect=False,
            cache_images=False,
            single_cls=False,
            stride=32,
            pad=0,
            prefix="""",
            downsample_ratio=1,
            overlap=False,
            usegt=False,
            use_gray=False,
            gt_type='input-concat'
    ):
        super().__init__(path, img_size, batch_size, augment, hyp, rect, cache_images, single_cls,
                         stride, pad, prefix, usegt, gt_type)
        self.downsample_ratio = downsample_ratio
        self.overlap = overlap
        if num_classes is not None:
            self.num_classes = num_classes
            cw = labels_to_class_weights(self.labels, self.num_classes) * (1 - np.zeros(self.num_classes)) ** 2 # class weights
            iw = labels_to_image_weights(self.labels, nc=self.num_classes, class_weights=cw)  # image weights
            min_iw = torch.min(iw)
            iw = torch.round(iw / min_iw)
            repeat_tensor = lambda rep_list: expand_indices(rep_list, iw.int().tolist()) if rep_list is not None else None
            self.indices = repeat_tensor(self.indices)
            self.ims = repeat_tensor(self.ims)
            self.im_files = repeat_tensor(self.im_files)
            self.npy_files = repeat_tensor(self.npy_files)
            self.labels = repeat_tensor(self.labels)
            self.segments = repeat_tensor(self.segments)
```
I hope someone can help me double check the implementation, if it's ok, I will be grad to contribute to the Yolov5 community.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13415/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13415/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13413,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13413/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13413/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13413/events,https://github.com/ultralytics/yolov5/issues/13413,2650865292,I_kwDOD8jP_s6eAP6M,13413,Why numbers of anchor are 3 in yolov5-p2.yaml?,"{'login': 'DiaJB', 'id': 100334898, 'node_id': 'U_kgDOBfr9Mg', 'avatar_url': 'https://avatars.githubusercontent.com/u/100334898?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/DiaJB', 'html_url': 'https://github.com/DiaJB', 'followers_url': 'https://api.github.com/users/DiaJB/followers', 'following_url': 'https://api.github.com/users/DiaJB/following{/other_user}', 'gists_url': 'https://api.github.com/users/DiaJB/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/DiaJB/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/DiaJB/subscriptions', 'organizations_url': 'https://api.github.com/users/DiaJB/orgs', 'repos_url': 'https://api.github.com/users/DiaJB/repos', 'events_url': 'https://api.github.com/users/DiaJB/events{/privacy}', 'received_events_url': 'https://api.github.com/users/DiaJB/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-11-12T02:53:10Z,2024-11-12T11:16:23Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

There are 4 detectors([21, 24, 27, 30]) in in yolov5-p2.yaml. Why numbers of anchor are 3 in yolov5-p2.yaml? Did anyone try it and whether it worked? 

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13413/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13413/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13412,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13412/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13412/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13412/events,https://github.com/ultralytics/yolov5/issues/13412,2649752980,I_kwDOD8jP_s6d8AWU,13412,How to change the thickness & the transparency of the bounding boxes ?,"{'login': 'andreade11', 'id': 188081712, 'node_id': 'U_kgDOCzXmMA', 'avatar_url': 'https://avatars.githubusercontent.com/u/188081712?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/andreade11', 'html_url': 'https://github.com/andreade11', 'followers_url': 'https://api.github.com/users/andreade11/followers', 'following_url': 'https://api.github.com/users/andreade11/following{/other_user}', 'gists_url': 'https://api.github.com/users/andreade11/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/andreade11/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/andreade11/subscriptions', 'organizations_url': 'https://api.github.com/users/andreade11/orgs', 'repos_url': 'https://api.github.com/users/andreade11/repos', 'events_url': 'https://api.github.com/users/andreade11/events{/privacy}', 'received_events_url': 'https://api.github.com/users/andreade11/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,3,2024-11-11T16:02:34Z,2024-11-12T00:16:01Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Basically i would like my bounding boxes to become nearly transparent as my program is to detect text that is near them and sometimes they hide the text and my OCR model cannot detect them completely. So ideally I would like to make them nearly transparent or with the smallest thickness possible. I tried looking in **detect.py** and changing the `line_thickness=1` but it doesnt produce anything...  

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13412/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13412/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13411,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13411/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13411/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13411/events,https://github.com/ultralytics/yolov5/issues/13411,2649195946,I_kwDOD8jP_s6d54Wq,13411,yolov5 on milk-v tpu 256,"{'login': 'tcpipchip', 'id': 11488460, 'node_id': 'MDQ6VXNlcjExNDg4NDYw', 'avatar_url': 'https://avatars.githubusercontent.com/u/11488460?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/tcpipchip', 'html_url': 'https://github.com/tcpipchip', 'followers_url': 'https://api.github.com/users/tcpipchip/followers', 'following_url': 'https://api.github.com/users/tcpipchip/following{/other_user}', 'gists_url': 'https://api.github.com/users/tcpipchip/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/tcpipchip/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/tcpipchip/subscriptions', 'organizations_url': 'https://api.github.com/users/tcpipchip/orgs', 'repos_url': 'https://api.github.com/users/tcpipchip/repos', 'events_url': 'https://api.github.com/users/tcpipchip/events{/privacy}', 'received_events_url': 'https://api.github.com/users/tcpipchip/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}, {'id': 7663689187, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd4w', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/embedded', 'name': 'embedded', 'color': '0052cc', 'default': False, 'description': 'Pertaining to IOT or low-power devices'}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,11,2024-11-11T12:25:13Z,2024-11-17T07:47:36Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

Hi Sir,
Recently i got the MILK-V 256, a risc-v processor.
I followed these instructions to recognize objects 
https://milkv.io/docs/duo/application-development/tpu/tpu-introduction
https://milkv.io/docs/duo/application-development/tpu/tpu-docker
https://milkv.io/docs/duo/application-development/tpu/tpu-yolov5
[best.zip](https://github.com/user-attachments/files/17701785/best.zip)

And works very very very nice, using the YOLOV5 with the trainned https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n.pt
But, when i create my pt on Colab, best.pt, and convert it to execute on MILK, i always get SEGMENT FAULT
[train_data.zip](https://github.com/user-attachments/files/17701300/train_data.zip)
attached my train on COLAB. On COLAB works, i can do the inference.
Attached too the best.pt

### Environment

Yolo5, docker, all requirements ok to yolov5 master


### Minimal Reproducible Example

```
_import torch
from models.experimental import attempt_download
model = torch.load(attempt_download(""./best.pt""),
map_location=torch.device('cpu'))['model'].float()
model.eval()
model.model[-1].export = True
torch.jit.trace(model, torch.rand(1, 3, 640, 640), strict=False).save('./yolov5n_jit.pt')_
```

```
model_transform.py \
--model_name yolov5n \
--model_def ./yolov5n_jit.pt \
--input_shapes [[1,3,640,640]] \
--pixel_format ""rgb"" \
--keep_aspect_ratio \
--mean 0,0,0 \
--scale 0.0039216,0.0039216,0.0039216 \
--test_input ./cat.jpg \
--test_result yolov5n_top_outputs.npz \
--mlir yolov5n.mlir
```

```
run_calibration.py yolov5n.mlir \
 --dataset ./train_data/train/images \
 --input_num 42 \
 -o ./yolov5n_cali_table
```
```
model_deploy.py \
 --mlir yolov5n.mlir \
 --quantize INT8 \
 --calibration_table ./yolov5n_cali_table \
 --chip cv181x \
 --test_input ./cat.jpg \
 --test_reference yolov5n_top_outputs.npz \
 --compare_all \
 --fuse_preprocess \
 --debug \
 --model yolov5n_int8_fuse.cvimodel
```
```
 ./samples/samples_extra/bin/cvi_sample_detector_yolo_v5_fused_preprocess \
 ./yolov5n_int8_fuse.cvimodel \
 ./face.jpg \
 ./yolov5n_out.jpg
```
SEGMENT FAULT

looks that my problem is on my best.pt, because the yolov5n.pt pre trainned works nice!


### Additional

Sequence using the yolov5n.pt
![image](https://github.com/user-attachments/assets/c1558997-8ff6-4112-9b28-ce969e9e363a)
![image](https://github.com/user-attachments/assets/189f00ef-d948-448f-9dc3-895c85788c35)
![image](https://github.com/user-attachments/assets/0f67458c-d671-40b9-a0bf-cfabbad5c3e1)
![image](https://github.com/user-attachments/assets/159f5b1b-0f79-46ba-a3c9-473fd60dc327)
![image](https://github.com/user-attachments/assets/664eec46-ce0d-4af1-a139-76bc870bb7ef)
![image](https://github.com/user-attachments/assets/60c608c6-4627-4714-afe0-6dc9addb2bf8)
![image](https://github.com/user-attachments/assets/7c9240b3-10ce-4879-870c-4084fb051516)
![image](https://github.com/user-attachments/assets/c2c66bdf-3334-42b3-965f-71e364253004)
![image](https://github.com/user-attachments/assets/bb1f9756-d88c-41a2-b48a-7fbcda00673c)
![image](https://github.com/user-attachments/assets/fef02b92-f753-4ce7-a489-91544b58b4a1)
![image](https://github.com/user-attachments/assets/e4dbf1d0-367b-4d43-a857-bf28cab21969)
![image](https://github.com/user-attachments/assets/e16c4396-2e0e-4990-b094-fd93c7bb5ef2)
![image](https://github.com/user-attachments/assets/2a87ef3b-be63-415a-a11d-40f5bcaf678b)

all works fine

For more help on how to use Docker, head to https://docs.docker.com/go/guides/
ubuntu@DESKTOP-UHGFA4M:~$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
ubuntu@DESKTOP-UHGFA4M:~$ docker run --privileged --name duotpu -v /workspace -it sophgo/tpuc_dev:v3.1
docker: Error response from daemon: Conflict. The container name ""/duotpu"" is already in use by container ""2a46fc75400fa362ed00811b4ec34bba2612506d3938b0e72f8fabab41350246"". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
ubuntu@DESKTOP-UHGFA4M:~$ docker run --privileged --name duotpu -v /workspace -it sophgo/tpuc_dev:v3.1
docker: Error response from daemon: Conflict. The container name ""/duotpu"" is already in use by container ""2a46fc75400fa362ed00811b4ec34bba2612506d3938b0e72f8fabab41350246"". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
ubuntu@DESKTOP-UHGFA4M:~$ docker ps
CONTAINER ID   IMAGE                  COMMAND       CREATED      STATUS          PORTS     NAMES
2a46fc75400f   sophgo/tpuc_dev:v3.1   ""/bin/bash""   2 days ago   Up 12 seconds             duotpu
ubuntu@DESKTOP-UHGFA4M:~$ docker exec -it 2a46fc75400f /bin/bash
root@2a46fc75400f:/workspace# pytorch
bash: pytorch: command not found
root@2a46fc75400f:/workspace# ls
best.pt  master  tpu-mlir  tpu-sdk  yolov5-master  yolov5n_torch
root@2a46fc75400f:/workspace# cd yolov5n_torch/
root@2a46fc75400f:/workspace/yolov5n_torch# ls
_weight_map.csv     yolov5n_cv181x_int8_sym_final.mlir         yolov5n_jit.pt
best.pt             yolov5n_cv181x_int8_sym_model_outputs.npz  yolov5n_origin.mlir
cat.jpg             yolov5n_cv181x_int8_sym_tpu.mlir           yolov5n_top_f32_all_origin_weight.npz
train_data          yolov5n_cv181x_int8_sym_tpu_outputs.npz    yolov5n_top_f32_all_weight.npz
train_data.zip      yolov5n_in_f32.npz                         yolov5n_top_outputs.npz
work                yolov5n_in_ori.npz                         yolov5n_tpu_addressed_cv181x_int8_sym_weight.npz
yolov5n.mlir        yolov5n_int8_fuse.cvimodel                 yolov5n_tpu_addressed_cv181x_int8_sym_weight_fix.npz
yolov5n_cali_table  yolov5n_int8_fuse_tensor_info.txt          yolov5n_tpu_lowered_cv181x_int8_sym_weight.npz
root@2a46fc75400f:/workspace/yolov5n_torch# ls r*
ls: cannot access 'r*': No such file or directory
root@2a46fc75400f:/workspace/yolov5n_torch# cd ..
root@2a46fc75400f:/workspace# ls
best.pt  master  tpu-mlir  tpu-sdk  yolov5-master  yolov5n_torch
root@2a46fc75400f:/workspace# cd yolov5-master/
root@2a46fc75400f:/workspace/yolov5-master# dir
CITATION.cff     README.zh-CN.md  data        main.py           segment         val.py
CONTRIBUTING.md  benchmarks.py    detect.py   models            train.py        yolov5n_jit.pt
LICENSE          best.pt          export.py   pyproject.toml    tutorial.ipynb
README.md        classify         hubconf.py  requirements.txt  utils
root@2a46fc75400f:/workspace/yolov5-master# cat requirements.txt
# YOLOv5 requirements
# Usage: pip install -r requirements.txt

# Base ------------------------------------------------------------------------
gitpython>=3.1.30
matplotlib>=3.3
numpy>=1.23.5
opencv-python>=4.1.1
pillow>=10.3.0
psutil  # system resources
PyYAML>=5.3.1
requests>=2.32.2
scipy>=1.4.1
thop>=0.1.1  # FLOPs computation
torch>=1.8.0  # see https://pytorch.org/get-started/locally (recommended)
torchvision>=0.9.0
tqdm>=4.66.3
ultralytics>=8.2.34  # https://ultralytics.com
# protobuf<=3.20.1  # https://github.com/ultralytics/yolov5/issues/8012

# Logging ---------------------------------------------------------------------
# tensorboard>=2.4.1
# clearml>=1.2.0
# comet

# Plotting --------------------------------------------------------------------
pandas>=1.1.4
seaborn>=0.11.0

# Export ----------------------------------------------------------------------
# coremltools>=6.0  # CoreML export
# onnx>=1.10.0  # ONNX export
# onnx-simplifier>=0.4.1  # ONNX simplifier
# nvidia-pyindex  # TensorRT export
# nvidia-tensorrt  # TensorRT export
# scikit-learn<=1.1.2  # CoreML quantization
# tensorflow>=2.4.0,<=2.13.1  # TF exports (-cpu, -aarch64, -macos)
# tensorflowjs>=3.9.0  # TF.js export
# openvino-dev>=2023.0  # OpenVINO export

# Deploy ----------------------------------------------------------------------
setuptools>=70.0.0 # Snyk vulnerability fix
# tritonclient[all]~=2.24.0

# Extras ----------------------------------------------------------------------
# ipython  # interactive notebook
# mss  # screenshots
# albumentations>=1.0.3
# pycocotools>=2.0.6  # COCO mAP
root@2a46fc75400f:/workspace/yolov5-master# nano requirements.txt
root@2a46fc75400f:/workspace/yolov5-master# pip install -r requirements.txt
Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.32)
Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.2)
Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.24.3)
Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.74)
Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (11.0.0)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)
Requirement already satisfied: PyYAML>=5.3.1 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 11)) (5.4.1)
Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)
Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.1)
Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)
Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cpu)
Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cpu)
Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.67.0)
Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.3.28)
Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0.3)
Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)
Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (75.3.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)
Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)
Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)
Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)
Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.42.1)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.2.0)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (1.26.16)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2023.7.22)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.5.0)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)
Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.6.0)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)
Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)
Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.11)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)
Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)
Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)
Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)
Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
root@2a46fc75400f:/workspace/yolov5-master# ls
CITATION.cff     README.zh-CN.md  data        main.py           segment         val.py
CONTRIBUTING.md  benchmarks.py    detect.py   models            train.py        yolov5n_jit.pt
LICENSE          best.pt          export.py   pyproject.toml    tutorial.ipynb
README.md        classify         hubconf.py  requirements.txt  utils
root@2a46fc75400f:/workspace/yolov5-master# nano main.py
root@2a46fc75400f:/workspace/yolov5-master#
root@2a46fc75400f:/workspace/yolov5-master#
root@2a46fc75400f:/workspace/yolov5-master#
root@2a46fc75400f:/workspace/yolov5-master# wget https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n.pt
--2024-11-11 19:18:11--  https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n.pt
Resolving github.com (github.com)... 20.201.28.151
Connecting to github.com (github.com)|20.201.28.151|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/3444cd1f-277c-414f-bdc9-3ac8ed6062df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241111T111811Z&X-Amz-Expires=300&X-Amz-Signature=b7761184e059f5a596b94e432bf731d13dc16857dab233d44d18080fc0f23350&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5n.pt&response-content-type=application%2Foctet-stream [following]
--2024-11-11 19:18:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/3444cd1f-277c-414f-bdc9-3ac8ed6062df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241111T111811Z&X-Amz-Expires=300&X-Amz-Signature=b7761184e059f5a596b94e432bf731d13dc16857dab233d44d18080fc0f23350&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5n.pt&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4062133 (3.9M) [application/octet-stream]
Saving to: ‘yolov5n.pt’

yolov5n.pt                    100%[================================================>]   3.87M  8.31MB/s    in 0.5s

2024-11-11 19:18:12 (8.31 MB/s) - ‘yolov5n.pt’ saved [4062133/4062133]

root@2a46fc75400f:/workspace/yolov5-master# cat main.py
import torch
from models.experimental import attempt_download
model = torch.load(attempt_download(""./yolov5n.pt""),
    map_location=torch.device('cpu'))['model'].float()
model.eval()
model.model[-1].export = True
torch.jit.trace(model, torch.rand(1, 3, 640, 640), strict=False).save('./yolov5n_jit.pt')
root@2a46fc75400f:/workspace/yolov5-master# python main.py
root@2a46fc75400f:/workspace/yolov5-master# cp yolov5n_jit.pt /workspace/yolov5-master/^C
root@2a46fc75400f:/workspace/yolov5-master# cd ..
root@2a46fc75400f:/workspace# cd yolov5n_torch
root@2a46fc75400f:/workspace/yolov5n_torch# cp /workspace/yolov5-master/yolov5n_jit.pt .
root@2a46fc75400f:/workspace/yolov5n_torch# source ./tpu-mlir/envsetup.sh
bash: ./tpu-mlir/envsetup.sh: No such file or directory
root@2a46fc75400f:/workspace/yolov5n_torch# cd ..
root@2a46fc75400f:/workspace# source ./tpu-mlir/envsetup.sh
root@2a46fc75400f:/workspace# cd yolov5n_torch/
root@2a46fc75400f:/workspace/yolov5n_torch#  cp -rf ${TPUC_ROOT}/regression/dataset/COCO2017 .
root@2a46fc75400f:/workspace/yolov5n_torch# cp -rf ${TPUC_ROOT}/regression/image .
root@2a46fc75400f:/workspace/yolov5n_torch# model_transform.py \
> --model_name yolov5n \
> --model_def ../yolov5n_jit.pt \
> --input_shapes [[1,3,640,640]] \
> --pixel_format ""rgb"" \
> --keep_aspect_ratio \
> --mean 0,0,0 \
> --scale 0.0039216,0.0039216,0.0039216 \
> --test_input ../image/dog.jpg \
> --test_result yolov5n_top_outputs.npz \
> --output_names 1219,1234,1249 \
> --mlir yolov5n.mlir
SOPHGO Toolchain v1.3.228-g19ca95e9-20230921
2024/11/11 19:22:19 - INFO :
         _____________________________________________________
        | preprocess:                                           |
        |   (x - mean) * scale                                  |
        '-------------------------------------------------------'
  config Preprocess args :
        resize_dims           : same to net input dims
        keep_aspect_ratio     : True
        keep_ratio_mode       : letterbox
        pad_value             : 0
        pad_type              : center
        --------------------------
        mean                  : [0.0, 0.0, 0.0]
        scale                 : [0.0039216, 0.0039216, 0.0039216]
        --------------------------
        pixel_format          : rgb
        channel_format        : nchw

Traceback (most recent call last):
  File ""/workspace/tpu-mlir/python/tools/model_transform.py"", line 272, in <module>
    tool = get_model_transform(args)
  File ""/workspace/tpu-mlir/python/tools/model_transform.py"", line 232, in get_model_transform
    tool = TorchTransformer(args.model_name, args.model_def, args.input_shapes,
  File ""/workspace/tpu-mlir/python/tools/model_transform.py"", line 204, in __init__
    self.converter = TorchConverter(self.model_name, self.model_def, input_shapes, input_types,
  File ""/workspace/tpu-mlir/python/transform/TorchConverter.py"", line 55, in __init__
    self.load_torch_model(torch_file, input_shapes, input_types, output_names)
  File ""/workspace/tpu-mlir/python/transform/TorchConverter.py"", line 251, in load_torch_model
    self.model = torch.jit.load(torch_file, map_location=torch.device('cpu'))
  File ""/usr/local/lib/python3.10/dist-packages/torch/jit/_serialization.py"", line 152, in load
    raise ValueError(""The provided filename {} does not exist"".format(f))  # type: ignore[str-bytes-safe]
ValueError: The provided filename ../yolov5n_jit.pt does not exist
root@2a46fc75400f:/workspace/yolov5n_torch# model_transform.py \
> --model_name yolov5n \
> --model_def ./yolov5n_jit.pt \
> --input_shapes [[1,3,640,640]] \
> --pixel_format ""rgb"" \
> --keep_aspect_ratio \
 \
--sca> --mean 0,0,0 \
> --scale 0.0039216,0.0039216,0.0039216 \
> --test_input ./image/dog.jpg \
> --test_result yolov5n_top_outputs.npz \
> --output_names 1219,1234,1249 \
> --mlir yolov5n.mlir
SOPHGO Toolchain v1.3.228-g19ca95e9-20230921
2024/11/11 19:23:07 - INFO :
         _____________________________________________________
        | preprocess:                                           |
        |   (x - mean) * scale                                  |
        '-------------------------------------------------------'
  config Preprocess args :
        resize_dims           : same to net input dims
        keep_aspect_ratio     : True
        keep_ratio_mode       : letterbox
        pad_value             : 0
        pad_type              : center
        --------------------------
        mean                  : [0.0, 0.0, 0.0]
        scale                 : [0.0039216, 0.0039216, 0.0039216]
        --------------------------
        pixel_format          : rgb
        channel_format        : nchw

Save mlir file: yolov5n_origin.mlir
[Running]: tpuc-opt yolov5n_origin.mlir --shape-infer --canonicalize --extra-optimize -o yolov5n.mlir
[Success]: tpuc-opt yolov5n_origin.mlir --shape-infer --canonicalize --extra-optimize -o yolov5n.mlir
Mlir file generated:yolov5n.mlir
2024/11/11 19:23:10 - INFO :
  load_config Preprocess args :
        resize_dims           : [640, 640]
        keep_aspect_ratio     : True
        keep_ratio_mode       : letterbox
        pad_value             : 0
        pad_type              : center
        input_dims            : [640, 640]
        --------------------------
        mean                  : [0.0, 0.0, 0.0]
        scale                 : [0.0039216, 0.0039216, 0.0039216]
        --------------------------
        pixel_format          : rgb
        channel_format        : nchw

[CMD]: model_runner.py --input yolov5n_in_f32.npz --model ./yolov5n_jit.pt --output yolov5n_ref_outputs.npz
80: 100%|████████████████████████████████████████████████████████████████████████| 1230/1230 [00:01<00:00, 1134.76it/s]
Saving yolov5n_ref_outputs.npz
[CMD]: model_runner.py --input yolov5n_in_f32.npz --model yolov5n.mlir --output yolov5n_top_outputs.npz
[##################################################] 100%
Saving yolov5n_top_outputs.npz
[Running]: npz_tool.py compare yolov5n_top_outputs.npz yolov5n_ref_outputs.npz --tolerance 0.99,0.99 --except - -vv
compare 1249: 100%|█████████████████████████████████████████████████████████████████▋| 199/200 [00:06<00:00, 37.17it/s][x.1                             ]        EQUAL [PASSED]
    (1, 3, 640, 640) float32
[input.62                        ]      SIMILAR [PASSED]
    (1, 16, 320, 320) float32
    cosine_similarity      = 1.000000
    euclidean_similarity   = 0.999999
    sqnr_similarity        = 123.899231
[input.26                        ]      SIMILAR [PASSED]
    (1, 16, 320, 320) float32
    cosine_similarity      = 1.000000
    euclidean_similarity   = 1.000000
    sqnr_similarity        = 127.972746
[103                             ]      SIMILAR [PASSED]
    (1, 16, 320, 320) float32
    cosine_similarity      = 1.000000
    euclidean_similarity   = 1.000000
    sqnr_similarity        = 122.331476
[input.60                        ]      SIMILAR [PASSED]
...
    (1, 255, 80, 80) float32
    cosine_similarity      = 1.000000
    euclidean_similarity   = 1.000000
    sqnr_similarity        = 119.547615
[1234                            ]      SIMILAR [PASSED]
    (1, 255, 40, 40) float32
    cosine_similarity      = 1.000000
    euclidean_similarity   = 1.000000
    sqnr_similarity        = 118.485079
[1249                            ]      SIMILAR [PASSED]
    (1, 255, 20, 20) float32
    cosine_similarity      = 1.000000
    euclidean_similarity   = 1.000000
    sqnr_similarity        = 118.825769
200 compared
200 passed
  1 equal, 3 close, 196 similar
0 failed
  0 not equal, 0 not similar
min_similiarity = (0.9999997615814209, 0.999998192529101, 114.64153289794922)
Target    yolov5n_top_outputs.npz
Reference yolov5n_ref_outputs.npz
npz compare PASSED.
compare 1249: 100%|██████████████████████████████████████████████████████████████████| 200/200 [00:08<00:00, 24.98it/s]
[Success]: npz_tool.py compare yolov5n_top_outputs.npz yolov5n_ref_outputs.npz --tolerance 0.99,0.99 --except - -vv
root@2a46fc75400f:/workspace/yolov5n_torch# run_calibration.py yolov5n.mlir \
>  --dataset ../COCO2017 \
>  --input_num 100 \
>  -o ./yolov5n_cali_table
SOPHGO Toolchain v1.3.228-g19ca95e9-20230921
Traceback (most recent call last):
  File ""/workspace/tpu-mlir/python/tools/run_calibration.py"", line 36, in <module>
    selector = DataSelector(args.dataset, args.input_num, args.data_list)
  File ""/workspace/tpu-mlir/python/calibration/data_selector.py"", line 47, in __init__
    raise RuntimeError(""There is no inputs"")
RuntimeError: There is no inputs
root@2a46fc75400f:/workspace/yolov5n_torch# run_calibration.py yolov5n.mlir \
>  --dataset ./COCO2017 \
>  --input_num 100 \
>  -o ./yolov5n_cali_table
SOPHGO Toolchain v1.3.228-g19ca95e9-20230921
GmemAllocator use OpSizeOrderAssign
reused mem is 3276800, all mem is 43767600
2024/11/11 19:24:09 - INFO :
  load_config Preprocess args :
        resize_dims           : [640, 640]
        keep_aspect_ratio     : True
        keep_ratio_mode       : letterbox
        pad_value             : 0
        pad_type              : center
        input_dims            : [640, 640]
        --------------------------
        mean                  : [0.0, 0.0, 0.0]
        scale                 : [0.0039216, 0.0039216, 0.0039216]
        --------------------------
        pixel_format          : rgb
        channel_format        : nchw

last input data (idx=100) not valid, droped
input_num = 100, ref = 100
real input_num = 100
activation_collect_and_calc_th for op: 1249: 100%|███████████████████████████████████| 200/200 [04:25<00:00,  1.33s/it]
[2048] threshold: 1249: 100%|███████████████████████████████████████████████████████| 200/200 [00:00<00:00, 235.10it/s]
GmemAllocator use OpSizeOrderAssign
reused mem is 3276800, all mem is 43767600
GmemAllocator use OpSizeOrderAssign
reused mem is 3276800, all mem is 43767600
prepare data from 100
tune op: 1249: 100%|█████████████████████████████████████████████████████████████████| 200/200 [07:13<00:00,  2.17s/it]
auto tune end, run time:433.61561346054077
root@2a46fc75400f:/workspace/yolov5n_torch#   model_deploy.py \
 \
 --qu>  --mlir yolov5n.mlir \
>  --quantize INT8 \
>  --calibration_table ./yolov5n_cali_table \
>  --chip cv181x \
>  --test_input ./image/dog.jpg \
>  --test_reference yolov5n_top_outputs.npz \
>  --compare_all \
>  --tolerance 0.96,0.72 \
>  --fuse_preprocess \
>  --debug \
>  --model yolov5n_int8_fuse.cvimodel
SOPHGO Toolchain v1.3.228-g19ca95e9-20230921
2024/11/11 19:37:39 - INFO :
  load_config Preprocess args :
        resize_dims           : [640, 640]
        keep_aspect_ratio     : True
        keep_ratio_mode       : letterbox
        pad_value             : 0
        pad_type              : center
        input_dims            : [640, 640]
        --------------------------
        mean                  : [0.0, 0.0, 0.0]
        scale                 : [0.0039216, 0.0039216, 0.0039216]
        --------------------------
        pixel_format          : rgb
        channel_format        : nchw

Add preprocess, set the following params:
2024/11/11 19:37:39 - INFO :
         _____________________________________________________
        | preprocess:                                           |
        |   (x - mean) * scale                                  |
        '-------------------------------------------------------'
  config Preprocess args :
        resize_dims           : [640, 640]
        keep_aspect_ratio     : True
        keep_ratio_mode       : letterbox
        pad_value             : 0
        pad_type              : center
        --------------------------
        mean                  : [0.0, 0.0, 0.0]
        scale                 : [1.0, 1.0, 1.0]
        --------------------------
        pixel_format          : rgb
        channel_format        : nchw

[Running]: tpuc-opt yolov5n.mlir --chip-assign=""chip=cv181x"" --import-calibration-table=""file=./yolov5n_cali_table asymmetric=False"" --chip-top-optimize --fuse-preprocess=""mode=INT8 customization_format=RGB_PLANAR align=False"" --convert-top-to-tpu=""mode=INT8  asymmetric=False linear_quant_mode=NORMAL doWinograd=False ignore_f16_overflow=False"" --canonicalize -o yolov5n_cv181x_int8_sym_tpu.mlir
Entering FusePreprocessPass.
Inserting ScalelutOp.
[Success]: tpuc-opt yolov5n.mlir --chip-assign=""chip=cv181x"" --import-calibration-table=""file=./yolov5n_cali_table asymmetric=False"" --chip-top-optimize --fuse-preprocess=""mode=INT8 customization_format=RGB_PLANAR align=False"" --convert-top-to-tpu=""mode=INT8  asymmetric=False linear_quant_mode=NORMAL doWinograd=False ignore_f16_overflow=False"" --canonicalize -o yolov5n_cv181x_int8_sym_tpu.mlir
[CMD]: model_runner.py --input yolov5n_in_ori.npz --model yolov5n_cv181x_int8_sym_tpu.mlir --output yolov5n_cv181x_int8_sym_tpu_outputs.npz
[##################################################] 100%
[Running]: npz_tool.py compare yolov5n_cv181x_int8_sym_tpu_outputs.npz yolov5n_top_outputs.npz --tolerance 0.96,0.72 --except - -vv
compare 1249:  99%|█████████████████████████████████████████████████████████████████▌| 141/142 [00:05<00:00, 21.14it/s][input.26                        ]      SIMILAR [PASSED]
    (1, 16, 320, 320) float32
    cosine_similarity      = 0.999769
    euclidean_similarity   = 0.978254
    sqnr_similarity        = 32.948797
[103                             ]      SIMILAR [PASSED]
    (1, 16, 320, 320) float32
    cosine_similarity      = 0.999255
    euclidean_similarity   = 0.961272
    sqnr_similarity        = 24.556572
...
    (1, 255, 40, 40) float32
    cosine_similarity      = 0.999221
    euclidean_similarity   = 0.959803
    sqnr_similarity        = 18.724862
[1249                            ]      SIMILAR [PASSED]
    (1, 255, 20, 20) float32
    cosine_similarity      = 0.999214
    euclidean_similarity   = 0.960290
    sqnr_similarity        = 18.388116
142 compared
142 passed
  0 equal, 0 close, 142 similar
0 failed
  0 not equal, 0 not similar
min_similiarity = (0.9679524302482605, 0.7443984113616068, 11.602303981781006)
Target    yolov5n_cv181x_int8_sym_tpu_outputs.npz
Reference yolov5n_top_outputs.npz
npz compare PASSED.
compare 1249: 100%|██████████████████████████████████████████████████████████████████| 142/142 [00:06<00:00, 22.79it/s]
[Success]: npz_tool.py compare yolov5n_cv181x_int8_sym_tpu_outputs.npz yolov5n_top_outputs.npz --tolerance 0.96,0.72 --except - -vv
[Running]: tpuc-opt yolov5n_cv181x_int8_sym_tpu.mlir --mlir-disable-threading --strip-io-quant=""quant_input=False quant_output=False"" --chip-tpu-optimize --distribute='num_device=1' --weight-reorder  --subnet-divide=""dynamic=False"" --op-reorder --layer-group=""opt=2"" --parallel='num_core=1' --address-assign -o yolov5n_cv181x_int8_sym_final.mlir
==---------------------------==
Run LayerGroupSearchPass :
    Searching the optimal layer groups
==---------------------------==

=======================================================
***** Dynamic Programming layer group with cluster ****
=======================================================
total num of base_group is 7
clusters idx(size): 0(1), 1(2), 3(2), 5(2), 7(2), 9(2), 11(2), 13(1), 14(1), 15(2), 17(2), 19(2), 21(2), 23(2), 25(2), 27(2), 29(2), 31(2), 33(1), 34(2), 36(2), 38(2), 40(2), 42(2), 44(2), 46(2), 48(2), 50(2), 52(2), 54(2), 56(1), 57(1), 58(2), 60(1), 61(2), 63(2), 65(2), 67(2), 69(2), 71(2), 73(2), 75(2), 77(2), 79(2), 81(2), 83(2), 85(2), 87(2), 89(2), 91(2), 93(1), 94(1), 95(2), 97(2), 99(2), 101(2), 103(2), 105(2), 107(2), 109(1), 110(2), 112(2), 114(2), 116(2), 118(2), 120(2), 122(1), 123(1), 124(2), 126(2), 128(2), 130(2), 132(2), 134(2), 136(1), 137(2), 139(2),
process base group 0, layer_num=141, cluster_num=77
Searching best group slices...
[#################################################] 100%
clusters idx(size): 0(1),
process base group 1, layer_num=1, cluster_num=1
clusters idx(size): 0(1),
process base group 2, layer_num=1, cluster_num=1
clusters idx(size): 0(1),
process base group 3, layer_num=1, cluster_num=1
clusters idx(size): 0(1),
process base group 4, layer_num=1, cluster_num=1
clusters idx(size): 0(1),
process base group 5, layer_num=1, cluster_num=1
clusters idx(size): 0(1),
process base group 6, layer_num=1, cluster_num=1
-------------------------------------------------------
Consider redundant computation and gdma cost
-------------------------------------------------------
The final cost of the two group is 1182594
//// Group cost 1182594, optimal cut idx 139
The final cost of the two group is 1116710
//// Group cost 1116710, optimal cut idx 138
The final cost of the two group is 1315164
The final cost of the two group is 970894
//// Group cost 970894, optimal cut idx 137
The final cost of the two group is 866493
//// Group cost 866493, optimal cut idx 136
The final cost of the two group is 877481
The final cost of the two group is 941308
The final cost of the two group is 892746
The pre cost of the two group is 898167
The final cost of the two group is 901710
//// Group cost 901710, optimal cut idx 132
The final cost of the two group is 832079
....
The final cost of the two group is 4092392
//// Group cost 4092392, optimal cut idx 0
-------------------------------------------------------
Merge cut idx to reduce gdma cost
-------------------------------------------------------
==---------------------------==
Run GroupPostTransformPass :
    Some transform after layer groups is determined
==---------------------------==
==---------------------------==
Run TimeStepAssignmentPass :
    Assign timestep task for each group.
==---------------------------==
==---------------------------==
Run LocalMemoryAllocationPass :
    Allocate local memory for all layer groups
==---------------------------==
==---------------------------==
Run TimeStepCombinePass :
    Combine time step for better parallel balance
==---------------------------==
==---------------------------==
Run GroupDataMoveOverlapPass :
    Overlap data move between two layer group
==---------------------------==
GmemAllocator use OpSizeOrderAssign
[Success]: tpuc-opt yolov5n_cv181x_int8_sym_tpu.mlir --mlir-disable-threading --strip-io-quant=""quant_input=False quant_output=False"" --chip-tpu-optimize --distribute='num_device=1' --weight-reorder  --subnet-divide=""dynamic=False"" --op-reorder --layer-group=""opt=2"" --parallel='num_core=1' --address-assign -o yolov5n_cv181x_int8_sym_final.mlir
[Running]: tpuc-opt yolov5n_cv181x_int8_sym_final.mlir --codegen=""model_file=yolov5n_int8_fuse.cvimodel embed_debug_info=true model_version=latest"" -o /dev/null
  [oc_pos=32] cur_oc 8, stepSize 1024, compressedSize 1040, SKIP
[Success]: tpuc-opt yolov5n_cv181x_int8_sym_final.mlir --codegen=""model_file=yolov5n_int8_fuse.cvimodel embed_debug_info=true model_version=latest"" -o /dev/null
[CMD]: model_runner.py --input yolov5n_in_ori.npz --model yolov5n_int8_fuse.cvimodel --output yolov5n_cv181x_int8_sym_model_outputs.npz
setenv:cv181x
Start TPU Simulator for cv181x
device[0] opened, 4294967296
version: 1.4.0
yolov5n Build at 2024-11-11 19:37:51 For platform cv181x
Cmodel: bm_load_cmdbuf
Max SharedMem size:2457600
Cmodel: bm_run_cmdbuf
device[0] closed
[Running]: npz_tool.py compare yolov5n_cv181x_int8_sym_model_outputs.npz yolov5n_cv181x_int8_sym_tpu_outputs.npz --tolerance 0.99,0.90 --except - -vv
compare 1249_f32:  88%|█████████████████████████████████████████████████████████▊        | 7/8 [00:00<00:00, 69.16it/s][964                             ]        EQUAL [PASSED]
    (1, 64, 80, 80) float32
[1081                            ]        EQUAL [PASSED]
    (1, 128, 40, 40) float32
[input.1                         ]        EQUAL [PASSED]
    (1, 256, 20, 20) float32
[1198                            ]        EQUAL [PASSED]
    (1, 256, 20, 20) float32
[1219_f32                        ]        EQUAL [PASSED]
    (1, 255, 80, 80) float32
[1234_f32                        ]        EQUAL [PASSED]
    (1, 255, 40, 40) float32
[1249                            ]        EQUAL [PASSED]
    (1, 255, 20, 20) float32
[1249_f32                        ]        EQUAL [PASSED]
    (1, 255, 20, 20) float32
8 compared
8 passed
  8 equal, 0 close, 0 similar
0 failed
  0 not equal, 0 not similar
min_similiarity = (1.0, 1.0, inf)
Target    yolov5n_cv181x_int8_sym_model_outputs.npz
Reference yolov5n_cv181x_int8_sym_tpu_outputs.npz
npz compare PASSED.
compare 1249_f32: 100%|██████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 27.38it/s]
[Success]: npz_tool.py compare yolov5n_cv181x_int8_sym_model_outputs.npz yolov5n_cv181x_int8_sym_tpu_outputs.npz --tolerance 0.99,0.90 --except - -vv
root@2a46fc75400f:/workspace/yolov5n_torch# scp -r /workspace/tpu-sdk root@192.168.42.1:/mnt/tpu/
root@192.168.42.1's password:
OpenCVModules-release.cmake                                                          100% 2053   402.1KB/s   00:00
haarcascade_eye.xml                                                                  100%  333KB   2.7MB/s   00:00
haarcascade_smile.xml                                                                100%  184KB   2.7MB/s   00:00
....
libcvimath-static.a                                                                  100%  172KB   2.6MB/s   00:00
libcviruntime.so                                                                     100%  574KB   2.9MB/s   00:00
root@2a46fc75400f:/workspace/yolov5n_torch# scp /workspace/yolov5n_torch/yolov5n_int8_fuse.cvimodel root@192.168.42.1:/
mnt/tpu/tpu-sdk/
root@192.168.42.1's password:
yolov5n_int8_fuse.cvimodel                                                           100% 2158KB   2.9MB/s   00:00
root@2a46fc75400f:/workspace/yolov5n_torch# ls -l
total 389176
drwxr-xr-x 2 root root      4096 Nov 11 19:21 COCO2017
-rw-r--r-- 1 root root     12398 Nov 11 19:37 _weight_map.csv
-rwxr-xr-x 1 root root  14447400 Nov  9 09:00 best.pt
-rwxr-xr-x 1 root root     40717 Oct 29 07:42 cat.jpg
drwxr-xr-x 2 root root      4096 Nov 11 19:21 image
drwxr-xr-x 5 root root      4096 Nov  7 14:12 train_data
-rwxr-xr-x 1 root root   2524205 Nov  8 01:36 train_data.zip
drwxr-xr-x 2 root root      4096 Nov  9 10:02 work
-rw-r--r-- 1 root root     64711 Nov 11 19:23 yolov5n.mlir
-rw-r--r-- 1 root root      8011 Nov 11 19:35 yolov5n_cali_table
-rw-r--r-- 1 root root   2210112 Nov 11 19:37 yolov5n_int8_fuse.cvimodel

root@2a46fc75400f:/workspace/yolov5n_torch#

![image](https://github.com/user-attachments/assets/619dc0ea-2d54-42f8-8787-477ff8cd5e5b)

now using the best.pt

model_deploy.py \
 --mlir yolov5n.mlir \
 --quantize INT8 \
 --calibration_table ./yolov5n_cali_table \
 --chip cv181x \
 --test_input ./cat.jpg \
 --test_reference yolov5n_top_outputs.npz \
 --compare_all \
 --fuse_preprocess \
 --debug \
 --model yolov5n_int8_fuse.cvimodel

![image](https://github.com/user-attachments/assets/da19cb65-3b27-4879-93ac-ac8325d8e630)

Thank you!

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13411/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13411/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13409,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13409/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13409/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13409/events,https://github.com/ultralytics/yolov5/issues/13409,2646833455,I_kwDOD8jP_s6dw3kv,13409,how to use the val.py script to detect only 'person' and 'car' classes？,"{'login': 'ghosmile', 'id': 93780240, 'node_id': 'U_kgDOBZb5EA', 'avatar_url': 'https://avatars.githubusercontent.com/u/93780240?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ghosmile', 'html_url': 'https://github.com/ghosmile', 'followers_url': 'https://api.github.com/users/ghosmile/followers', 'following_url': 'https://api.github.com/users/ghosmile/following{/other_user}', 'gists_url': 'https://api.github.com/users/ghosmile/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ghosmile/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ghosmile/subscriptions', 'organizations_url': 'https://api.github.com/users/ghosmile/orgs', 'repos_url': 'https://api.github.com/users/ghosmile/repos', 'events_url': 'https://api.github.com/users/ghosmile/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ghosmile/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-11-10T05:02:44Z,2024-11-10T16:43:18Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I want to use the val.py script to detect only 'person' and 'car' classes, but the output prediction results still include other classes, and modifying the include_class in the dataloaders file doesn't work, what should I do?""
![image](https://github.com/user-attachments/assets/1a33a856-a568-4b66-9244-69fe8f2d311c)
![image](https://github.com/user-attachments/assets/8978746a-b980-4396-b14f-2943c78e6583)
pred has else class

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13409/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13409/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13404,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13404/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13404/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13404/events,https://github.com/ultralytics/yolov5/issues/13404,2643347028,I_kwDOD8jP_s6djkZU,13404,problem with int8 quantization of tensorrt for models trained with adam optimizer,"{'login': 'skynn1128', 'id': 126381948, 'node_id': 'U_kgDOB4hvfA', 'avatar_url': 'https://avatars.githubusercontent.com/u/126381948?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/skynn1128', 'html_url': 'https://github.com/skynn1128', 'followers_url': 'https://api.github.com/users/skynn1128/followers', 'following_url': 'https://api.github.com/users/skynn1128/following{/other_user}', 'gists_url': 'https://api.github.com/users/skynn1128/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/skynn1128/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/skynn1128/subscriptions', 'organizations_url': 'https://api.github.com/users/skynn1128/orgs', 'repos_url': 'https://api.github.com/users/skynn1128/repos', 'events_url': 'https://api.github.com/users/skynn1128/events{/privacy}', 'received_events_url': 'https://api.github.com/users/skynn1128/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,2,2024-11-08T08:51:16Z,2024-11-08T22:17:27Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Export

### Bug

Hello
When I use the adam optimizer to train a pt model, then convert it to onnx, and then convert it to the tensorrt engine model, there is a problem with the output threshold during testing, but when I use the sgd optimizer to train the model and perform the above steps, the engine model output threshold is normal. What is the reason?
When using sgd, the normal threshold of the int8 engine output is 0.92, but when using adam, the output threshold is 0.14


### Environment

_No response_

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13404/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13404/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13401,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13401/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13401/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13401/events,https://github.com/ultralytics/yolov5/issues/13401,2637642980,I_kwDOD8jP_s6dNzzk,13401,Failing at small detection !!,"{'login': 'Manueljohnson063', 'id': 44712542, 'node_id': 'MDQ6VXNlcjQ0NzEyNTQy', 'avatar_url': 'https://avatars.githubusercontent.com/u/44712542?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Manueljohnson063', 'html_url': 'https://github.com/Manueljohnson063', 'followers_url': 'https://api.github.com/users/Manueljohnson063/followers', 'following_url': 'https://api.github.com/users/Manueljohnson063/following{/other_user}', 'gists_url': 'https://api.github.com/users/Manueljohnson063/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Manueljohnson063/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Manueljohnson063/subscriptions', 'organizations_url': 'https://api.github.com/users/Manueljohnson063/orgs', 'repos_url': 'https://api.github.com/users/Manueljohnson063/repos', 'events_url': 'https://api.github.com/users/Manueljohnson063/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Manueljohnson063/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,7,2024-11-06T10:22:59Z,2024-12-10T18:26:57Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Thank you for the great repository!

I’m currently working on a driver smoking detection project. I have trained my model with nearly 5,000 images; however, it mistakenly identifies light glare as a cigarette, due to the similarity in appearance. My model has only one class, labeled ""cigarette."" Could you suggest some modifications to improve its accuracy?@Glenn

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13401/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13401/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13400,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13400/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13400/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13400/events,https://github.com/ultralytics/yolov5/issues/13400,2635563762,I_kwDOD8jP_s6dF4Ly,13400,How to use my GPU GeForce 920M with YoloV5,"{'login': 'henriquerubio', 'id': 47529189, 'node_id': 'MDQ6VXNlcjQ3NTI5MTg5', 'avatar_url': 'https://avatars.githubusercontent.com/u/47529189?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/henriquerubio', 'html_url': 'https://github.com/henriquerubio', 'followers_url': 'https://api.github.com/users/henriquerubio/followers', 'following_url': 'https://api.github.com/users/henriquerubio/following{/other_user}', 'gists_url': 'https://api.github.com/users/henriquerubio/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/henriquerubio/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/henriquerubio/subscriptions', 'organizations_url': 'https://api.github.com/users/henriquerubio/orgs', 'repos_url': 'https://api.github.com/users/henriquerubio/repos', 'events_url': 'https://api.github.com/users/henriquerubio/events{/privacy}', 'received_events_url': 'https://api.github.com/users/henriquerubio/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2597366614, 'node_id': 'MDU6TGFiZWwyNTk3MzY2NjE0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/dependencies', 'name': 'dependencies', 'color': 'C7E824', 'default': False, 'description': 'Dependencies and packages'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,9,2024-11-05T14:05:18Z,2024-11-10T00:31:54Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

Hi, I have a GPU GeForce 920M, but I can't use it. I can run inference with CPU, but it doesn't woork with my GPU.

python detect.py --weights yolov5s.pt --source 0 --device cpu --> works well (image ""cpu"")
python detect.py --weights yolov5s.pt --source 0 --> ERROR (described bellow) (image ""gpu"")

- I have a GPU GeForce 920m, with 425.31 driver version (25.21.14.2531).
- The most up-to-date version of the ""CUDA compatible with my driver is the version: CUDA 10.1 (https://docs.nvidia.com/deploy/cuda-compatibility)
- To install the ""CUDA 10.1 I need Microsoft Visual Studio 2017. Installed!

All required packages are up to date, according to the ""Requirements.TXT"" from Yolov5 (""Requirements"" and ""Piplist"" images)
When I test the cuda and the GPU it seems to me to be right (image ""cuda-test"")

Do you think the current versions of Pytorch and Torchvision are incorrectly with GeForce 920m? Should I try to reinstall the Pytorch and Cuda?
I think if I try to execute Yolov5 with a version of Pytorch that is best suited for older GPUs, such as Pytorch 1.7 or 1.6 (which may be more compatible with my GPU), I will have to change yolo version to one Lower version than yolov5, right? I say this because in the ""Requirements"" is said ""Torch> = 1.8.0""

IMAGES:
""cpu""
![cpu](https://github.com/user-attachments/assets/4b190888-e13d-4cb2-84fd-aac8b2b7fd92)

""gpu""
![gpu](https://github.com/user-attachments/assets/9a224e70-e03d-44d0-84ff-9b25ad12e562)

""yolov5requirements""
![yolov5requirements](https://github.com/user-attachments/assets/87d68c8b-45c5-4be8-991f-93d411194056)

""pip list""
![pip list](https://github.com/user-attachments/assets/8c4cd4ee-84db-419c-956a-acad1ce42395)

""NVIDIA-SMI""
![NVIDIA-SMI](https://github.com/user-attachments/assets/68dac1b2-37fb-43de-a5b8-deea6545c2bb)

""cuda-test""
![cuda-test](https://github.com/user-attachments/assets/a79163fa-1bf1-4e10-86fa-68e488715d19)

### Environment

- YOLOv5
- Windows 10
- opencv-python: 4.10.0.84
- torch: 1.8.0+cu101
- torchvision: 0.9.0+cu101
- Python 3.9.5
- CUDA 10.1

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13400/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13400/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13399,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13399/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13399/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13399/events,https://github.com/ultralytics/yolov5/issues/13399,2634710009,I_kwDOD8jP_s6dCnv5,13399,why different optimizer train get different result,"{'login': 'tank1530532', 'id': 50346534, 'node_id': 'MDQ6VXNlcjUwMzQ2NTM0', 'avatar_url': 'https://avatars.githubusercontent.com/u/50346534?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/tank1530532', 'html_url': 'https://github.com/tank1530532', 'followers_url': 'https://api.github.com/users/tank1530532/followers', 'following_url': 'https://api.github.com/users/tank1530532/following{/other_user}', 'gists_url': 'https://api.github.com/users/tank1530532/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/tank1530532/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/tank1530532/subscriptions', 'organizations_url': 'https://api.github.com/users/tank1530532/orgs', 'repos_url': 'https://api.github.com/users/tank1530532/repos', 'events_url': 'https://api.github.com/users/tank1530532/events{/privacy}', 'received_events_url': 'https://api.github.com/users/tank1530532/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-11-05T07:58:32Z,2024-11-09T14:04:13Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

pertrain weights: yolov5s.pt
dataset: coco-2017 with below classes
classes:[0:person,1:car,2:motorcycle,3:bus,4:truck]
optimizer: SGD-redline Adam-blueline

I train yolov5 model with 2 different optimizes and I got two different results . Why this two results lookes like this?

### Additional

![image](https://github.com/user-attachments/assets/28568651-989e-4213-b041-c08876ee8be2)
![image](https://github.com/user-attachments/assets/3c4e3774-0388-40ed-9099-c51fa0b4d5ee)
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13399/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13399/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13398,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13398/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13398/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13398/events,https://github.com/ultralytics/yolov5/issues/13398,2631171528,I_kwDOD8jP_s6c1H3I,13398,error,"{'login': 'ShadyIskander', 'id': 175615415, 'node_id': 'U_kgDOCnettw', 'avatar_url': 'https://avatars.githubusercontent.com/u/175615415?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ShadyIskander', 'html_url': 'https://github.com/ShadyIskander', 'followers_url': 'https://api.github.com/users/ShadyIskander/followers', 'following_url': 'https://api.github.com/users/ShadyIskander/following{/other_user}', 'gists_url': 'https://api.github.com/users/ShadyIskander/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ShadyIskander/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ShadyIskander/subscriptions', 'organizations_url': 'https://api.github.com/users/ShadyIskander/orgs', 'repos_url': 'https://api.github.com/users/ShadyIskander/repos', 'events_url': 'https://api.github.com/users/ShadyIskander/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ShadyIskander/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,2,2024-11-03T12:09:36Z,2024-11-09T02:24:02Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

PythonTLSSnapshot: registered at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\core\PythonFallbackKernel.cpp:161 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\functorch\DynamicLayer.cpp:493 [backend fallback]
PreDispatch: registered at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\core\PythonFallbackKernel.cpp:165 [backend fallback]
PythonDispatcher: registered at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\core\PythonFallbackKernel.cpp:157 [backend fallback]

### Environment

_No response_

### Minimal Reproducible Example

issue

### Additional

m

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13398/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13398/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13396,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13396/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13396/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13396/events,https://github.com/ultralytics/yolov5/issues/13396,2629907996,I_kwDOD8jP_s6cwTYc,13396,How to read yolo11 tflite output tensor,"{'login': 'francesco-clementi-92', 'id': 30288622, 'node_id': 'MDQ6VXNlcjMwMjg4NjIy', 'avatar_url': 'https://avatars.githubusercontent.com/u/30288622?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/francesco-clementi-92', 'html_url': 'https://github.com/francesco-clementi-92', 'followers_url': 'https://api.github.com/users/francesco-clementi-92/followers', 'following_url': 'https://api.github.com/users/francesco-clementi-92/following{/other_user}', 'gists_url': 'https://api.github.com/users/francesco-clementi-92/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/francesco-clementi-92/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/francesco-clementi-92/subscriptions', 'organizations_url': 'https://api.github.com/users/francesco-clementi-92/orgs', 'repos_url': 'https://api.github.com/users/francesco-clementi-92/repos', 'events_url': 'https://api.github.com/users/francesco-clementi-92/events{/privacy}', 'received_events_url': 'https://api.github.com/users/francesco-clementi-92/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689206, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqd9g', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/exports', 'name': 'exports', 'color': 'BC5A2A', 'default': False, 'description': 'Model exports (ONNX, TensorRT, TFLite, etc.)'}]",open,False,,[],,18,2024-11-01T21:34:46Z,2024-11-30T14:38:47Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I read every online post on how to decode yolo tflite output tensor data.
My current setup is react-native + react-native-vision-camera + vision-camera-resize-plugin + react-native-fast-tflite.

I have done the training of a yolo11n models on a custom dataset and generated first an int8 with nms tflite model, then only an int8, then a simple tflite, but with each one of them my life is getting harder and harder. I cannot use ultralytics on javascript so I need to decode manually the output.

Currenlty I'm trying to run my model which as:
input: tensor: float32[1,320,320,3]
output: tensor: float32[1,5,2100]

So no quantization applied.
Resizing the frame is as easy as doing:
```
resize(frame, {
          scale: {
            width: 320,
            height: 320
          },
          pixelFormat: 'rgb',
          dataType: 'float32'
        });
```

Then I run the tflite model:
`const outputTensor = model.runSync([data]);`

Now the hardest part.

My model has only one class.

From the output, I understand that there is one input batch (1), 5 detection attributes `[x, y, width, height, confidence]` and 2100 detection candidates.

I don't know why, but it seems that the output is a one dimensional array.

If I only focus on the confidence with this code:
```
for (let i = 0; i < output[0].length; i += 5) {
          const confidence = predictions[i+4];
}
```
I get confidence score bigger than 1, so it's not possible.

Any help would be appreciated :) 
 


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13396/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13396/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13395,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13395/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13395/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13395/events,https://github.com/ultralytics/yolov5/issues/13395,2628989619,I_kwDOD8jP_s6cszKz,13395,Why is there a  memory overflow when the total gpu memory is 12g and each batch uses 4.5g,"{'login': 'heyxhh', 'id': 43626627, 'node_id': 'MDQ6VXNlcjQzNjI2NjI3', 'avatar_url': 'https://avatars.githubusercontent.com/u/43626627?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/heyxhh', 'html_url': 'https://github.com/heyxhh', 'followers_url': 'https://api.github.com/users/heyxhh/followers', 'following_url': 'https://api.github.com/users/heyxhh/following{/other_user}', 'gists_url': 'https://api.github.com/users/heyxhh/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/heyxhh/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/heyxhh/subscriptions', 'organizations_url': 'https://api.github.com/users/heyxhh/orgs', 'repos_url': 'https://api.github.com/users/heyxhh/repos', 'events_url': 'https://api.github.com/users/heyxhh/events{/privacy}', 'received_events_url': 'https://api.github.com/users/heyxhh/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-11-01T13:01:08Z,2024-11-09T07:25:55Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello，I tried to train YOLO V5 with config ""imgsz=640, batch_size=16"", there was no problem in the first two training epochs, but a gpu memory overflow occurred during the loading of data in the third epoch. The total gpu memory is 12g and each batch uses 4.5g, may I ask what could be the reason for this, The details of the problem can be seen in the screenshot。

![ques](https://github.com/user-attachments/assets/d5dbcf33-2669-4cbf-8038-575a9ba44e10)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13395/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13395/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13390,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13390/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13390/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13390/events,https://github.com/ultralytics/yolov5/issues/13390,2619092601,I_kwDOD8jP_s6cHC55,13390,"training ""Memory Error"" on Window","{'login': 'suws0501', 'id': 160751576, 'node_id': 'U_kgDOCZTf2A', 'avatar_url': 'https://avatars.githubusercontent.com/u/160751576?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/suws0501', 'html_url': 'https://github.com/suws0501', 'followers_url': 'https://api.github.com/users/suws0501/followers', 'following_url': 'https://api.github.com/users/suws0501/following{/other_user}', 'gists_url': 'https://api.github.com/users/suws0501/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/suws0501/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/suws0501/subscriptions', 'organizations_url': 'https://api.github.com/users/suws0501/orgs', 'repos_url': 'https://api.github.com/users/suws0501/repos', 'events_url': 'https://api.github.com/users/suws0501/events{/privacy}', 'received_events_url': 'https://api.github.com/users/suws0501/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,2,2024-10-28T17:41:57Z,2024-11-09T13:10:21Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

I tried to run the training app of yours on my Window machine. it has just loaded some stuffs, moving stuffs around, a few caches... then it crashed. 

`(yolo) C:\Users\baoth\OneDrive\Desktop\yolo\yolov5>python train.py --epochs 10 --img 640 --batch 16 --data ../data.yaml --weights yolov5s.pt
train: weights=yolov5s.pt, cfg=, data=../data.yaml, hyp=data\hyps\hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=Fal
se, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, devic
e=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_s
moothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github: up to date with https://github.com/ultralytics/yolov5 
YOLOv5  v7.0-378-g2f74455a Python-3.12.4 torch-2.5.0+cpu CPU

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1
.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
Comet: run 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet
TensorBoard: Start with 'tensorboard --logdir runs\train', view at http://localhost:6006/
Overriding model.yaml nc=80 with nc=3

                 from  n    params  module                                  arguments
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  4                -1  2    115712  models.common.C3                        [128, 128, 2]
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]
 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          
 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs

Transferred 343/349 items from yolov5s.pt
optimizer: SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias
train: Scanning C:\Users\baoth\OneDrive\Desktop\yolo\train\labels.cache... 996 images, 0 backgrounds, 0 corrupt: 100%|██████████| 996/996 [00:00<?, ?it/s]
val: Scanning C:\Users\baoth\OneDrive\Desktop\yolo\valid\labels.cache... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<?, ?it/s]
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\baoth\miniconda3\Lib\multiprocessing\spawn.py"", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\baoth\miniconda3\Lib\multiprocessing\spawn.py"", line 131, in _main
    prepare(preparation_data)
  File ""C:\Users\baoth\miniconda3\Lib\multiprocessing\spawn.py"", line 246, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File ""C:\Users\baoth\miniconda3\Lib\multiprocessing\spawn.py"", line 297, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<frozen runpy>"", line 286, in run_path
  File ""<frozen runpy>"", line 98, in _run_module_code
  File ""<frozen runpy>"", line 88, in _run_code
  File ""C:\Users\baoth\OneDrive\Desktop\yolo\yolov5\train.py"", line 47, in <module>
    import val as validate  # for end-of-epoch mAP
    ^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\baoth\OneDrive\Desktop\yolo\yolov5\val.py"", line 60, in <module>
    from utils.plots import output_to_target, plot_images, plot_val_study
  File ""C:\Users\baoth\OneDrive\Desktop\yolo\yolov5\utils\plots.py"", line 15, in <module>
    import seaborn as sn
  File ""C:\Users\baoth\miniconda3\Lib\site-packages\seaborn\__init__.py"", line 7, in <module>
    from .categorical import *  # noqa: F401,F403
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\baoth\miniconda3\Lib\site-packages\seaborn\categorical.py"", line 19, in <module>
    from seaborn._stats.density import KDE
  File ""C:\Users\baoth\miniconda3\Lib\site-packages\seaborn\_stats\density.py"", line 10, in <module>
    from scipy.stats import gaussian_kde
  File ""C:\Users\baoth\miniconda3\Lib\site-packages\scipy\stats\__init__.py"", line 610, in <module>
    from ._stats_py import *
  File ""<frozen importlib._bootstrap>"", line 1360, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1331, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 935, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 991, in exec_module
  File ""<frozen importlib._bootstrap_external>"", line 1087, in get_code
  File ""<frozen importlib._bootstrap_external>"", line 1187, in get_data
MemoryError
`

### Environment

yolov5s, Window, no cuda

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13390/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13390/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13389,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13389/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13389/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13389/events,https://github.com/ultralytics/yolov5/issues/13389,2619050105,I_kwDOD8jP_s6cG4h5,13389,how to reduce false postives in yolov5,"{'login': 'yAlqubati', 'id': 131190230, 'node_id': 'U_kgDOB9HN1g', 'avatar_url': 'https://avatars.githubusercontent.com/u/131190230?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/yAlqubati', 'html_url': 'https://github.com/yAlqubati', 'followers_url': 'https://api.github.com/users/yAlqubati/followers', 'following_url': 'https://api.github.com/users/yAlqubati/following{/other_user}', 'gists_url': 'https://api.github.com/users/yAlqubati/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/yAlqubati/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/yAlqubati/subscriptions', 'organizations_url': 'https://api.github.com/users/yAlqubati/orgs', 'repos_url': 'https://api.github.com/users/yAlqubati/repos', 'events_url': 'https://api.github.com/users/yAlqubati/events{/privacy}', 'received_events_url': 'https://api.github.com/users/yAlqubati/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 7663689091, 'node_id': 'LA_kwDOD8jP_s8AAAAByMqdgw', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/detect', 'name': 'detect', 'color': '8054FD', 'default': False, 'description': ""Object Detection issues, PR's""}]",open,False,,[],,2,2024-10-28T17:26:18Z,2024-11-09T01:07:51Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello everyone,

I'm currently training YOLOv5s to detect three objects: phone, cigarette, and vape. My original dataset contained 9,000 images, with 3,000 images for each class. After training the model for 100 epochs, I've noticed a high number of false positives.

To address this, I've added 3,000 negative images (images that don't contain any of the target objects) to the dataset. I've also experimented with adjusting the conf_thres and iou_thres settings a bit. I plan to train the model for more epochs in the future.

Are there any additional strategies or techniques you recommend to further reduce the number of false positives? Any insights would be greatly appreciated!

thanks in advance.

### Additional

training info
pochs 100, --img-size 640, --batch-size 16, --optimizer SGD --cache ram --hyp /content/yolov5/data/hyps/hyp.scratch-low.yaml

the content of hyp.scratch-low.yaml file is set to default

",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13389/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13389/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13387,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13387/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13387/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13387/events,https://github.com/ultralytics/yolov5/issues/13387,2616191942,I_kwDOD8jP_s6b7-vG,13387,Negative weights when using Macbook M1 with MPS,"{'login': 'guybashan', 'id': 3739222, 'node_id': 'MDQ6VXNlcjM3MzkyMjI=', 'avatar_url': 'https://avatars.githubusercontent.com/u/3739222?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/guybashan', 'html_url': 'https://github.com/guybashan', 'followers_url': 'https://api.github.com/users/guybashan/followers', 'following_url': 'https://api.github.com/users/guybashan/following{/other_user}', 'gists_url': 'https://api.github.com/users/guybashan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/guybashan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/guybashan/subscriptions', 'organizations_url': 'https://api.github.com/users/guybashan/orgs', 'repos_url': 'https://api.github.com/users/guybashan/repos', 'events_url': 'https://api.github.com/users/guybashan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/guybashan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,4,2024-10-26T22:48:07Z,2024-11-11T16:14:24Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Detection

### Bug

Hi,

Indeed I am using the latest code from git (main branch).
I re-run the training using this:
/cam-analyzer/pytorch_metal_env/bin/python ../yolov5/train.py --img 416 --batch 16 --epochs 100 --data ../yolo_cfg/data.yaml --weights yolov5m.pt --device mps
I re-checked my ""train"" and ""val"" folders. They look ok and the files look fine. I created the labels using YoloLabel app (open source).
I run the detection using this command:
/cam-analyzer/pytorch_metal_env/bin/python detect.py --save-txt --save-conf --weights /Users/user/Documents/dev/yolo_model/cam_analyzer/weights/best.pt --source /Users/user/Documents/dev/yolo_images --conf 0.1 --project /Users/columbo/Documents/dev/yolo_results --name detections --device mps
I use M1 Max with 64GB memory
I enabled working with GPU

### Environment

- Yolo 5
- Python 3.13.0

### Minimal Reproducible Example

`/cam-analyzer/pytorch_metal_env/bin/python detect.py --save-txt --save-conf --weights /Users/user/Documents/dev/yolo_model/cam_analyzer/weights/best.pt --source /Users/user/Documents/dev/yolo_images --conf 0.1 --project /Users/columbo/Documents/dev/yolo_results --name detections --device mps`

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13387/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13387/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13383,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13383/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13383/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13383/events,https://github.com/ultralytics/yolov5/pull/13383,2612175482,PR_kwDOD8jP_s5_zgC0,13383,Project Proposal and Pseudocode,"{'login': '1259xcdh', 'id': 131236160, 'node_id': 'U_kgDOB9KBQA', 'avatar_url': 'https://avatars.githubusercontent.com/u/131236160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/1259xcdh', 'html_url': 'https://github.com/1259xcdh', 'followers_url': 'https://api.github.com/users/1259xcdh/followers', 'following_url': 'https://api.github.com/users/1259xcdh/following{/other_user}', 'gists_url': 'https://api.github.com/users/1259xcdh/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/1259xcdh/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/1259xcdh/subscriptions', 'organizations_url': 'https://api.github.com/users/1259xcdh/orgs', 'repos_url': 'https://api.github.com/users/1259xcdh/repos', 'events_url': 'https://api.github.com/users/1259xcdh/events{/privacy}', 'received_events_url': 'https://api.github.com/users/1259xcdh/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,,[],,3,2024-10-24T17:26:10Z,2024-10-24T23:07:43Z,,NONE,,"Fixes #13381 

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
A new project proposal introduces the integration of YOLOv5 with AI for automated text recognition and conversion, including text-to-image generation.

### 📊 Key Changes
- **Project Proposal**: A comprehensive proposal outlining a system to detect, recognize, and convert text using YOLOv5 integrated with AI-driven OCR and text-to-image models.
- **Pseudocode Added**: A basic implementation outline for the system's main functions, covering text detection, OCR, and optional text-to-image generation.

### 🎯 Purpose & Impact
- **Enhanced Text Processing**: Enables real-time text detection and conversion into editable formats, useful across multiple industries like education and legal.
- **Interactive Visualizations**: Introduces text-to-image generation, adding a creative way to visualize text, thereby enhancing accessibility and engagement.
- **Improved Accessibility**: Supports diverse applications, including aiding visually impaired users by converting text into image-based formats for easier comprehension.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13383/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13383/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13383', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13383', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13383.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13383.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13381,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13381/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13381/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13381/events,https://github.com/ultralytics/yolov5/issues/13381,2612134455,I_kwDOD8jP_s6bsgI3,13381,Implementing image text recognition and automatic conversion based on YOLOv5 combined with AI technology,"{'login': '1259xcdh', 'id': 131236160, 'node_id': 'U_kgDOB9KBQA', 'avatar_url': 'https://avatars.githubusercontent.com/u/131236160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/1259xcdh', 'html_url': 'https://github.com/1259xcdh', 'followers_url': 'https://api.github.com/users/1259xcdh/followers', 'following_url': 'https://api.github.com/users/1259xcdh/following{/other_user}', 'gists_url': 'https://api.github.com/users/1259xcdh/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/1259xcdh/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/1259xcdh/subscriptions', 'organizations_url': 'https://api.github.com/users/1259xcdh/orgs', 'repos_url': 'https://api.github.com/users/1259xcdh/repos', 'events_url': 'https://api.github.com/users/1259xcdh/events{/privacy}', 'received_events_url': 'https://api.github.com/users/1259xcdh/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,,[],,2,2024-10-24T17:03:33Z,2024-11-09T13:14:27Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

The ability to automatically recognize and convert text from images into text or even images will greatly enhance the efficiency of intelligent systems in document processing, visual search, and information acquisition. By using image generation models (such as GAN), the recognized text content is regenerated into images that meet specific formatting and style requirements.

### Use case

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13381/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13381/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13380,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13380/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13380/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13380/events,https://github.com/ultralytics/yolov5/issues/13380,2611246835,I_kwDOD8jP_s6bpHbz,13380,realtime detection on jetson using pi camera ,"{'login': 'Munia-AK', 'id': 45848859, 'node_id': 'MDQ6VXNlcjQ1ODQ4ODU5', 'avatar_url': 'https://avatars.githubusercontent.com/u/45848859?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Munia-AK', 'html_url': 'https://github.com/Munia-AK', 'followers_url': 'https://api.github.com/users/Munia-AK/followers', 'following_url': 'https://api.github.com/users/Munia-AK/following{/other_user}', 'gists_url': 'https://api.github.com/users/Munia-AK/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Munia-AK/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Munia-AK/subscriptions', 'organizations_url': 'https://api.github.com/users/Munia-AK/orgs', 'repos_url': 'https://api.github.com/users/Munia-AK/repos', 'events_url': 'https://api.github.com/users/Munia-AK/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Munia-AK/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-24T11:13:52Z,2024-11-09T08:49:58Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I'm trying to run real time detection on jetson nano using custom fine tuned yolov5s model and pi camera. I already did this using below script which worked:
![Screenshot from 2024-10-24 11-57-39](https://github.com/user-attachments/assets/2376c9b4-9699-4406-89db-640f8ef2425e)

However I don't want to use torch.hub for loading the model because it requires internet connection. I need to make it work without internet. I tried in the same code to load the model from it's path without using torch.hub.load, for example:
**model = 'best.py'**
and then send each frame as input directly like: **results = model(frame)**
but this didn't work and gave error

I know the solution lies in the detect.py script. I ran the detect.py script with webcam on jetson nano without internet connection and it worked.
So, I made two attempts, in first attempt I used same previous code but took the parts of loading the model from detect.py and added them to the code to replace torch.hub.load, like this:
![Screenshot from 2024-10-24 13-25-05](https://github.com/user-attachments/assets/4ea0fe9f-e9c6-475b-b0dd-d57b4ed708c1)

but this gave this error too that I wasn't able to fix in the end:
  _File ""detect__.py"", line 71, in <module>
	result_img = result.render()[0]  # Render the detection and get the image
AttributeError: 'Tensor' object has no attribute 'render_

In the second try I was editing the detect.script attempting to add the command that runs the pi camera using GStreamer pipeline. Specifically I edited the following three parts believing that I should edit the webcam sections by making the code runs pi camera instead of webcam when --source 0 is chosen.:
after editing:

**part 1:**
def run(
    weights=ROOT / ""yolov5s.pt"",  # model path or triton URL
    source = ""nvarguscamerasrc ! video/x-raw(memory:NVMM), width=(int)1280, height=(int)720, format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv flip-method=0 ! video/x-raw, width=(int)1280, height=(int)720, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink""
.
.
.
**part 2:**
![Screenshot from 2024-10-24 11-58-50](https://github.com/user-attachments/assets/e990c287-c26d-4c65-a0e2-4fe6dc10992e)

**part 3:**
![Screenshot from 2024-10-24 12-13-08](https://github.com/user-attachments/assets/b0717b28-fb9e-44f6-a7be-f0d0aab30f96)

but this didn't work and threw an error.

![Screenshot from 2024-10-24 13-01-49](https://github.com/user-attachments/assets/676a7294-9883-4eb8-9511-2cfec71695b2)

I couldn't fix any of the errors of all attempts. So I'm not sure whether I'm following the right path but if this is doable then can you please guide me onto how to make pi camera do the detection without using torch.hub.load

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13380/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13380/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13379,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13379/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13379/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13379/events,https://github.com/ultralytics/yolov5/issues/13379,2610572021,I_kwDOD8jP_s6bmir1,13379,How to use a second GPU outside of the default GPU on yolov5?,"{'login': 'ijnrghjkdsmigywneig203', 'id': 105937945, 'node_id': 'U_kgDOBlB8GQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/105937945?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ijnrghjkdsmigywneig203', 'html_url': 'https://github.com/ijnrghjkdsmigywneig203', 'followers_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/followers', 'following_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/following{/other_user}', 'gists_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/subscriptions', 'organizations_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/orgs', 'repos_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/repos', 'events_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ijnrghjkdsmigywneig203/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-24T06:09:36Z,2024-11-09T13:27:17Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have tried doing torch.cuda.set_device and self.model.to(device), etc... None of it seems to work. It always defaults to main GPU.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13379/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13379/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13378,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13378/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13378/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13378/events,https://github.com/ultralytics/yolov5/issues/13378,2610253081,I_kwDOD8jP_s6blU0Z,13378,Continue training,"{'login': 'pjh11214', 'id': 164312706, 'node_id': 'U_kgDOCcs2gg', 'avatar_url': 'https://avatars.githubusercontent.com/u/164312706?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/pjh11214', 'html_url': 'https://github.com/pjh11214', 'followers_url': 'https://api.github.com/users/pjh11214/followers', 'following_url': 'https://api.github.com/users/pjh11214/following{/other_user}', 'gists_url': 'https://api.github.com/users/pjh11214/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/pjh11214/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/pjh11214/subscriptions', 'organizations_url': 'https://api.github.com/users/pjh11214/orgs', 'repos_url': 'https://api.github.com/users/pjh11214/repos', 'events_url': 'https://api.github.com/users/pjh11214/events{/privacy}', 'received_events_url': 'https://api.github.com/users/pjh11214/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-24T02:41:42Z,2024-11-09T12:35:26Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

How to continue training on the basis of already trained models

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13378/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13378/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13376,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13376/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13376/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13376/events,https://github.com/ultralytics/yolov5/issues/13376,2609333610,I_kwDOD8jP_s6bh0Vq,13376,pycharm에서의 yolov5 실시간 카메라 실행 문제,"{'login': 'JepeJa', 'id': 170074199, 'node_id': 'U_kgDOCiMgVw', 'avatar_url': 'https://avatars.githubusercontent.com/u/170074199?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/JepeJa', 'html_url': 'https://github.com/JepeJa', 'followers_url': 'https://api.github.com/users/JepeJa/followers', 'following_url': 'https://api.github.com/users/JepeJa/following{/other_user}', 'gists_url': 'https://api.github.com/users/JepeJa/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/JepeJa/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/JepeJa/subscriptions', 'organizations_url': 'https://api.github.com/users/JepeJa/orgs', 'repos_url': 'https://api.github.com/users/JepeJa/repos', 'events_url': 'https://api.github.com/users/JepeJa/events{/privacy}', 'received_events_url': 'https://api.github.com/users/JepeJa/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-23T17:28:37Z,2024-11-09T00:41:42Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

colab에서 yolov5를 딥러닝 후 best.pt 파일을 yolov5 폴더에 다운로드 받아 pycharm에서 yolov5 파일을 열었습니다. 그리고 실시간 인식을 하기 위해 터미널에 python detect.py --weights best.py --conf 0.5 --img 416 --source 0을 입력하였는데
AssertionError: best.py acceptable suffix is ['.pt', '.torchscript', '.onnx', '_openvino_model', '.engine', '.mlpackage', '_saved_model', '.pb', '.tflite', '_edgetpu.tflite', '_web_model', '_paddle_model']
이렇게 오류문자가 뜹니다. 저는 코딩을 잘 할 줄 몰라서 유튜브에서 알려주는 대로 밖에 할 수 없습니다. 제가 따라한 유튜브 링크는https://www.youtube.com/watch?v=U-wkRQ8U3GE 입니다.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13376/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13376/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13375,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13375/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13375/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13375/events,https://github.com/ultralytics/yolov5/issues/13375,2607757551,I_kwDOD8jP_s6bbzjv,13375,tflite,"{'login': 'motesz', 'id': 138199370, 'node_id': 'U_kgDOCDzBSg', 'avatar_url': 'https://avatars.githubusercontent.com/u/138199370?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/motesz', 'html_url': 'https://github.com/motesz', 'followers_url': 'https://api.github.com/users/motesz/followers', 'following_url': 'https://api.github.com/users/motesz/following{/other_user}', 'gists_url': 'https://api.github.com/users/motesz/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/motesz/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/motesz/subscriptions', 'organizations_url': 'https://api.github.com/users/motesz/orgs', 'repos_url': 'https://api.github.com/users/motesz/repos', 'events_url': 'https://api.github.com/users/motesz/events{/privacy}', 'received_events_url': 'https://api.github.com/users/motesz/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-23T08:39:48Z,2024-11-09T12:04:28Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

how can i export yolov5s into tflite

### Use case

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13375/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13375/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13373,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13373/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13373/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13373/events,https://github.com/ultralytics/yolov5/issues/13373,2605698485,I_kwDOD8jP_s6bT821,13373,Doubts about the confusion matrix and YOLO evaluation indicators,"{'login': 'ayitime', 'id': 69344105, 'node_id': 'MDQ6VXNlcjY5MzQ0MTA1', 'avatar_url': 'https://avatars.githubusercontent.com/u/69344105?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ayitime', 'html_url': 'https://github.com/ayitime', 'followers_url': 'https://api.github.com/users/ayitime/followers', 'following_url': 'https://api.github.com/users/ayitime/following{/other_user}', 'gists_url': 'https://api.github.com/users/ayitime/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ayitime/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ayitime/subscriptions', 'organizations_url': 'https://api.github.com/users/ayitime/orgs', 'repos_url': 'https://api.github.com/users/ayitime/repos', 'events_url': 'https://api.github.com/users/ayitime/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ayitime/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,6,2024-10-22T14:52:39Z,2024-10-23T10:01:14Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have a computational problem regarding the recall and precision of the model. First of all the dataset I'm training on has a category of 1, and the validation set has a total of 357 ground truth boxes. I tried to look at the console output precision, recall metrics, and the values in the confusion matrix, but I found some ambiguity in both.

The precision and recall printed in the console seem to be the results corresponding to the optimal f1 value when IoU=0.5, and by combining these two values with the number of ground truth frames I can back-calculate the values of tp and fp, which are 179 and 301, respectively. And these two values are supposed to be obtained corresponding to a certain conf threshold, although I don't know the value of that threshold for now.

However when I set the conf threshold of the confusion matrix to 0.3 and iou=0.5, something strange happened. I observed that the tp value of the confusion_matrix is 189 and the fp value is 271. i.e. the tp value of the confusion matrix is greater than the tp value of the console and the fp value of the obfuscation matrix is less than the fp value of the console. If I increase the conf threshold of the confusion matrix, then the tp and fp in the confusion matrix decrease at the same time; similarly if I decrease the conf threshold of the obfuscation matrix, then the tp and fp increase at the same time. But here is the problem, there is no way to change the conf threshold of the confusion matrix to make the tp and fp output of the confusion matrix and the console output equal, so I can't reproduce the tp and fp output of the console through the confusion matrix.

I can't figure out the reason behind this so I'm here to ask, looking forward to your answer!
![1729607251465](https://github.com/user-attachments/assets/506d5f48-fed9-4f90-a325-ed9d56e05975)

![1729607282929](https://github.com/user-attachments/assets/f7c37007-b3ec-4be7-a752-46abc054883b)

![1729607324902](https://github.com/user-attachments/assets/cd5066a3-3fe9-42ef-b0b2-cbdaed0a9481)



### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13373/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13373/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13371,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13371/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13371/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13371/events,https://github.com/ultralytics/yolov5/issues/13371,2603421692,I_kwDOD8jP_s6bLQ_8,13371,Training inside Python 3.12 miniconda environment currently fails with ModuleNotFoundError,"{'login': 'michael-mayo', 'id': 100046142, 'node_id': 'U_kgDOBfaVPg', 'avatar_url': 'https://avatars.githubusercontent.com/u/100046142?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/michael-mayo', 'html_url': 'https://github.com/michael-mayo', 'followers_url': 'https://api.github.com/users/michael-mayo/followers', 'following_url': 'https://api.github.com/users/michael-mayo/following{/other_user}', 'gists_url': 'https://api.github.com/users/michael-mayo/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/michael-mayo/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/michael-mayo/subscriptions', 'organizations_url': 'https://api.github.com/users/michael-mayo/orgs', 'repos_url': 'https://api.github.com/users/michael-mayo/repos', 'events_url': 'https://api.github.com/users/michael-mayo/events{/privacy}', 'received_events_url': 'https://api.github.com/users/michael-mayo/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,9,2024-10-21T19:04:32Z,2024-10-27T13:30:31Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Training, Detection

### Bug

```
$ python train.py --epochs 1
train: weights=yolov5s.pt, cfg=, data=data/coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, bbox_interval=-1, artifact_alias=latest, neptune_token=None, neptune_project=None, neptune_resume_id=None, s3_upload_dir=None, upload_dataset=False, hf_model_id=None, hf_token=None, hf_private=False, hf_dataset_id=None, roboflow_token=None, roboflow_upload=False
requirements: /home/michael/miniconda3/envs/test/lib/python3.12/site-packages/requirements.txt not found, check failed.
YOLOv5 🚀 2024-10-22 Python-3.12.7 torch-2.5.0+cu124 CPU

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0

Dataset not found ⚠️, missing paths ['/home/michael/miniconda3/envs/test/lib/python3.12/site-packages/datasets/coco128/images/train2017']
Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.66M/6.66M [00:00<00:00, 32.9MB/s]
Dataset download success ✅ (2.4s), saved to datasets
ClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML
Comet: run 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet
TensorBoard: Start with 'tensorboard --logdir runs/train', view at http://localhost:6006/
Traceback (most recent call last):
  File ""/home/michael/miniconda3/envs/test/lib/python3.12/site-packages/yolov5/train.py"", line 735, in <module>
    main(opt)
  File ""/home/michael/miniconda3/envs/test/lib/python3.12/site-packages/yolov5/train.py"", line 615, in main
    train(opt.hyp, opt, device, callbacks)
  File ""/home/michael/miniconda3/envs/test/lib/python3.12/site-packages/yolov5/train.py"", line 132, in train
    result = attempt_download_from_hub(weights, hf_token=None)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/michael/miniconda3/envs/test/lib/python3.12/site-packages/yolov5/utils/downloads.py"", line 150, in attempt_download_from_hub
    from huggingface_hub.utils._errors import RepositoryNotFoundError
ModuleNotFoundError: No module named 'huggingface_hub.utils._errors
```

### Environment

- YOLO: 2024-10-22 Python-3.12.7 torch-2.5.0+cu124 CPU
- OS: Ubuntu 20.04.6 LTS running in WSL on Windows 11
- Python: Miniconda env with 3.12

### Minimal Reproducible Example

```
# Install miniconda on linux then do the following:
conda create -n test python=3.12
conda activate test
pip install yolov5
cd `python -c ""import yolov5; print(yolov5.__path__[0])""`
python train.py --epochs 1
```

### Additional

The errror occurs both when training a model and also when trying to load a custom local model using `torch.hub.load`. Error also occurs when running directly on windows, and when I downgrade Pytorch to 2.4. It appears to be caused by the pypi version of yolov5 referencing hugging face modules that no longer exist.

### Are you willing to submit a PR?

- [x] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13371/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13371/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13369,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13369/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13369/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13369/events,https://github.com/ultralytics/yolov5/issues/13369,2601122915,I_kwDOD8jP_s6bCfxj,13369,Training process output,"{'login': 'rongvang17', 'id': 123542803, 'node_id': 'U_kgDOB10dEw', 'avatar_url': 'https://avatars.githubusercontent.com/u/123542803?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/rongvang17', 'html_url': 'https://github.com/rongvang17', 'followers_url': 'https://api.github.com/users/rongvang17/followers', 'following_url': 'https://api.github.com/users/rongvang17/following{/other_user}', 'gists_url': 'https://api.github.com/users/rongvang17/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/rongvang17/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/rongvang17/subscriptions', 'organizations_url': 'https://api.github.com/users/rongvang17/orgs', 'repos_url': 'https://api.github.com/users/rongvang17/repos', 'events_url': 'https://api.github.com/users/rongvang17/events{/privacy}', 'received_events_url': 'https://api.github.com/users/rongvang17/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-10-21T02:32:58Z,2024-10-21T16:09:16Z,,NONE,,,,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13369/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13369/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13367,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13367/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13367/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13367/events,https://github.com/ultralytics/yolov5/issues/13367,2597186539,I_kwDOD8jP_s6azevr,13367,Issue using PaddleDetection's YOLOv5 model in val.py after converting to ONNX - Error with scale_factor,"{'login': 'gauricollab09', 'id': 90369386, 'node_id': 'MDQ6VXNlcjkwMzY5Mzg2', 'avatar_url': 'https://avatars.githubusercontent.com/u/90369386?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/gauricollab09', 'html_url': 'https://github.com/gauricollab09', 'followers_url': 'https://api.github.com/users/gauricollab09/followers', 'following_url': 'https://api.github.com/users/gauricollab09/following{/other_user}', 'gists_url': 'https://api.github.com/users/gauricollab09/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/gauricollab09/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/gauricollab09/subscriptions', 'organizations_url': 'https://api.github.com/users/gauricollab09/orgs', 'repos_url': 'https://api.github.com/users/gauricollab09/repos', 'events_url': 'https://api.github.com/users/gauricollab09/events{/privacy}', 'received_events_url': 'https://api.github.com/users/gauricollab09/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,3,2024-10-18T10:49:05Z,2024-10-22T14:13:10Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi all,

I'm working with a YOLOE plus model from PaddleDetection and trying to use its .pdparams weights in the val.py script. My process involves converting the Paddle model to ONNX and then using .onnx model for validation. (I wanted to use val.py from this repo as I want to compare some of my previous results with the yoloe plus). However, I am encountering an issue related to scale_factor during this process.

Issue Details:
Model: YOLOv5 from PaddleDetection (weights in .pdparams format).
Error: The script throws an error related to scale_factor.
![image](https://github.com/user-attachments/assets/40232bdc-f861-4f6a-b32e-17ba4be84ad2)

Environment:
PaddleDetection version: 3.0.0-betal
PaddlePaddle version: release/2.5

Question:
Is there any known compatibility issue or additional steps required when using a PaddleDetection YOLOv5 model converted to ONNX with scale_factor in the val.py script? How should I adjust the scale_factor parameter properly in the val.py scenario to ensure correct evaluation?

Any guidance or suggestions would be greatly appreciated!

Thanks in advance.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13367/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13367/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13364,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13364/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13364/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13364/events,https://github.com/ultralytics/yolov5/issues/13364,2593945482,I_kwDOD8jP_s6anHeK,13364,没有打印精度在每个epoch结束，val的时候也有相同的情况,"{'login': 'tong1311', 'id': 67692069, 'node_id': 'MDQ6VXNlcjY3NjkyMDY5', 'avatar_url': 'https://avatars.githubusercontent.com/u/67692069?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/tong1311', 'html_url': 'https://github.com/tong1311', 'followers_url': 'https://api.github.com/users/tong1311/followers', 'following_url': 'https://api.github.com/users/tong1311/following{/other_user}', 'gists_url': 'https://api.github.com/users/tong1311/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/tong1311/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/tong1311/subscriptions', 'organizations_url': 'https://api.github.com/users/tong1311/orgs', 'repos_url': 'https://api.github.com/users/tong1311/repos', 'events_url': 'https://api.github.com/users/tong1311/events{/privacy}', 'received_events_url': 'https://api.github.com/users/tong1311/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-10-17T07:58:47Z,2024-10-17T10:05:20Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

![Screenshot from 2024-10-16 22-18-33](https://github.com/user-attachments/assets/71f2c728-14d8-4ba1-b59b-a0e7b96d582e)


### Additional

可能和环境中某个库的版本有关系？
name: yolov5
channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
  - defaults
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=2_gnu
  - bzip2=1.0.8=h4bc722e_7
  - ca-certificates=2024.7.4=hbcca054_0
  - ld_impl_linux-64=2.40=hf3520f5_7
  - libffi=3.4.2=h7f98852_5
  - libgcc-ng=14.1.0=h77fa898_0
  - libgomp=14.1.0=h77fa898_0
  - libnsl=2.0.1=hd590300_0
  - libsqlite=3.46.0=hde9e2c9_0
  - libuuid=2.38.1=h0b41bf4_0
  - libxcrypt=4.4.36=hd590300_1
  - libzlib=1.3.1=h4ab18f5_1
  - ncurses=6.5=h59595ed_0
  - openssl=3.3.1=h4bc722e_2
  - pip=24.0=pyhd8ed1ab_0
  - python=3.8.19=hd12c33a_0_cpython
  - readline=8.2=h8228510_1
  - setuptools=71.0.4=pyhd8ed1ab_0
  - tk=8.6.13=noxft_h4845f30_101
  - wheel=0.43.0=pyhd8ed1ab_1
  - xz=5.2.6=h166bdaf_0
  - pip:
      - absl-py==2.1.0
      - asttokens==2.4.1
      - backcall==0.2.0
      - cachetools==5.4.0
      - certifi==2022.12.7
      - charset-normalizer==2.1.1
      - cmake==3.25.0
      - contourpy==1.1.1
      - cycler==0.12.1
      - decorator==5.1.1
      - executing==2.0.1
      - filelock==3.13.1
      - fonttools==4.53.1
      - google-auth==2.32.0
      - google-auth-oauthlib==1.0.0
      - grpcio==1.65.1
      - idna==3.4
      - importlib-metadata==8.0.0
      - importlib-resources==6.4.0
      - ipython==8.12.3
      - jedi==0.19.1
      - jinja2==3.1.3
      - kiwisolver==1.4.5
      - lit==15.0.7
      - markdown==3.6
      - markupsafe==2.1.5
      - matplotlib==3.7.5
      - matplotlib-inline==0.1.7
      - mpmath==1.3.0
      - networkx==3.0
      - numpy==1.22.0
      - oauthlib==3.2.2
      - opencv-python==4.10.0.84
      - packaging==24.1
      - pandas==2.0.3
      - parso==0.8.4
      - pexpect==4.9.0
      - pickleshare==0.7.5
      - pillow==9.5.0
      - prompt-toolkit==3.0.47
      - protobuf==3.20.1
      - psutil==6.0.0
      - ptyprocess==0.7.0
      - pure-eval==0.2.3
      - pyasn1==0.6.0
      - pyasn1-modules==0.4.0
      - pygments==2.18.0
      - pyparsing==3.1.2
      - python-dateutil==2.9.0.post0
      - pytz==2024.1
      - pyyaml==6.0.1
      - requests==2.28.1
      - requests-oauthlib==2.0.0
      - rsa==4.9
      - scipy==1.10.1
      - seaborn==0.13.2
      - six==1.16.0
      - stack-data==0.6.3
      - sympy==1.12
      - tensorboard==2.14.0
      - tensorboard-data-server==0.7.2
      - thop==0.1.1-2209072238
      - torch==2.0.0+cu118
      - torchaudio==2.0.1+cu118
      - torchvision==0.15.1+cu118
      - tqdm==4.66.4
      - traitlets==5.14.3
      - triton==2.0.0
      - typing-extensions==4.9.0
      - tzdata==2024.1
      - urllib3==1.26.13
      - wcwidth==0.2.13
      - werkzeug==3.0.3
      - zipp==3.19.2
prefix: /home/th/anaconda3/envs/yolov5",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13364/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13364/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13362,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13362/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13362/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13362/events,https://github.com/ultralytics/yolov5/issues/13362,2592202024,I_kwDOD8jP_s6agd0o,13362,"NMS time limit issue on MPS, Works in CPU","{'login': 'shanalikhan', 'id': 8774556, 'node_id': 'MDQ6VXNlcjg3NzQ1NTY=', 'avatar_url': 'https://avatars.githubusercontent.com/u/8774556?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/shanalikhan', 'html_url': 'https://github.com/shanalikhan', 'followers_url': 'https://api.github.com/users/shanalikhan/followers', 'following_url': 'https://api.github.com/users/shanalikhan/following{/other_user}', 'gists_url': 'https://api.github.com/users/shanalikhan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/shanalikhan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/shanalikhan/subscriptions', 'organizations_url': 'https://api.github.com/users/shanalikhan/orgs', 'repos_url': 'https://api.github.com/users/shanalikhan/repos', 'events_url': 'https://api.github.com/users/shanalikhan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/shanalikhan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-10-16T15:14:51Z,2024-10-16T21:54:14Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi, 
I'm using `yolo11n` 

This line works
```
results = model.train(data=""/Users/shan/Documents/iqlogy/047/yolo8obb_2347/yoloobb_main.yaml"", epochs=1, imgsz=512)#,device=""mps"")
```
Generates the following output:

```
train: Scanning [/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/train.cache...](https://file+.vscode-resource.vscode-cdn.net/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/train.cache...) 2117 images, 500 backgrounds, 0 corrupt: 100%|██████████| 2117/2117 [00:00<?, ?it/s]
val: Scanning [/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/test.cache...](https://file+.vscode-resource.vscode-cdn.net/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/test.cache...) 230 images, 60 backgrounds, 0 corrupt: 100%|██████████| 230/230 [00:00<?, ?it/s]
Plotting labels to runs/detect/train132/labels.jpg... 

optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... 
optimizer: AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)
TensorBoard: model graph visualization added ✅
Image sizes 512 train, 512 val
Using 0 dataloader workers
Logging results to runs/detect/train132
Starting training for 1 epochs...

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
        1/1         0G      2.141      1.816      1.171         27        512: 100%|██████████| 133/133 [07:45<00:00,  3.50s/it]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.84s/it]
                   all        230       1052      0.562      0.417       0.43      0.158

1 epochs completed in 0.137 hours.
Optimizer stripped from runs/detect/train132/weights/last.pt, 5.4MB
Optimizer stripped from runs/detect/train132/weights/best.pt, 5.4MB

Validating runs/detect/train132/weights/best.pt...
WARNING ⚠️ validating an untrained model YAML will result in 0 mAP.
Ultralytics 8.3.13 🚀 Python-3.12.7 torch-2.4.0 CPU (Apple M3)
YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.63s/it]
                   all        230       1052      0.564      0.417      0.429      0.157
Speed: 0.4ms preprocess, 86.0ms inference, 0.0ms loss, 0.8ms postprocess per image
Results saved to runs/detect/train132
```



Now converting from CPU to `mps` shows warning `WARNING ⚠️ NMS time limit 3.600s exceeded`

```
results = model.train(data=""/Users/shan/Documents/iqlogy/047/yolo8obb_2347/yoloobb_main.yaml"", epochs=1, imgsz=512, optimizer='SGD',device=""mps"",lr0=0.001,verbose=True)

```
Transferred 448/499 items from pretrained weights
TensorBoard: Start with 'tensorboard --logdir runs/detect/train14', view at http://localhost:6006/
Freezing layer 'model.23.dfl.conv.weight'
train: Scanning [/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/train.cache...](https://file+.vscode-resource.vscode-cdn.net/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/train.cache...) 2117 images, 500 backgrounds, 0 corrupt: 100%|██████████| 2117/2117 [00:00<?, ?it/s]
val: Scanning [/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/test.cache...](https://file+.vscode-resource.vscode-cdn.net/Users/shan/Documents/iqlogy/047/yolo8obb_2347/labels/test.cache...) 230 images, 60 backgrounds, 0 corrupt: 100%|██████████| 230/230 [00:00<?, ?it/s]
Plotting labels to runs/detect/train14/labels.jpg... 
optimizer: SGD(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)
TensorBoard: model graph visualization added ✅
Image sizes 512 train, 512 val
Using 0 dataloader workers
Logging results to runs/detect/train14
Starting training for 1 epochs...

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
        1/1      4.06G      2.419      3.446      1.311         27        512: 100%|██████████| 133/133 [02:19<00:00,  1.05s/it]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/8 [00:00<?, ?it/s]
WARNING ⚠️ NMS time limit 3.600s exceeded
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  12%|█▎        | 1/8 [00:12<01:29, 12.76s/it]
WARNING ⚠️ NMS time limit 3.600s exceeded
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▌       | 2/8 [00:21<01:00, 10.16s/it]
WARNING ⚠️ NMS time limit 3.600s exceeded
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  38%|███▊      | 3/8 [00:29<00:46,  9.26s/it]
WARNING ⚠️ NMS time limit 3.600s exceeded
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 4/8 [00:38<00:38,  9.60s/it]
```
```


Am i missing something, how to optimise in MPS


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13362/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13362/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13360,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13360/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13360/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13360/events,https://github.com/ultralytics/yolov5/issues/13360,2588016318,I_kwDOD8jP_s6aQf6-,13360,onnx convert tensorrt with dynamic issue,"{'login': 'fenghuoxiguozu', 'id': 40490367, 'node_id': 'MDQ6VXNlcjQwNDkwMzY3', 'avatar_url': 'https://avatars.githubusercontent.com/u/40490367?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/fenghuoxiguozu', 'html_url': 'https://github.com/fenghuoxiguozu', 'followers_url': 'https://api.github.com/users/fenghuoxiguozu/followers', 'following_url': 'https://api.github.com/users/fenghuoxiguozu/following{/other_user}', 'gists_url': 'https://api.github.com/users/fenghuoxiguozu/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/fenghuoxiguozu/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/fenghuoxiguozu/subscriptions', 'organizations_url': 'https://api.github.com/users/fenghuoxiguozu/orgs', 'repos_url': 'https://api.github.com/users/fenghuoxiguozu/repos', 'events_url': 'https://api.github.com/users/fenghuoxiguozu/events{/privacy}', 'received_events_url': 'https://api.github.com/users/fenghuoxiguozu/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,1,2024-10-15T08:23:17Z,2024-10-15T11:45:29Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

find same issue  [https://github.com/ultralytics/yolov5/issues/9764](url)

![image](https://github.com/user-attachments/assets/80d4556a-28fd-4842-8ad4-bdc63d468cb4)

### Environment

yolov5-7.0   torch1.13+ cu116 + tensorrt8.24

### Minimal Reproducible Example

onnx export success:
`python export.py --weights yolov5m.pt --include onnx --dynamic --simplify --opset 12`

trt convert error:
`trtexec --onnx=yolov5m.onnx --minShapes=images:1x3x640x640 --optShapes=images:10x3x640x640 --maxShapes=images:10x3x640x640 --saveEngine=yolov5m.engine --fp16`

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13360/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13360/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13359,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13359/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13359/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13359/events,https://github.com/ultralytics/yolov5/issues/13359,2587392803,I_kwDOD8jP_s6aOHsj,13359,YOLOv5 ncnn OpenVINO MNN ONNXRuntime OpenCV CPP Implementations,"{'login': 'Avafly', 'id': 114848280, 'node_id': 'U_kgDOBthyGA', 'avatar_url': 'https://avatars.githubusercontent.com/u/114848280?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Avafly', 'html_url': 'https://github.com/Avafly', 'followers_url': 'https://api.github.com/users/Avafly/followers', 'following_url': 'https://api.github.com/users/Avafly/following{/other_user}', 'gists_url': 'https://api.github.com/users/Avafly/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Avafly/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Avafly/subscriptions', 'organizations_url': 'https://api.github.com/users/Avafly/orgs', 'repos_url': 'https://api.github.com/users/Avafly/repos', 'events_url': 'https://api.github.com/users/Avafly/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Avafly/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,,[],,2,2024-10-15T01:19:44Z,2024-11-09T01:23:45Z,,NONE,,"Hi YOLOv5 community!

I created a repository that might be helpful to some people: [YOLOv5-ncnn-OpenVINO-MNN-ONNXRuntime-OpenCV-CPP](https://github.com/Avafly/YOLOv5-ncnn-OpenVINO-MNN-ONNXRuntime-OpenCV-CPP).

The code uses multiple frameworks to run YOLOv5 detection in C++. Unlike many existing tutorials, this repo implements dynamic input shape detection for all frameworks, which can accelerate inference speed a lot, but is not actively mentioned in many tutorials. Check out the link for more content.

Many thanks to ultralytics/yolov5 community because this repository helped many people learn and use YOLO.

Some demos:

<p align=""center"">
  <img src=""https://cdn.jsdelivr.net/gh/Avafly/ImageHostingService@master/uPic/SCR-20241007-ruzq.png"" width=""500"">
</p>

<p align=""center"">
  <img src=""https://cdn.jsdelivr.net/gh/Avafly/ImageHostingService@master/uPic/SCR-20241007-ruzqq.jpg"" width = ""450"">
</p>",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13359/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13359/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13357,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13357/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13357/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13357/events,https://github.com/ultralytics/yolov5/issues/13357,2586263609,I_kwDOD8jP_s6aJ0A5,13357,How to train with new pictures?,"{'login': 'PengPeng-JunJun', 'id': 59547125, 'node_id': 'MDQ6VXNlcjU5NTQ3MTI1', 'avatar_url': 'https://avatars.githubusercontent.com/u/59547125?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/PengPeng-JunJun', 'html_url': 'https://github.com/PengPeng-JunJun', 'followers_url': 'https://api.github.com/users/PengPeng-JunJun/followers', 'following_url': 'https://api.github.com/users/PengPeng-JunJun/following{/other_user}', 'gists_url': 'https://api.github.com/users/PengPeng-JunJun/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/PengPeng-JunJun/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/PengPeng-JunJun/subscriptions', 'organizations_url': 'https://api.github.com/users/PengPeng-JunJun/orgs', 'repos_url': 'https://api.github.com/users/PengPeng-JunJun/repos', 'events_url': 'https://api.github.com/users/PengPeng-JunJun/events{/privacy}', 'received_events_url': 'https://api.github.com/users/PengPeng-JunJun/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-14T14:44:04Z,2024-11-09T06:29:27Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi, I have to train as code YOLOV5-6.1 and get good result.Now , I add some new images to the dataset.I want to know how to continue training on the best.pt before.
And please tell me how to call this operation,thanks!

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13357/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13357/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13356,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13356/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13356/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13356/events,https://github.com/ultralytics/yolov5/issues/13356,2584602352,I_kwDOD8jP_s6aDebw,13356,"Yolov5_V7.0 while export dynamic onnx, netron layer error ","{'login': 'fenghuoxiguozu', 'id': 40490367, 'node_id': 'MDQ6VXNlcjQwNDkwMzY3', 'avatar_url': 'https://avatars.githubusercontent.com/u/40490367?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/fenghuoxiguozu', 'html_url': 'https://github.com/fenghuoxiguozu', 'followers_url': 'https://api.github.com/users/fenghuoxiguozu/followers', 'following_url': 'https://api.github.com/users/fenghuoxiguozu/following{/other_user}', 'gists_url': 'https://api.github.com/users/fenghuoxiguozu/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/fenghuoxiguozu/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/fenghuoxiguozu/subscriptions', 'organizations_url': 'https://api.github.com/users/fenghuoxiguozu/orgs', 'repos_url': 'https://api.github.com/users/fenghuoxiguozu/repos', 'events_url': 'https://api.github.com/users/fenghuoxiguozu/events{/privacy}', 'received_events_url': 'https://api.github.com/users/fenghuoxiguozu/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,3,2024-10-14T02:57:02Z,2024-10-27T13:30:32Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

use export code:
`python export.py --weights yolov5m.pt --include onnx --dynamic --simplify` 

then i put it into netron, find last Detect layer error
![image](https://github.com/user-attachments/assets/2641dc56-2e81-4fe2-ab47-8c3be8008b33)

how to solve it

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13356/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13356/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13351,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13351/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13351/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13351/events,https://github.com/ultralytics/yolov5/pull/13351,2578768823,PR_kwDOD8jP_s5-OCLf,13351,"Added voice feedback feature using pyttsx3, which is an offline text-to-speech library. ","{'login': 'ParthDA', 'id': 164341955, 'node_id': 'U_kgDOCcuoww', 'avatar_url': 'https://avatars.githubusercontent.com/u/164341955?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ParthDA', 'html_url': 'https://github.com/ParthDA', 'followers_url': 'https://api.github.com/users/ParthDA/followers', 'following_url': 'https://api.github.com/users/ParthDA/following{/other_user}', 'gists_url': 'https://api.github.com/users/ParthDA/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ParthDA/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ParthDA/subscriptions', 'organizations_url': 'https://api.github.com/users/ParthDA/orgs', 'repos_url': 'https://api.github.com/users/ParthDA/repos', 'events_url': 'https://api.github.com/users/ParthDA/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ParthDA/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2597366614, 'node_id': 'MDU6TGFiZWwyNTk3MzY2NjE0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/dependencies', 'name': 'dependencies', 'color': 'C7E824', 'default': False, 'description': 'Dependencies and packages'}]",open,False,,[],,6,2024-10-10T12:56:22Z,2024-10-31T02:10:18Z,,NONE,,"<!--
Thank you 🙏 for your contribution to [Ultralytics](https://www.ultralytics.com/) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. Check for Existing Contributions: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. Link Related Issues: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. Elaborate Your Changes: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. Ultralytics Contributor License Agreement (CLA): To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    I have read the CLA Document and I sign the CLA

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.
--->


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Added text-to-speech functionality to YOLOv5 detections using pyttsx3.

### 📊 Key Changes
- Integrated `pyttsx3` library into `detect.py` for text-to-speech capabilities.
- Updated `requirements.txt` to include `pyttsx3`.

### 🎯 Purpose & Impact
- **Purpose**: Allows YOLOv5 to announce detections verbally, enhancing accessibility.
- **Impact**: Users can receive audible alerts for detections, which can be particularly useful in environments where visual attention is limited. 📢",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13351/reactions', 'total_count': 1, '+1': 0, '-1': 1, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13351/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13351', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13351', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13351.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13351.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13349,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13349/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13349/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13349/events,https://github.com/ultralytics/yolov5/issues/13349,2575335092,I_kwDOD8jP_s6ZgH60,13349,Why is the GPU usage low and the CPU usage high when training the model?,"{'login': 'Assassintears', 'id': 18465107, 'node_id': 'MDQ6VXNlcjE4NDY1MTA3', 'avatar_url': 'https://avatars.githubusercontent.com/u/18465107?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Assassintears', 'html_url': 'https://github.com/Assassintears', 'followers_url': 'https://api.github.com/users/Assassintears/followers', 'following_url': 'https://api.github.com/users/Assassintears/following{/other_user}', 'gists_url': 'https://api.github.com/users/Assassintears/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Assassintears/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Assassintears/subscriptions', 'organizations_url': 'https://api.github.com/users/Assassintears/orgs', 'repos_url': 'https://api.github.com/users/Assassintears/repos', 'events_url': 'https://api.github.com/users/Assassintears/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Assassintears/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,3,2024-10-09T09:24:22Z,2024-10-27T13:30:33Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I train my data with Yolov5.7, it works well. But I find that the GPU usage is very low and the CPU usage  high, my train code like bellow:

```bash
python train.py --weights xxx --batch_size 8 --imgsz 832 --workers 4 --device 0
```

Well, if I set the workers parameter to 8 or bigger, the CPU usage may be high to 100%， the training process like bellow: 
![2](https://github.com/user-attachments/assets/dda8ec51-38d8-42a0-b95b-3b9b0b723079)

What should I do to get more high usage of GPU?


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13349/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13349/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13348,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13348/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13348/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13348/events,https://github.com/ultralytics/yolov5/issues/13348,2574803891,I_kwDOD8jP_s6ZeGOz,13348,How can I see F1-score and precision/recall curves for validation set ?,"{'login': 'Grhanas', 'id': 79200940, 'node_id': 'MDQ6VXNlcjc5MjAwOTQw', 'avatar_url': 'https://avatars.githubusercontent.com/u/79200940?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Grhanas', 'html_url': 'https://github.com/Grhanas', 'followers_url': 'https://api.github.com/users/Grhanas/followers', 'following_url': 'https://api.github.com/users/Grhanas/following{/other_user}', 'gists_url': 'https://api.github.com/users/Grhanas/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Grhanas/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Grhanas/subscriptions', 'organizations_url': 'https://api.github.com/users/Grhanas/orgs', 'repos_url': 'https://api.github.com/users/Grhanas/repos', 'events_url': 'https://api.github.com/users/Grhanas/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Grhanas/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-09T05:32:56Z,2024-11-09T13:03:27Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello! I can see the F1-score for the training dataset after completing the training process. Additionally, I have access to the dfl_loss, box_loss, and cls_loss for both the training and validation sets, as shown in ""results.png."" However, I'm unable to find precision and recall values for the validation set. I would like to understand if my model is experiencing overfitting or underfitting.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13348/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13348/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13347,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13347/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13347/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13347/events,https://github.com/ultralytics/yolov5/issues/13347,2572501052,I_kwDOD8jP_s6ZVUA8,13347,How to adjust effect of loss functions for yolov5 training ?,"{'login': 'Grhanas', 'id': 79200940, 'node_id': 'MDQ6VXNlcjc5MjAwOTQw', 'avatar_url': 'https://avatars.githubusercontent.com/u/79200940?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Grhanas', 'html_url': 'https://github.com/Grhanas', 'followers_url': 'https://api.github.com/users/Grhanas/followers', 'following_url': 'https://api.github.com/users/Grhanas/following{/other_user}', 'gists_url': 'https://api.github.com/users/Grhanas/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Grhanas/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Grhanas/subscriptions', 'organizations_url': 'https://api.github.com/users/Grhanas/orgs', 'repos_url': 'https://api.github.com/users/Grhanas/repos', 'events_url': 'https://api.github.com/users/Grhanas/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Grhanas/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-08T08:38:27Z,2024-11-09T01:25:23Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I want to learn how can i change the effects of loss functions for training. For example dfl_loss is more important for me than other loss functions. How can i make more important this loss function for my training.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13347/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13347/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13343,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13343/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13343/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13343/events,https://github.com/ultralytics/yolov5/issues/13343,2565576519,I_kwDOD8jP_s6Y65dH,13343,Yolov5s onnx model inference ,"{'login': 'anazkhan', 'id': 106157248, 'node_id': 'U_kgDOBlPUwA', 'avatar_url': 'https://avatars.githubusercontent.com/u/106157248?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/anazkhan', 'html_url': 'https://github.com/anazkhan', 'followers_url': 'https://api.github.com/users/anazkhan/followers', 'following_url': 'https://api.github.com/users/anazkhan/following{/other_user}', 'gists_url': 'https://api.github.com/users/anazkhan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/anazkhan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/anazkhan/subscriptions', 'organizations_url': 'https://api.github.com/users/anazkhan/orgs', 'repos_url': 'https://api.github.com/users/anazkhan/repos', 'events_url': 'https://api.github.com/users/anazkhan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/anazkhan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-04T06:39:50Z,2024-11-09T13:41:04Z,,NONE,,"### Search before asking

- [x] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi , I am unable to get bounding boxes from the output i got by running yolov5s onnx model in onnx runtime. The output is list of arrays of the shape (3,52,52,85) , (3,26,26,85) , (3,13,13,85)  respectively . it will be helpful if you can provide me with the postprocess code to define the bounding boxes.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13343/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13343/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13342,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13342/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13342/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13342/events,https://github.com/ultralytics/yolov5/issues/13342,2563136916,I_kwDOD8jP_s6Yxl2U,13342,7.0版本首次运行报错AttributeError: 'FreeTypeFont' object has no attribute 'getsize',"{'login': 'MonHer', 'id': 40558379, 'node_id': 'MDQ6VXNlcjQwNTU4Mzc5', 'avatar_url': 'https://avatars.githubusercontent.com/u/40558379?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/MonHer', 'html_url': 'https://github.com/MonHer', 'followers_url': 'https://api.github.com/users/MonHer/followers', 'following_url': 'https://api.github.com/users/MonHer/following{/other_user}', 'gists_url': 'https://api.github.com/users/MonHer/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/MonHer/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/MonHer/subscriptions', 'organizations_url': 'https://api.github.com/users/MonHer/orgs', 'repos_url': 'https://api.github.com/users/MonHer/repos', 'events_url': 'https://api.github.com/users/MonHer/events{/privacy}', 'received_events_url': 'https://api.github.com/users/MonHer/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,2,2024-10-03T05:09:49Z,2024-11-09T16:27:11Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Training

### Bug

报错日志：
```
Exception in thread Thread-16:
Traceback (most recent call last):
  File ""D:\ProgramData\anaconda3\envs\38yolov5\lib\threading.py"", line 932, in _bootstrap_inner
    self.run()
  File ""D:\ProgramData\anaconda3\envs\38yolov5\lib\threading.py"", line 870, in run
    self._target(*self._args, **self._kwargs)
  File ""E:\Code\Python\YoloPoker\yolo\utils\plots.py"", line 305, in plot_images
    annotator.box_label(box, label, color=color)
  File ""E:\Code\Python\YoloPoker\yolo\utils\plots.py"", line 91, in box_label
    w, h = self.font.getsize(label)  # text width, height
AttributeError: 'FreeTypeFont' object has no attribute 'getsize' 训练完成报错这个 
```
#导致原因
这个错误是由于 FreeTypeFont 对象没有 getsize() 方法引起的，这通常是因为 Pillow 版本的问题。自 Pillow 10.0.0 版本起，getsize() 方法被弃用，改为了 textsize() 或 getbbox()
解决办法：
# 解决方法：
有两种方式可以解决这个问题：

## 1. 降级 Pillow 版本
YOLOv5 和其他旧代码可能依赖于较早版本的 Pillow，因此降级 Pillow 到适合的版本（比如 9.x.x 版本）可以解决这个问题。使用以下命令降级 Pillow：

```
pip install pillow==9.5.0
```
这样可以确保旧的 getsize() 方法在 FreeTypeFont 中可用。
## 2. 修改代码适应新的 Pillow 版本
如果你希望使用较新的 Pillow 版本，可以通过修改 plots.py 文件中的代码，使用新的 getbbox() 方法替换 getsize()。修改代码如下
```
w, h = self.font.getsize(label)  # text width, height
```
update 为：
```
w, h = self.font.getbbox(label)[2:]  # text width, height
```
getbbox() 返回一个 4 元素的元组 (left, top, right, bottom)，其中 right-left 就是宽度，bottom-top 就是高度

### Environment

- yolov5  python 3.8   cuda 12.4

### Minimal Reproducible Example

![image](https://github.com/user-attachments/assets/48904a79-835b-43a8-876d-1102af68a32f)


### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13342/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13342/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13341,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13341/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13341/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13341/events,https://github.com/ultralytics/yolov5/issues/13341,2563057506,I_kwDOD8jP_s6YxSdi,13341,Significant Variations in Training Results with Same Dataset and Parameters,"{'login': 'timiil', 'id': 6621768, 'node_id': 'MDQ6VXNlcjY2MjE3Njg=', 'avatar_url': 'https://avatars.githubusercontent.com/u/6621768?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/timiil', 'html_url': 'https://github.com/timiil', 'followers_url': 'https://api.github.com/users/timiil/followers', 'following_url': 'https://api.github.com/users/timiil/following{/other_user}', 'gists_url': 'https://api.github.com/users/timiil/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/timiil/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/timiil/subscriptions', 'organizations_url': 'https://api.github.com/users/timiil/orgs', 'repos_url': 'https://api.github.com/users/timiil/repos', 'events_url': 'https://api.github.com/users/timiil/events{/privacy}', 'received_events_url': 'https://api.github.com/users/timiil/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-03T03:47:05Z,2024-11-09T06:29:48Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi everyone,

We’ve encountered a noticeable discrepancy in the performance metrics when training the same model (yolov8n.pt) on the same dataset but with different hardware and similar training parameters. The results, specifically the mAP (50-95), vary significantly across different setups.

#### Base Model: yolov8n.pt

#### Training Parameters:  
| No. | Hardware | Epochs | Batch Size | mAP (50-95) |  
|---|---|---|---|---|  
| 1 | A6000(48GB vram) | 100 | 16 | 0.961 |  
| 2 | 4090(24GB vram) | 100 | 12 | 0.93 |  
| 3 | 4090(24GB vram) | 150 | 12 | 0.92 |  
| 4 | L20(48GB vram) | 100 | 16 | 0.976 |

We’ve also tried enabling or disabling `coslr`, but it seems to have little to no effect on the outcome.

Could anyone shed light on what might be causing this inconsistency? Additionally, what strategies could we adopt to achieve better performance on more limited hardware setups?

Thank you in advance for your help!

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13341/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13341/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13340,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13340/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13340/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13340/events,https://github.com/ultralytics/yolov5/issues/13340,2561844249,I_kwDOD8jP_s6YsqQZ,13340,문제 YOLOv5 구현,"{'login': 'Batwan01', 'id': 128815650, 'node_id': 'U_kgDOB62SIg', 'avatar_url': 'https://avatars.githubusercontent.com/u/128815650?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Batwan01', 'html_url': 'https://github.com/Batwan01', 'followers_url': 'https://api.github.com/users/Batwan01/followers', 'following_url': 'https://api.github.com/users/Batwan01/following{/other_user}', 'gists_url': 'https://api.github.com/users/Batwan01/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Batwan01/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Batwan01/subscriptions', 'organizations_url': 'https://api.github.com/users/Batwan01/orgs', 'repos_url': 'https://api.github.com/users/Batwan01/repos', 'events_url': 'https://api.github.com/users/Batwan01/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Batwan01/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-10-02T14:29:58Z,2024-11-09T13:39:28Z,,NONE,,"<!-- 새 문제의 본문을 편집한 다음 편집기의 오른쪽 상단에 있는 ✓ ""문제 만들기"" 버튼을 클릭합니다. 첫 번째 줄은 문제 제목이 됩니다. 담당자와 레이블은 빈 줄 뒤에 옵니다. 문제의 본문을 시작하기 전에 빈 줄을 남겨 두세요. -->",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13340/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13340/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13338,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13338/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13338/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13338/events,https://github.com/ultralytics/yolov5/issues/13338,2558692460,I_kwDOD8jP_s6Ygoxs,13338,ONNXRuntime-Cpp and ONNXRuntime python give different results:,"{'login': 'devendraswamy', 'id': 47595310, 'node_id': 'MDQ6VXNlcjQ3NTk1MzEw', 'avatar_url': 'https://avatars.githubusercontent.com/u/47595310?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/devendraswamy', 'html_url': 'https://github.com/devendraswamy', 'followers_url': 'https://api.github.com/users/devendraswamy/followers', 'following_url': 'https://api.github.com/users/devendraswamy/following{/other_user}', 'gists_url': 'https://api.github.com/users/devendraswamy/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/devendraswamy/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/devendraswamy/subscriptions', 'organizations_url': 'https://api.github.com/users/devendraswamy/orgs', 'repos_url': 'https://api.github.com/users/devendraswamy/repos', 'events_url': 'https://api.github.com/users/devendraswamy/events{/privacy}', 'received_events_url': 'https://api.github.com/users/devendraswamy/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,6,2024-10-01T09:34:20Z,2024-12-17T12:34:25Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I am facing the problem with YOLOV5 model. While I am testing my Python ONNX code, all the bounding box (bbox) values are correct. However, when I perform the same process with my C++ code, I am getting incorrect bbox values.

the image processed in ptyhon code:
image_data = np.expand_dims(image_data, axis=0) # Add batch dimension

and feed that image to python pyd file (c++ inference file complied to pyd)

auto output_tensors = session.Run(Ort::RunOptions{ nullptr }, input_names, &input_tensor, 1, output_names, 1);

### Additional

complied or build C++ code is:

#include <onnxruntime_cxx_api.h>
#include <pybind11/pybind11.h>
#include <pybind11/numpy.h>
#include <vector>
#include <array>
#include <string>
#include <iostream>

using namespace std;
namespace py = pybind11;

class OnnxModel {
public:
    OnnxModel(const std::string& model_path)
        : env(ORT_LOGGING_LEVEL_WARNING, ""OnnxModel""),
          session(env, std::wstring(model_path.begin(), model_path.end()).c_str(), Ort::SessionOptions()) 
    {
        Ort::AllocatorWithDefaultOptions allocator;

        // Get input and output names as Ort::AllocatedStringPtr
        Ort::AllocatedStringPtr input_name_alloc = session.GetInputNameAllocated(0, allocator);
        Ort::AllocatedStringPtr output_name_alloc = session.GetOutputNameAllocated(0, allocator);

        // Convert the Ort::AllocatedStringPtr to std::string using the get() method
        input_name = std::string(input_name_alloc.get());
        output_name = std::string(output_name_alloc.get());

        // Optional: Print the input and output names for debugging
        std::cout << ""Input name: "" << input_name << std::endl;
        std::cout << ""Output name: "" << output_name << std::endl;
    }

    // Accept a 4D numpy array: (batch_size, channels, height, width)
    py::array_t<float> run(py::array_t<float> input_array) {
        // Request a buffer from the numpy array
        py::buffer_info buf = input_array.request();

        // Check that the input is indeed a 4-dimensional array
        if (buf.ndim != 4) {
            throw std::runtime_error(""Input should be a 4-dimensional array (batch_size, channels, height, width)"");
        }

        // Convert numpy array data to std::vector<float>
        std::vector<float> input_data(static_cast<float*>(buf.ptr), 
                                      static_cast<float*>(buf.ptr) + buf.size);

        // Run the inference
        return run_inf(input_data, {1, 3, 640, 640});  // Adjust shape based on your model's input
    }

    py::array_t<float> run_inf(const std::vector<float>& input_data, const std::array<int64_t, 4>& input_shape) {
        // Create input tensor
        Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
        Ort::Value input_tensor = Ort::Value::CreateTensor<float>(
            memory_info,
            const_cast<float*>(input_data.data()),
            input_data.size(),
            input_shape.data(),
            input_shape.size()
        );

        // Prepare input and output names
        const char* input_names[] = { input_name.c_str() };
        const char* output_names[] = { output_name.c_str() };

        // Run the model
        auto output_tensors = session.Run(Ort::RunOptions{ nullptr }, input_names, &input_tensor, 1, output_names, 1);

        // Get the output data
        float* output_data = output_tensors[0].GetTensorMutableData<float>();
        size_t output_count = output_tensors[0].GetTensorTypeAndShapeInfo().GetElementCount();

        // Create a numpy array from the output data
        return py::array_t<float>(output_count, output_data);
    }

private:
    Ort::Env env;
    Ort::Session session;
    std::string input_name;
    std::string output_name;
};

PYBIND11_MODULE(onnx_loader, m) {
    py::class_<OnnxModel>(m, ""OnnxModel"")
        .def(py::init<const std::string&>())
        .def(""run"", &OnnxModel::run);
}

Image feeding from python code:

# Function to preprocess the image
def preprocess_image(image_path, input_size=(640, 640)):
    # Load the image using OpenCV
    image = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Load image in color mode
    if image is None:
        raise ValueError(f""Could not open or find the image: {image_path}"")
    # Convert from BGR to RGB format
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # Resize the image to match the input size expected by the model
    image = cv2.resize(image, input_size)
    # Normalize the image to [0, 1] range
    image = image.astype(np.float32) / 255.0  # Convert to float and normalize
    # Rearrange the image to CHW format (1, C, H, W)
    image_data = np.transpose(image, (2, 0, 1))  # Convert to CHW format
    image_data = np.expand_dims(image_data, axis=0)  # Add batch dimension
    print(f""Image preprocessed: type = {type(image_data)}, shape = {image_data.shape}"")
    return image_data, image  # Return the preprocessed image data

",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13338/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13338/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13335,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13335/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13335/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13335/events,https://github.com/ultralytics/yolov5/issues/13335,2552998997,I_kwDOD8jP_s6YK6xV,13335,Error running in windows 11 with python 3.12 virtual env,"{'login': 'balakreshnan', 'id': 25058438, 'node_id': 'MDQ6VXNlcjI1MDU4NDM4', 'avatar_url': 'https://avatars.githubusercontent.com/u/25058438?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/balakreshnan', 'html_url': 'https://github.com/balakreshnan', 'followers_url': 'https://api.github.com/users/balakreshnan/followers', 'following_url': 'https://api.github.com/users/balakreshnan/following{/other_user}', 'gists_url': 'https://api.github.com/users/balakreshnan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/balakreshnan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/balakreshnan/subscriptions', 'organizations_url': 'https://api.github.com/users/balakreshnan/orgs', 'repos_url': 'https://api.github.com/users/balakreshnan/repos', 'events_url': 'https://api.github.com/users/balakreshnan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/balakreshnan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,5,2024-09-27T13:49:04Z,2024-10-27T13:30:35Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

File ""c:\Code\gradioapps\mfgappsv1\.venv\Lib\site-packages\torch\hub.py"", line 599, in _load_local
    model = entry(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\hubconf.py"", line 215, in yolov5s
    return _create(""yolov5s"", pretrained, channels, classes, autoshape, _verbose, device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\hubconf.py"", line 103, in _create
    raise Exception(s) from e
Exception: 'model'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help.

### Environment

python 3.12
latest on all libraries

### Minimal Reproducible Example

import torch

# Model
model = torch.hub.load(""ultralytics/yolov5"", ""yolov5s"", channels=3, force_reload=True)

# Image
im = ""https://ultralytics.com/images/zidane.jpg""

# Inference
results = model(im)

results.pandas().xyxy[0]
#      xmin    ymin    xmax   ymax  confidence  class    name
# 0  749.50   43.50  1148.0  704.5    0.874023      0  person
# 1  433.50  433.50   517.5  714.5    0.687988     27     tie
# 2  114.75  195.75  1095.0  708.0    0.624512      0  person
# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie

### Additional

PS C:\Code\gradioapps\mfgappsv1> python .\yolotest.py
Downloading: ""https://github.com/ultralytics/yolov5/zipball/master"" to C:\Users\babal/.cache\torch\hub\master.zip
YOLOv5  2024-9-27 Python-3.12.6 torch-2.4.1+cpu CPU

Traceback (most recent call last):
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\hubconf.py"", line 70, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\models\common.py"", line 489, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\models\experimental.py"", line 99, in attempt_load
    ckpt = (ckpt.get(""ema"") or ckpt[""model""]).to(device).float()  # FP32 model
                               ~~~~^^^^^^^^^
KeyError: 'model'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\hubconf.py"", line 85, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\models\experimental.py"", line 99, in attempt_load
    ckpt = (ckpt.get(""ema"") or ckpt[""model""]).to(device).float()  # FP32 model
                               ~~~~^^^^^^^^^
KeyError: 'model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Code\gradioapps\mfgappsv1\yolotest.py"", line 4, in <module>
    model = torch.hub.load(""ultralytics/yolov5"", ""yolov5s"", channels=3, force_reload=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""c:\Code\gradioapps\mfgappsv1\.venv\Lib\site-packages\torch\hub.py"", line 570, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""c:\Code\gradioapps\mfgappsv1\.venv\Lib\site-packages\torch\hub.py"", line 599, in _load_local
    model = entry(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\hubconf.py"", line 215, in yolov5s
    return _create(""yolov5s"", pretrained, channels, classes, autoshape, _verbose, device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\babal/.cache\torch\hub\ultralytics_yolov5_master\hubconf.py"", line 103, in _create
    raise Exception(s) from e
Exception: 'model'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help.

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13335/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13335/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13334,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13334/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13334/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13334/events,https://github.com/ultralytics/yolov5/issues/13334,2547386323,I_kwDOD8jP_s6X1gfT,13334,how can I just use yolov5s.pt,"{'login': 'DarkLeaves', 'id': 50801566, 'node_id': 'MDQ6VXNlcjUwODAxNTY2', 'avatar_url': 'https://avatars.githubusercontent.com/u/50801566?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/DarkLeaves', 'html_url': 'https://github.com/DarkLeaves', 'followers_url': 'https://api.github.com/users/DarkLeaves/followers', 'following_url': 'https://api.github.com/users/DarkLeaves/following{/other_user}', 'gists_url': 'https://api.github.com/users/DarkLeaves/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/DarkLeaves/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/DarkLeaves/subscriptions', 'organizations_url': 'https://api.github.com/users/DarkLeaves/orgs', 'repos_url': 'https://api.github.com/users/DarkLeaves/repos', 'events_url': 'https://api.github.com/users/DarkLeaves/events{/privacy}', 'received_events_url': 'https://api.github.com/users/DarkLeaves/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-25T08:55:09Z,2024-11-09T06:26:57Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I want to use yolov5s.pt to do some experiments.
but when I run my code:
`model = YOLO('yolov5s.pt')`

the ultralytics will  Replace 'model=pics/yolov5s.pt' with new 'model=pics/yolov5su.pt'.
how to cancel this replacement?



### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13334/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13334/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13333,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13333/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13333/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13333/events,https://github.com/ultralytics/yolov5/issues/13333,2547093752,I_kwDOD8jP_s6X0ZD4,13333,License for the TF Lite quantized version of YOLOv5 on Kaggle,"{'login': 'kruska7', 'id': 174865279, 'node_id': 'U_kgDOCmw7fw', 'avatar_url': 'https://avatars.githubusercontent.com/u/174865279?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/kruska7', 'html_url': 'https://github.com/kruska7', 'followers_url': 'https://api.github.com/users/kruska7/followers', 'following_url': 'https://api.github.com/users/kruska7/following{/other_user}', 'gists_url': 'https://api.github.com/users/kruska7/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/kruska7/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/kruska7/subscriptions', 'organizations_url': 'https://api.github.com/users/kruska7/orgs', 'repos_url': 'https://api.github.com/users/kruska7/repos', 'events_url': 'https://api.github.com/users/kruska7/events{/privacy}', 'received_events_url': 'https://api.github.com/users/kruska7/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-25T06:49:34Z,2024-11-09T12:36:59Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

The license is stated as Apache 2.0 for the TF Lite quantized version of YOLOv5 on Kaggle. Is this possible and correct, and can it be used under this license? I was at the impression that the license for YOLOv5 is AGPL-3.0.

https://www.kaggle.com/models/kaggle/yolo-v5/tfLite/tflite-tflite-model/1

<img width=""1315"" alt=""Screenshot 2024-09-25 at 08 46 30"" src=""https://github.com/user-attachments/assets/a6a0a58d-329b-4117-be57-857c8af13004"">


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13333/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13333/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13332,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13332/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13332/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13332/events,https://github.com/ultralytics/yolov5/issues/13332,2546691729,I_kwDOD8jP_s6Xy26R,13332,WARNING ⚠️ NMS time limit 0.340s exceeded,"{'login': 'haniraid', 'id': 102861060, 'node_id': 'U_kgDOBiGJBA', 'avatar_url': 'https://avatars.githubusercontent.com/u/102861060?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/haniraid', 'html_url': 'https://github.com/haniraid', 'followers_url': 'https://api.github.com/users/haniraid/followers', 'following_url': 'https://api.github.com/users/haniraid/following{/other_user}', 'gists_url': 'https://api.github.com/users/haniraid/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/haniraid/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/haniraid/subscriptions', 'organizations_url': 'https://api.github.com/users/haniraid/orgs', 'repos_url': 'https://api.github.com/users/haniraid/repos', 'events_url': 'https://api.github.com/users/haniraid/events{/privacy}', 'received_events_url': 'https://api.github.com/users/haniraid/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,2,2024-09-25T01:24:00Z,2024-11-09T14:46:48Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

Hi YOLO comunnity. so im running training on my cpu and i have this probleme notice that ive already checked on the previous simular issues and i found this 
 time_limit = 0.1 + 0.02 * bs  # seconds to quit after
 i applied it but the issue still here
raidhani@raidhani-All-Series:~/catkin_ws/src/yolov5$ python3 train.py --img 640 --batch 6 --epochs 100 --data /home/raidhani/catkin_ws/src/data/data.yaml --weights yolov5s.pt 
train: weights=yolov5s.pt, cfg=, data=/home/raidhani/catkin_ws/src/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=6, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github: up to date with https://github.com/ultralytics/yolov5 ✅
YOLOv5 🚀 v7.0-368-gb163ff8d Python-3.8.10 torch-1.11.0+cpu CPU

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
Comet: run 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet
TensorBoard: Start with 'tensorboard --logdir runs/train', view at http://localhost:6006/
Overriding model.yaml nc=80 with nc=10

                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          
 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          
 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
Model summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs

Transferred 343/349 items from yolov5s.pt
optimizer: SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.000515625), 60 bias
train: Scanning /home/raidhani/catkin_ws/src/data/train/labels.cache... 1008 images, 120 backgrounds, 0 corrupt: 100%|█████████
val: Scanning /home/raidhani/catkin_ws/src/data/valid/labels.cache... 230 images, 31 backgrounds, 0 corrupt: 100%|██████████| 2

AutoAnchor: 4.51 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅
Plotting labels to runs/train/exp11/labels.jpg... 
Image sizes 640 train, 640 val
Using 6 dataloader workers
Logging results to runs/train/exp11
Starting training for 100 epochs...

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
       0/99         0G     0.1032    0.06545    0.05506         64        640: 100%|██████████| 169/169 [07:32<00:00,  2.68s/it
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 [00:00<?, ?it/sWARNING ⚠️ NMS time limit 0.340s exceeded
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 [00:01<00:29,  WARNING ⚠️ NMS time limit 0.340s exceeded
                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 [00:03<00:27,  WARNING ⚠️ NMS time limit 0.340s exceeded
                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 [00:04<00:26,  WARNING ⚠️ NMS time limit 0.340s exceeded
                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 [00:06<00:24,  WARNING ⚠️ NMS time limit 0.340s exceeded
                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 [00:07<00:24,                   Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 [00:08<00:24,  
Traceback (most recent call last):
  File ""train.py"", line 986, in <module>


### Environment

YOLOv5 🚀 v7.0-368-gb163ff8d Python-3.8.10 torch-1.11.0+cpu CPU


### Minimal Reproducible Example

python3 train.py --img 640 --batch 6 --epochs 100 --data /home/raidhani/catkin_ws/src/data/data.yaml --weights yolov5s.pt 


### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13332/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13332/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13331,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13331/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13331/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13331/events,https://github.com/ultralytics/yolov5/issues/13331,2542181701,I_kwDOD8jP_s6Xhp1F,13331,I want to know whether there is a yolov5s uses Relu train on Coco.,"{'login': 'JackeyWang1', 'id': 127383727, 'node_id': 'U_kgDOB5e4rw', 'avatar_url': 'https://avatars.githubusercontent.com/u/127383727?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/JackeyWang1', 'html_url': 'https://github.com/JackeyWang1', 'followers_url': 'https://api.github.com/users/JackeyWang1/followers', 'following_url': 'https://api.github.com/users/JackeyWang1/following{/other_user}', 'gists_url': 'https://api.github.com/users/JackeyWang1/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/JackeyWang1/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/JackeyWang1/subscriptions', 'organizations_url': 'https://api.github.com/users/JackeyWang1/orgs', 'repos_url': 'https://api.github.com/users/JackeyWang1/repos', 'events_url': 'https://api.github.com/users/JackeyWang1/events{/privacy}', 'received_events_url': 'https://api.github.com/users/JackeyWang1/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-23T10:17:20Z,2024-11-09T09:39:20Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I want to know whether there is a yolov5s uses Relu train on Coco.

### Additional

no",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13331/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13331/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13330,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13330/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13330/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13330/events,https://github.com/ultralytics/yolov5/issues/13330,2542098336,I_kwDOD8jP_s6XhVeg,13330,about save-txt in yolov5-seg,"{'login': 'Powerfulidot', 'id': 125859971, 'node_id': 'U_kgDOB4B4gw', 'avatar_url': 'https://avatars.githubusercontent.com/u/125859971?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Powerfulidot', 'html_url': 'https://github.com/Powerfulidot', 'followers_url': 'https://api.github.com/users/Powerfulidot/followers', 'following_url': 'https://api.github.com/users/Powerfulidot/following{/other_user}', 'gists_url': 'https://api.github.com/users/Powerfulidot/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Powerfulidot/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Powerfulidot/subscriptions', 'organizations_url': 'https://api.github.com/users/Powerfulidot/orgs', 'repos_url': 'https://api.github.com/users/Powerfulidot/repos', 'events_url': 'https://api.github.com/users/Powerfulidot/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Powerfulidot/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,5,2024-09-23T09:40:49Z,2024-10-27T13:30:36Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

when activating ""save-txt"" in yolov5-seg.py, a txt with the coordinates of the predicted region is saved, but i found that the coordinates seem not to be in sequence, that is to say when i use fillpoly in opencv, the coordinates seem unable to form a polygon like the one of prediction. is there a way to make the coordinates in sequence?

我发现启用save-txt后保存的包含预测分割区域的txt里的坐标似乎不是按顺序的（指坐标的保存顺序不是围着分割区域的）？用opencv的fillpoly填充出来的也跟预测的区域不一样。有办法把坐标变成按顺序的吗？

![QQ20240923-174819](https://github.com/user-attachments/assets/c991dea0-47bf-4dc1-93cb-d79697ce0493)

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13330/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13330/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13329,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13329/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13329/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13329/events,https://github.com/ultralytics/yolov5/issues/13329,2541624428,I_kwDOD8jP_s6Xfhxs,13329,yolov5s / detect.py/ 욜로v5 결과저장을 10분에 한번 하고 싶습니다,"{'login': 'rod-0123', 'id': 181764082, 'node_id': 'U_kgDOCtV_8g', 'avatar_url': 'https://avatars.githubusercontent.com/u/181764082?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/rod-0123', 'html_url': 'https://github.com/rod-0123', 'followers_url': 'https://api.github.com/users/rod-0123/followers', 'following_url': 'https://api.github.com/users/rod-0123/following{/other_user}', 'gists_url': 'https://api.github.com/users/rod-0123/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/rod-0123/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/rod-0123/subscriptions', 'organizations_url': 'https://api.github.com/users/rod-0123/orgs', 'repos_url': 'https://api.github.com/users/rod-0123/repos', 'events_url': 'https://api.github.com/users/rod-0123/events{/privacy}', 'received_events_url': 'https://api.github.com/users/rod-0123/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-23T05:43:20Z,2024-11-09T09:58:31Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

지금은 프레임마다 모든 결과가 저장이 되는데 일정시간마다 저장되게 하고 싶습니다

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13329/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13329/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13327,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13327/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13327/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13327/events,https://github.com/ultralytics/yolov5/issues/13327,2541509776,I_kwDOD8jP_s6XfFyQ,13327,分割？,"{'login': 'pjh11214', 'id': 164312706, 'node_id': 'U_kgDOCcs2gg', 'avatar_url': 'https://avatars.githubusercontent.com/u/164312706?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/pjh11214', 'html_url': 'https://github.com/pjh11214', 'followers_url': 'https://api.github.com/users/pjh11214/followers', 'following_url': 'https://api.github.com/users/pjh11214/following{/other_user}', 'gists_url': 'https://api.github.com/users/pjh11214/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/pjh11214/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/pjh11214/subscriptions', 'organizations_url': 'https://api.github.com/users/pjh11214/orgs', 'repos_url': 'https://api.github.com/users/pjh11214/repos', 'events_url': 'https://api.github.com/users/pjh11214/events{/privacy}', 'received_events_url': 'https://api.github.com/users/pjh11214/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-23T03:48:11Z,2024-11-09T12:00:43Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Segmentation code is instance segmentation or semantic segmentation？ I am optimistic that many data are said to be instance segmentation, then I want to until how to let the target output of the same class is a different color mask?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13327/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13327/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13326,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13326/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13326/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13326/events,https://github.com/ultralytics/yolov5/issues/13326,2540110219,I_kwDOD8jP_s6XZwGL,13326,Real time image recognition in Google Colab problem,"{'login': 'mamasha-bt', 'id': 175305911, 'node_id': 'U_kgDOCnL0tw', 'avatar_url': 'https://avatars.githubusercontent.com/u/175305911?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mamasha-bt', 'html_url': 'https://github.com/mamasha-bt', 'followers_url': 'https://api.github.com/users/mamasha-bt/followers', 'following_url': 'https://api.github.com/users/mamasha-bt/following{/other_user}', 'gists_url': 'https://api.github.com/users/mamasha-bt/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mamasha-bt/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mamasha-bt/subscriptions', 'organizations_url': 'https://api.github.com/users/mamasha-bt/orgs', 'repos_url': 'https://api.github.com/users/mamasha-bt/repos', 'events_url': 'https://api.github.com/users/mamasha-bt/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mamasha-bt/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-21T09:21:29Z,2024-11-09T10:00:18Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have trained YOLOv5 model in Google Colab on custom dataset, have got access to my webcam, but I don't know how to run object detection in real time from webcam in Google Colab. Please, help

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13326/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13326/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13324,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13324/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13324/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13324/events,https://github.com/ultralytics/yolov5/issues/13324,2536515923,I_kwDOD8jP_s6XMClT,13324,close mosaic in yolov5,"{'login': 'ChenJian7578', 'id': 42240985, 'node_id': 'MDQ6VXNlcjQyMjQwOTg1', 'avatar_url': 'https://avatars.githubusercontent.com/u/42240985?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ChenJian7578', 'html_url': 'https://github.com/ChenJian7578', 'followers_url': 'https://api.github.com/users/ChenJian7578/followers', 'following_url': 'https://api.github.com/users/ChenJian7578/following{/other_user}', 'gists_url': 'https://api.github.com/users/ChenJian7578/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ChenJian7578/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ChenJian7578/subscriptions', 'organizations_url': 'https://api.github.com/users/ChenJian7578/orgs', 'repos_url': 'https://api.github.com/users/ChenJian7578/repos', 'events_url': 'https://api.github.com/users/ChenJian7578/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ChenJian7578/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-19T14:25:59Z,2024-11-09T16:23:15Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

in v8,   ultralytics/cfg/default.yaml.  there have the parameter close_mosaic to close the mosaic in the last few epochs of training, so how can i Implement this functionality in v5?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13324/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13324/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13319,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13319/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13319/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13319/events,https://github.com/ultralytics/yolov5/issues/13319,2528918755,I_kwDOD8jP_s6WvDzj,13319,yolov5 / detect.py 결과를 10분주기로 출력하고 싶습니다,"{'login': 'rod-0123', 'id': 181764082, 'node_id': 'U_kgDOCtV_8g', 'avatar_url': 'https://avatars.githubusercontent.com/u/181764082?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/rod-0123', 'html_url': 'https://github.com/rod-0123', 'followers_url': 'https://api.github.com/users/rod-0123/followers', 'following_url': 'https://api.github.com/users/rod-0123/following{/other_user}', 'gists_url': 'https://api.github.com/users/rod-0123/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/rod-0123/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/rod-0123/subscriptions', 'organizations_url': 'https://api.github.com/users/rod-0123/orgs', 'repos_url': 'https://api.github.com/users/rod-0123/repos', 'events_url': 'https://api.github.com/users/rod-0123/events{/privacy}', 'received_events_url': 'https://api.github.com/users/rod-0123/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-16T16:23:53Z,2024-11-09T07:00:33Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

yolov5 / detect.py 결과를 10분 주기로 출력하고 싶습니다

72 0.296875 0.61875 0.275 0.741667
0 0.541406 0.65 0.732813 0.7

지금은 이렇게 출력이 되는데, 시작하고 10분마다 결과를 출력하고 싶습니다
혹시 방법이 있을까요?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13319/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13319/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13317,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13317/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13317/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13317/events,https://github.com/ultralytics/yolov5/issues/13317,2527904335,I_kwDOD8jP_s6WrMJP,13317,Remove detection head,"{'login': 'Neloy262', 'id': 42342914, 'node_id': 'MDQ6VXNlcjQyMzQyOTE0', 'avatar_url': 'https://avatars.githubusercontent.com/u/42342914?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Neloy262', 'html_url': 'https://github.com/Neloy262', 'followers_url': 'https://api.github.com/users/Neloy262/followers', 'following_url': 'https://api.github.com/users/Neloy262/following{/other_user}', 'gists_url': 'https://api.github.com/users/Neloy262/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Neloy262/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Neloy262/subscriptions', 'organizations_url': 'https://api.github.com/users/Neloy262/orgs', 'repos_url': 'https://api.github.com/users/Neloy262/repos', 'events_url': 'https://api.github.com/users/Neloy262/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Neloy262/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-16T09:08:59Z,2024-09-17T19:36:44Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have trained a yolov5n model on a custom dataset. Now i want to remove the detection head so i can get the features immediately before the detection head. How might I do this?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13317/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13317/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13316,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13316/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13316/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13316/events,https://github.com/ultralytics/yolov5/issues/13316,2527522957,I_kwDOD8jP_s6WpvCN,13316,RuntimeError: The size of tensor a (6) must match the size of tensor b (7) at non-singleton dimension 2,"{'login': 'YounghoJo01', 'id': 180150684, 'node_id': 'U_kgDOCrzhnA', 'avatar_url': 'https://avatars.githubusercontent.com/u/180150684?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/YounghoJo01', 'html_url': 'https://github.com/YounghoJo01', 'followers_url': 'https://api.github.com/users/YounghoJo01/followers', 'following_url': 'https://api.github.com/users/YounghoJo01/following{/other_user}', 'gists_url': 'https://api.github.com/users/YounghoJo01/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/YounghoJo01/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/YounghoJo01/subscriptions', 'organizations_url': 'https://api.github.com/users/YounghoJo01/orgs', 'repos_url': 'https://api.github.com/users/YounghoJo01/repos', 'events_url': 'https://api.github.com/users/YounghoJo01/events{/privacy}', 'received_events_url': 'https://api.github.com/users/YounghoJo01/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-16T05:18:21Z,2024-11-09T13:15:23Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

whdudgh@whdudgh-G5-KE:~/yolov5$ python3 load_dataset.py
Scanning /home/whdudgh/datasets/my_dataset/labels/train.cache... 1038 images, 12
Overriding model.yaml nc=80 with nc=3

                 from  n    params  module                                  arguments                     
  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              
  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                
  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   
  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               
  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 
  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              
  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 
  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              
  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 
  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 
 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          
 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          
 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          
 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          
 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]
YOLOv5m summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs

Processed Shapes: tensor([1080., 1920., 1080., 1920.], device='cuda:0')
Labels size: torch.Size([1, 3, 6])
Labels: tensor([[[0.00000, 2.00000, 0.35182, 0.43099, 0.03490, 0.01302],
         [0.00000, 2.00000, 0.50338, 0.42891, 0.02656, 0.00990],
         [0.00000, 2.00000, 0.55469, 0.42630, 0.02500, 0.01094]]], device='cuda:0')
targets shape: torch.Size([3, 5])
gain shape: torch.Size([7])
targets: tensor([[0.00000, 2.00000, 0.35182, 0.43099, 0.03490],
        [0.00000, 2.00000, 0.50338, 0.42891, 0.02656],
        [0.00000, 2.00000, 0.55469, 0.42630, 0.02500]], device='cuda:0')
Traceback (most recent call last):
  File ""load_dataset.py"", line 73, in <module>
    loss, loss_items = compute_loss(outputs, labels)
  File ""/home/whdudgh/yolov5/utils/loss.py"", line 144, in __call__
    tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets
  File ""/home/whdudgh/yolov5/utils/loss.py"", line 240, in build_targets
    t = targets * gain  # shape(3,n,7)
RuntimeError: The size of tensor a (6) must match the size of tensor b (7) at non-singleton dimension 2

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13316/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13316/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13315,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13315/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13315/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13315/events,https://github.com/ultralytics/yolov5/issues/13315,2526756096,I_kwDOD8jP_s6Wmz0A,13315,RuntimeError: The size of tensor a (6) must match the size of tensor b (7) at non-singleton dimension 2,"{'login': 'YounghoJo01', 'id': 180150684, 'node_id': 'U_kgDOCrzhnA', 'avatar_url': 'https://avatars.githubusercontent.com/u/180150684?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/YounghoJo01', 'html_url': 'https://github.com/YounghoJo01', 'followers_url': 'https://api.github.com/users/YounghoJo01/followers', 'following_url': 'https://api.github.com/users/YounghoJo01/following{/other_user}', 'gists_url': 'https://api.github.com/users/YounghoJo01/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/YounghoJo01/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/YounghoJo01/subscriptions', 'organizations_url': 'https://api.github.com/users/YounghoJo01/orgs', 'repos_url': 'https://api.github.com/users/YounghoJo01/repos', 'events_url': 'https://api.github.com/users/YounghoJo01/events{/privacy}', 'received_events_url': 'https://api.github.com/users/YounghoJo01/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-15T06:01:57Z,2024-11-09T07:02:27Z,,NONE,,"### Search before asking

- [x] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I installed CUDA 12.6, cuDNN, and YOLOv5 to train a model for traffic light detection. However, I'm encountering an error while running tests on a subset of my dataset. Due to this error, I'm unable to resolve the issue. Please, I need your help to find a solution.
![Uploading 스크린샷, 2024-09-15 23-57-43.png…]()


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13315/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13315/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13313,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13313/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13313/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13313/events,https://github.com/ultralytics/yolov5/issues/13313,2526138186,I_kwDOD8jP_s6Wkc9K,13313,Report errors while continuing training,"{'login': 'pjh11214', 'id': 164312706, 'node_id': 'U_kgDOCcs2gg', 'avatar_url': 'https://avatars.githubusercontent.com/u/164312706?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/pjh11214', 'html_url': 'https://github.com/pjh11214', 'followers_url': 'https://api.github.com/users/pjh11214/followers', 'following_url': 'https://api.github.com/users/pjh11214/following{/other_user}', 'gists_url': 'https://api.github.com/users/pjh11214/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/pjh11214/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/pjh11214/subscriptions', 'organizations_url': 'https://api.github.com/users/pjh11214/orgs', 'repos_url': 'https://api.github.com/users/pjh11214/repos', 'events_url': 'https://api.github.com/users/pjh11214/events{/privacy}', 'received_events_url': 'https://api.github.com/users/pjh11214/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-14T09:16:38Z,2024-11-09T02:25:11Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

When I run train.py for target detection, my resume is set to True and I want to continue my previous training. However, when I have last.pt in my tarin-seg folder, I will read the tarin-seg file directly, instead of reading the weight under the tarin file that my target detects.           I don't quite understand this question, please answer it for me. Is that my problem.
![12345](https://github.com/user-attachments/assets/c9ee641a-23c3-4451-a3b8-351e9cfcf12c)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13313/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13313/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13312,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13312/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13312/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13312/events,https://github.com/ultralytics/yolov5/issues/13312,2524944332,I_kwDOD8jP_s6Wf5fM,13312,yolov5-pip forced boto3 consumption invalidates py3.7-9 support,"{'login': 'lockwoodar', 'id': 161524313, 'node_id': 'U_kgDOCaCqWQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/161524313?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/lockwoodar', 'html_url': 'https://github.com/lockwoodar', 'followers_url': 'https://api.github.com/users/lockwoodar/followers', 'following_url': 'https://api.github.com/users/lockwoodar/following{/other_user}', 'gists_url': 'https://api.github.com/users/lockwoodar/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/lockwoodar/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/lockwoodar/subscriptions', 'organizations_url': 'https://api.github.com/users/lockwoodar/orgs', 'repos_url': 'https://api.github.com/users/lockwoodar/repos', 'events_url': 'https://api.github.com/users/lockwoodar/events{/privacy}', 'received_events_url': 'https://api.github.com/users/lockwoodar/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2597366614, 'node_id': 'MDU6TGFiZWwyNTk3MzY2NjE0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/dependencies', 'name': 'dependencies', 'color': 'C7E824', 'default': False, 'description': 'Dependencies and packages'}]",open,False,,[],,2,2024-09-13T14:09:01Z,2024-11-09T10:03:00Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Other

### Bug

#### Problem

yolov5-pip ([v7.0.13 PyPi packaging](https://pypi.org/project/yolov5/)) is currently forcing end-users to consume [boto3](https://github.com/fcakyon/yolov5-pip/blob/main/requirements.txt#L54-L55), which brings in transitive updates to [botocore](https://github.com/boto/botocore/blob/develop/setup.py#L31-L32) that constrain `urllib3` on python version <3.10 due to security updates.  This functionally ends yolov5 support for python versions 3, 3.7-9 based on end-user environment configuration.

(e.g. yolov5 cannot be installed in a py3.9 environment that is also using `gradio>=4.27.0`, which introduces a `urllib3~=2.0` security constraint)

#### Ask / Potential Solution

yolov5 can retroactively continue to support python <3.10 environments by vending an optional configuration that omits enforced consumption of AWS-CLI dependencies (e.g. `pip install yolov5[no-aws-cli]` while not disrupting downstream end-users that are expecting the enforced consumption).



### Environment

n/a - reproducible environment cannot solve due to above problem (see reproduction section for example)

### Minimal Reproducible Example

Create a minimal conda environment (or use another preferred venv)

```bash
conda create -n yolov5-env -c conda-forge python=3.9 pip
```

Install any dependency that has enforced secops pins on `urllib3>=2.0`
```bash
pip install gradio==4.27.0
```

Install yolov5
```bash
pip install yolov5
```

Example failure:
```shell
vision, thop, ultralytics, yolov5
  Attempting uninstall: urllib3
    Found existing installation: urllib3 2.2.3
    Uninstalling urllib3-2.2.3:
      Successfully uninstalled urllib3-2.2.3
  Attempting uninstall: idna
    Found existing installation: idna 3.8
    Uninstalling idna-3.8:
      Successfully uninstalled idna-3.8
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
gradio 4.27.0 requires urllib3~=2.0, but you have urllib3 1.26.20 which is incompatible.
```



### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13312/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13312/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13308,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13308/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13308/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13308/events,https://github.com/ultralytics/yolov5/issues/13308,2522512866,I_kwDOD8jP_s6WWn3i,13308,Export torchscript with NMS,"{'login': 'RobinFrcd', 'id': 29704178, 'node_id': 'MDQ6VXNlcjI5NzA0MTc4', 'avatar_url': 'https://avatars.githubusercontent.com/u/29704178?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/RobinFrcd', 'html_url': 'https://github.com/RobinFrcd', 'followers_url': 'https://api.github.com/users/RobinFrcd/followers', 'following_url': 'https://api.github.com/users/RobinFrcd/following{/other_user}', 'gists_url': 'https://api.github.com/users/RobinFrcd/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/RobinFrcd/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/RobinFrcd/subscriptions', 'organizations_url': 'https://api.github.com/users/RobinFrcd/orgs', 'repos_url': 'https://api.github.com/users/RobinFrcd/repos', 'events_url': 'https://api.github.com/users/RobinFrcd/events{/privacy}', 'received_events_url': 'https://api.github.com/users/RobinFrcd/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-09-12T14:08:23Z,2024-11-09T13:15:11Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

In the export script it's possible to export a [coreml](https://github.com/ultralytics/yolov5/blob/master/export.py#L526) or [tflite](https://github.com/ultralytics/yolov5/blob/master/export.py#L830) with `nms` but not for the default [torchscript](https://github.com/ultralytics/yolov5/blob/master/export.py#L229).

I want to export the full model (with pre-post processing functions) with torchscript. Is there any official recommended way to go or do we need to rely on slightly deprecated tools like [yolort](https://github.com/zhiqwang/yolort) ?

### Use case

Export YOLOv5 to torchscript with pre and post processing functions included in the torchscript.

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13308/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13308/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13305,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13305/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13305/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13305/events,https://github.com/ultralytics/yolov5/issues/13305,2518654653,I_kwDOD8jP_s6WH569,13305,Regarding the application establishment of preprocessing functions,"{'login': 'K011-17', 'id': 151705335, 'node_id': 'U_kgDOCQrW9w', 'avatar_url': 'https://avatars.githubusercontent.com/u/151705335?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/K011-17', 'html_url': 'https://github.com/K011-17', 'followers_url': 'https://api.github.com/users/K011-17/followers', 'following_url': 'https://api.github.com/users/K011-17/following{/other_user}', 'gists_url': 'https://api.github.com/users/K011-17/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/K011-17/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/K011-17/subscriptions', 'organizations_url': 'https://api.github.com/users/K011-17/orgs', 'repos_url': 'https://api.github.com/users/K011-17/repos', 'events_url': 'https://api.github.com/users/K011-17/events{/privacy}', 'received_events_url': 'https://api.github.com/users/K011-17/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-09-11T06:29:08Z,2024-09-13T10:14:39Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

YOLOv5 has various preprocessing functions, such as the Albumations library, mosaic, mixup, random_perspective, etc. If you look at the hyp file, you will see the parameters for each preprocessing function as shown below.

```
lr0: 0.01 # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.01 # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.937 # SGD momentum/Adam beta1
weight_decay: 0.0005 # optimizer weight decay 5e-4
warmup_epochs: 3.0 # warmup epochs (fractions ok)
warmup_momentum: 0.8 # warmup initial momentum
warmup_bias_lr: 0.1 # warmup initial bias lr
box: 0.05 # box loss gain
cls: 0.5 # cls loss gain
cls_pw: 1.0 # cls BCELoss positive_weight
obj: 1.0 # obj loss gain (scale with pixels)
obj_pw: 1.0 # obj BCELoss positive_weight
iou_t: 0.20 # IoU training threshold
anchor_t: 4.0 # anchor-multiple threshold
# anchors: 3  # anchors per output layer (0 to ignore)
fl_gamma: 0.0 # focal loss gamma (efficientDet default gamma=1.5)
hsv_h: 0.015 # image HSV-Hue augmentation (fraction)
hsv_s: 0.7 # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4 # image HSV-Value augmentation (fraction)
degrees: 0.0 # image rotation (+/- deg)
translate: 0.1 # image translation (+/- fraction)
scale: 0.5 # image scale (+/- gain)
shear: 0.0 # image shear (+/- deg)
perspective: 0.0 # image perspective (+/- fraction), range 0-0.001
flipud: 0.0 # image flip up-down (probability)
fliplr: 0.5 # image flip left-right (probability)
mosaic: 1.0 # image mosaic (probability)
mixup: 0.0 # image mixup (probability)
copy_paste: 0.0 # segment copy-paste (probability)
```

I think this represents the parameters of each preprocessing.
But are preprocessing processes themselves applied definite? For example, are `random_perspective` and `mosaic` applied 100% to all images in each epoch? Or is there some probability of application?
I would be grateful for your reply. Thanks in advance.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13305/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13305/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13303,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13303/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13303/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13303/events,https://github.com/ultralytics/yolov5/issues/13303,2512995521,I_kwDOD8jP_s6VyUTB,13303, Error During TensorFlow SavedModel and TFLite Export: TFDetect.__init__() got multiple values for argument 'w' and 'NoneType' object has no attribute 'outputs',"{'login': 'computerVision3', 'id': 178974182, 'node_id': 'U_kgDOCqrt5g', 'avatar_url': 'https://avatars.githubusercontent.com/u/178974182?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/computerVision3', 'html_url': 'https://github.com/computerVision3', 'followers_url': 'https://api.github.com/users/computerVision3/followers', 'following_url': 'https://api.github.com/users/computerVision3/following{/other_user}', 'gists_url': 'https://api.github.com/users/computerVision3/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/computerVision3/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/computerVision3/subscriptions', 'organizations_url': 'https://api.github.com/users/computerVision3/orgs', 'repos_url': 'https://api.github.com/users/computerVision3/repos', 'events_url': 'https://api.github.com/users/computerVision3/events{/privacy}', 'received_events_url': 'https://api.github.com/users/computerVision3/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-09-09T06:07:09Z,2024-10-27T13:30:39Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I encountered errors while attempting to export a YOLOv5 model to TensorFlow SavedModel and TFLite formats. The model is a YOLOv5 with FPN, and the export process fails with the following errors:

`TensorFlow SavedModel: export failure ❌ 1.5s: TFDetect.__init__() got multiple values for argument 'w'`

`TensorFlow Lite: export failure ❌ 0.0s: 'NoneType' object has no attribute 'call'
Traceback (most recent call last):
  File ""/home/ai/Masood/Pipes/yolov5_old/export.py"", line 1542, in <module>
    main(opt)
  File ""/home/ai/Masood/Pipes/yolov5_old/export.py"", line 1537, in main
    run(**vars(opt))
  File ""/home/ai/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py"", line 116, in decorate_context
    return func(*args, **kwargs)
  File ""/home/ai/Masood/Pipes/yolov5_old/export.py"", line 1450, in run
    add_tflite_metadata(f[8] or f[7], metadata, num_outputs=len(s_model.outputs))
AttributeError: 'NoneType' object has no attribute 'outputs'`



### Additional

# yolov5fpn.yaml
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple
anchors:
  - [5, 7, 10, 13, 16, 20]  # P2/4
  - [57.5, 42.0, 46.99, 36.0, 23.99, 17.5] # P3/8
  - [30, 61, 62, 45, 59, 119]  # P4/16
  - [152, 110, 165, 115, 181, 120] # P5/32

### YOLOv5 v6.0 backbone
backbone:
  [
    [-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
    [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
    [-1, 3, C3, [128]],
    [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
    [-1, 6, C3, [256]],
    [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
    [-1, 9, C3, [512]],
    [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
    [-1, 3, C3, [1024]],
    [-1, 1, SPPF, [1024, 5]],  # 9
  ]

### YOLOv5 v6.0 FPN head
head: [
    [-1, 3, C3, [1024, False]],  # 10 (P5/32-large)
    
    [-1, 1, nn.Upsample, [None, 2, ""nearest""]],
    [[-1, 6], 1, Concat, [1]],  # cat backbone P4
    [-1, 1, Conv, [512, 1, 1]],
    [-1, 3, C3, [512, False]],  # 14 (P4/16-medium)
    
    [-1, 1, nn.Upsample, [None, 2, ""nearest""]],
    [[-1, 4], 1, Concat, [1]],  # cat backbone P3
    [-1, 1, Conv, [256, 1, 1]],
    [-1, 3, C3, [256, False]],  # 18 (P3/8-small)

    # Add a new layer for P2/4 detection
    [-1, 1, nn.Upsample, [None, 2, ""nearest""]],
    [[-1, 2], 1, Concat, [1]],  # cat backbone P2
    [-1, 1, Conv, [128, 1, 1]],
    [-1, 3, C3, [128, False]],  # 22 P2/4-small
    
    # [[18, 14, 10], 1, Detect, [nc, anchors, [128, 256, 512, 1024]]],  # Detect(P3, P4, P5)
    [[22, 18, 14, 10], 1, Detect, [nc, anchors, [128, 256, 512, 1024]]]  # Detect(P2, P3, P4, P5)
]",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13303/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13303/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13302,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13302/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13302/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13302/events,https://github.com/ultralytics/yolov5/issues/13302,2512133258,I_kwDOD8jP_s6VvByK,13302,RuntimeError: The size of tensor a (80) must match the size of tensor b (60) at non-singleton dimension 3,"{'login': 'haniraid', 'id': 102861060, 'node_id': 'U_kgDOBiGJBA', 'avatar_url': 'https://avatars.githubusercontent.com/u/102861060?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/haniraid', 'html_url': 'https://github.com/haniraid', 'followers_url': 'https://api.github.com/users/haniraid/followers', 'following_url': 'https://api.github.com/users/haniraid/following{/other_user}', 'gists_url': 'https://api.github.com/users/haniraid/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/haniraid/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/haniraid/subscriptions', 'organizations_url': 'https://api.github.com/users/haniraid/orgs', 'repos_url': 'https://api.github.com/users/haniraid/repos', 'events_url': 'https://api.github.com/users/haniraid/events{/privacy}', 'received_events_url': 'https://api.github.com/users/haniraid/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,4,2024-09-08T00:33:49Z,2024-10-27T13:30:40Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Detection

### Bug

i tried to train my yolov5 on this dataset
https://www.kaggle.com/datasets/thepbordin/indoor-object-detection/data
and after i tried to run the detection using ros2 node with robomaster s1 monocular camera im having this issue and i cant get rid of it
ros2_ws/src/YOLOv5-ROS/yolov5_ros/yolov5_ros$ ros2 launch yolov5_ros yolov5s_simple.launch.py
[INFO] [launch]: All log files can be found below /home/raidhani/.ros/log/2024-09-07-20-24-29-467496-raidhani-All-Series-149777
[INFO] [launch]: Default logging verbosity is set to INFO
[INFO] [v4l2_camera_node-1]: process started with pid [149780]
[INFO] [yolov5_ros-2]: process started with pid [149782]
[v4l2_camera_node-1] [ERROR] [1725755069.564331567] [v4l2_camera]: Failed opening device /dev/video0: No such file or directory (2)
[yolov5_ros-2] YOLOv5 🚀 2024-9-2 torch 1.11.0+cpu CPU
[yolov5_ros-2] 
[yolov5_ros-2] Loading config/best.torchscript for TorchScript inference...
[yolov5_ros-2] Traceback (most recent call last):
[yolov5_ros-2]   File ""/home/raidhani/ros2_ws/src/YOLOv5-ROS/yolov5_ros/install/yolov5_ros/lib/yolov5_ros/yolov5_ros"", line 33, in <module>
[yolov5_ros-2]     sys.exit(load_entry_point('yolov5-ros', 'console_scripts', 'yolov5_ros')())
[yolov5_ros-2]   File ""/home/raidhani/ros2_ws/src/YOLOv5-ROS/yolov5_ros/build/yolov5_ros/yolov5_ros/main.py"", line 283, in ros_main
[yolov5_ros-2]     rclpy.spin(yolov5_node)
[yolov5_ros-2]   File ""/opt/ros/foxy/lib/python3.8/site-packages/rclpy/__init__.py"", line 191, in spin
[yolov5_ros-2]     executor.spin_once()
[yolov5_ros-2]   File ""/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py"", line 719, in spin_once
[yolov5_ros-2]     raise handler.exception()
[yolov5_ros-2]   File ""/opt/ros/foxy/lib/python3.8/site-packages/rclpy/task.py"", line 239, in __call__
[yolov5_ros-2]     self._handler.send(None)
[yolov5_ros-2]   File ""/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py"", line 429, in handler
[yolov5_ros-2]     await call_coroutine(entity, arg)
[yolov5_ros-2]   File ""/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py"", line 354, in _execute_subscription
[yolov5_ros-2]     await await_or_execute(sub.callback, msg)
[yolov5_ros-2]   File ""/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py"", line 118, in await_or_execute
[yolov5_ros-2]     return callback(*args)
[yolov5_ros-2]   File ""/home/raidhani/ros2_ws/src/YOLOv5-ROS/yolov5_ros/build/yolov5_ros/yolov5_ros/main.py"", line 269, in image_callback
[yolov5_ros-2]     class_list, confidence_list, x_min_list, y_min_list, x_max_list, y_max_list = self.yolov5.image_callback(image_raw)
[yolov5_ros-2]   File ""/home/raidhani/ros2_ws/src/YOLOv5-ROS/yolov5_ros/build/yolov5_ros/yolov5_ros/main.py"", line 128, in image_callback
[yolov5_ros-2]     pred = self.model(im, augment=False, visualize=False)
[yolov5_ros-2]   File ""/home/raidhani/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1110, in _call_impl
[yolov5_ros-2]     return forward_call(*input, **kwargs)
[yolov5_ros-2]   File ""/home/raidhani/ros2_ws/src/YOLOv5-ROS/yolov5_ros/build/yolov5_ros/yolov5_ros/models/common.py"", line 416, in forward
[yolov5_ros-2]     y = self.model(im)[0]
[yolov5_ros-2]   File ""/home/raidhani/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1110, in _call_impl
[yolov5_ros-2]     return forward_call(*input, **kwargs)
[yolov5_ros-2] RuntimeError: The following operation failed in the TorchScript interpreter.
[yolov5_ros-2] Traceback of TorchScript, serialized code (most recent call last):
[yolov5_ros-2]   File ""code/__torch__/models/yolo.py"", line 78, in forward
[yolov5_ros-2]     _36 = (_20).forward(act, _35, )
[yolov5_ros-2]     _37 = (_22).forward((_21).forward(act, _36, ), _30, )
[yolov5_ros-2]     _38 = (_24).forward(_34, _36, (_23).forward(_37, ), )
[yolov5_ros-2]            ~~~~~~~~~~~~ <--- HERE
[yolov5_ros-2]     return (_38,)
[yolov5_ros-2] class Detect(Module):
[yolov5_ros-2]   File ""code/__torch__/models/yolo.py"", line 108, in forward
[yolov5_ros-2]     _20 = torch.split_with_sizes(torch.sigmoid(_19), [2, 2, 11], 4)
[yolov5_ros-2]     xy, wh, conf, = _20
[yolov5_ros-2]     _21 = torch.add(torch.mul(xy, CONSTANTS.c0), CONSTANTS.c1)
[yolov5_ros-2]           ~~~~~~~~~ <--- HERE
[yolov5_ros-2]     xy0 = torch.mul(_21, torch.select(CONSTANTS.c2, 0, 0))
[yolov5_ros-2]     _22 = torch.pow(torch.mul(wh, CONSTANTS.c0), 2)
[yolov5_ros-2] 
[yolov5_ros-2] Traceback of TorchScript, original code (most recent call last):
[yolov5_ros-2] /home/raidhani/ros2_ws/src/yolov5/models/yolo.py(111): forward
[yolov5_ros-2] /home/raidhani/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward
[yolov5_ros-2] /home/raidhani/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl
[yolov5_ros-2] /home/raidhani/ros2_ws/src/yolov5/models/yolo.py(169): _forward_once
[yolov5_ros-2] /home/raidhani/ros2_ws/src/yolov5/models/yolo.py(270): forward
[yolov5_ros-2] /home/raidhani/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward
[yolov5_ros-2] /home/raidhani/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl
[yolov5_ros-2] /home/raidhani/.local/lib/python3.8/site-packages/torch/jit/_trace.py(958): trace_module
[yolov5_ros-2] /home/raidhani/.local/lib/python3.8/site-packages/torch/jit/_trace.py(741): trace
[yolov5_ros-2] export.py(274): export_torchscript
[yolov5_ros-2] export.py(218): outer_func
[yolov5_ros-2] export.py(1414): run
[yolov5_ros-2] /home/raidhani/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py(27): decorate_context
[yolov5_ros-2] export.py(1536): main
[yolov5_ros-2] export.py(1541): <module>
[yolov5_ros-2] RuntimeError: The size of tensor a (80) must match the size of tensor b (60) at non-singleton dimension 3
[yolov5_ros-2] 
[ERROR] [yolov5_ros-2]: process has died [pid 149782, exit code 1, cmd '/home/raidhani/ros2_ws/src/YOLOv5-ROS/yolov5_ros/install/yolov5_ros/lib/yolov5_ros/yolov5_ros --ros-args --params-file /tmp/launch_params_s6m3axfb'].
^C[WARNING] [launch]: user interrupted with ctrl-c (SIGINT)


### Environment

Yolov5 with ros2 wrapper on ubuntu 20.04 using libtorch 1.11.0+cpu

### Minimal Reproducible Example

RuntimeError: The size of tensor a (80) must match the size of tensor b (60) at non-singleton dimension 3

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13302/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13302/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13298,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13298/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13298/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13298/events,https://github.com/ultralytics/yolov5/issues/13298,2505668662,I_kwDOD8jP_s6VWXg2,13298,background color of image and other causes?,"{'login': 'pratikshac15', 'id': 90720404, 'node_id': 'MDQ6VXNlcjkwNzIwNDA0', 'avatar_url': 'https://avatars.githubusercontent.com/u/90720404?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/pratikshac15', 'html_url': 'https://github.com/pratikshac15', 'followers_url': 'https://api.github.com/users/pratikshac15/followers', 'following_url': 'https://api.github.com/users/pratikshac15/following{/other_user}', 'gists_url': 'https://api.github.com/users/pratikshac15/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/pratikshac15/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/pratikshac15/subscriptions', 'organizations_url': 'https://api.github.com/users/pratikshac15/orgs', 'repos_url': 'https://api.github.com/users/pratikshac15/repos', 'events_url': 'https://api.github.com/users/pratikshac15/events{/privacy}', 'received_events_url': 'https://api.github.com/users/pratikshac15/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-09-04T15:17:53Z,2024-09-05T07:33:13Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, @glenn-jocher I am training my image samples that contain particles on a white background, but I am testing the model with images that have a black background and completely different dataset. What could be the reasons why the model is unable to detect the particles on the black background? Even when it does detect something, it ends up detecting the entire image or a large portion of the black area. 

Attached files are some training images..
![LUCID_ATX081S-C_221200016__20240716123434318_image96_jpg rf ffd7ca0407b5c46ebcb2d09fadaecc9b](https://github.com/user-attachments/assets/338220e8-f24e-421a-971f-4298d221ace9)
![LUCID_ATX081S-C_221200016__20240716123859782_image114_jpg rf a6c72d23e8a6556c9198b7b92fdee914](https://github.com/user-attachments/assets/a8f6e0f2-3661-49a0-a274-7304d2516e4c)
![LUCID_ATX081S-C_221200016__20240716124824500_image143_jpg rf 132c1d4da33a57c1a027c106bf96da25](https://github.com/user-attachments/assets/6c17802b-022e-465a-aef9-1e7f529865d9)
![LUCID_ATX081S-C_221200016__20240716124843398_image145_jpg rf 9e3244418077155e74ff893345323938](https://github.com/user-attachments/assets/487db3cc-82fd-4461-8aaa-36d4f39f78ba)
![LUCID_ATX081S-C_221200016__20240716131625093_image226_jpg rf 4f8ceb738680a20705191d01d659ce99](https://github.com/user-attachments/assets/418781a4-f1a6-4b1e-889a-9e3129d033aa)
![LUCID_ATX081S-C_221200016__20240716142839990_image245_jpg rf 3cd5edd76a681cf8fd41f157ddf61194](https://github.com/user-attachments/assets/63a36562-4fbd-4f18-96b9-0a751a8c43f3)


Test images
![0509-0001](https://github.com/user-attachments/assets/6a13bc95-96dc-4ec2-a6b8-2b6ef8a4b576)
![0509-0002](https://github.com/user-attachments/assets/e9363bdd-3bcb-4f4f-83cf-9927189dc919)
![0509-0006](https://github.com/user-attachments/assets/74887bc5-5e90-45fe-bcb0-10e9cd66a35e)
![0509-0013](https://github.com/user-attachments/assets/a118ed91-b055-42e4-854a-fbc2ea0d0f80)
![0509-0027](https://github.com/user-attachments/assets/3e2c0313-5686-4d5b-a9e2-29bba3ab1a49)
![0510-0033](https://github.com/user-attachments/assets/5767ae9d-f17f-4cb1-9f0e-5769af8fdafd)
 ..





### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13298/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13298/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13297,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13297/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13297/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13297/events,https://github.com/ultralytics/yolov5/issues/13297,2504798634,I_kwDOD8jP_s6VTDGq,13297,Facing issues while changing class ID values,"{'login': 'RaushanSharma7', 'id': 180400275, 'node_id': 'U_kgDOCsCwkw', 'avatar_url': 'https://avatars.githubusercontent.com/u/180400275?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/RaushanSharma7', 'html_url': 'https://github.com/RaushanSharma7', 'followers_url': 'https://api.github.com/users/RaushanSharma7/followers', 'following_url': 'https://api.github.com/users/RaushanSharma7/following{/other_user}', 'gists_url': 'https://api.github.com/users/RaushanSharma7/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/RaushanSharma7/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/RaushanSharma7/subscriptions', 'organizations_url': 'https://api.github.com/users/RaushanSharma7/orgs', 'repos_url': 'https://api.github.com/users/RaushanSharma7/repos', 'events_url': 'https://api.github.com/users/RaushanSharma7/events{/privacy}', 'received_events_url': 'https://api.github.com/users/RaushanSharma7/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-09-04T09:31:49Z,2024-09-05T02:33:51Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I'm currently using the Xtreme1 tool for creating classes in the ontology section. I’m facing a couple of challenges and would appreciate any help:
 
Manual Assignment of Class IDs:

When I create a new class, the Class IDs are automatically assigned in sequential order. However, I need to assign specific Class IDs manually. Is there a way to override the automatic assignment and set the Class ID myself?
 
Managing Class ID Sequence After Deleting Datasets:

After deleting a dataset, Xtreme1 continues to track the previously generated Class IDs, and new classes are assigned the next available number. How can I reset or fix the Class ID sequence so that I can reuse or specify certain IDs?
 
Has anyone encountered similar issues, or does anyone know how to configure these settings?
 

 

### Additional

if anyone know the output the kindly reply here.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13297/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13297/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13296,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13296/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13296/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13296/events,https://github.com/ultralytics/yolov5/issues/13296,2504587709,I_kwDOD8jP_s6VSPm9,13296,challenges faced in Xtream1 tool while creating class ID's,"{'login': 'AbrahamRoshan', 'id': 180389027, 'node_id': 'U_kgDOCsCEow', 'avatar_url': 'https://avatars.githubusercontent.com/u/180389027?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AbrahamRoshan', 'html_url': 'https://github.com/AbrahamRoshan', 'followers_url': 'https://api.github.com/users/AbrahamRoshan/followers', 'following_url': 'https://api.github.com/users/AbrahamRoshan/following{/other_user}', 'gists_url': 'https://api.github.com/users/AbrahamRoshan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AbrahamRoshan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AbrahamRoshan/subscriptions', 'organizations_url': 'https://api.github.com/users/AbrahamRoshan/orgs', 'repos_url': 'https://api.github.com/users/AbrahamRoshan/repos', 'events_url': 'https://api.github.com/users/AbrahamRoshan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AbrahamRoshan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-09-04T07:58:10Z,2024-09-04T10:56:08Z,,NONE,,"### Search before asking

- [ ] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I'm currently using the Xtreme1 tool for creating classes in the ontology section. I’m facing a couple of challenges and would appreciate any help:
 
Manual Assignment of Class IDs:
When I create a new class, the Class IDs are automatically assigned in sequential order. However, I need to assign specific Class IDs manually. Is there a way to override the automatic assignment and set the Class ID myself?
 
Managing Class ID Sequence After Deleting Datasets:
After deleting a dataset, Xtreme1 continues to track the previously generated Class IDs, and new classes are assigned the next available number. How can I reset or fix the Class ID sequence so that I can reuse or specify certain IDs?
 
Has anyone encountered similar issues, or does anyone know how to configure these settings?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13296/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13296/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13295,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13295/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13295/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13295/events,https://github.com/ultralytics/yolov5/issues/13295,2503778434,I_kwDOD8jP_s6VPKCC,13295,Yolov5 inventing label on validation set,"{'login': 'tomhoq', 'id': 63908353, 'node_id': 'MDQ6VXNlcjYzOTA4MzUz', 'avatar_url': 'https://avatars.githubusercontent.com/u/63908353?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/tomhoq', 'html_url': 'https://github.com/tomhoq', 'followers_url': 'https://api.github.com/users/tomhoq/followers', 'following_url': 'https://api.github.com/users/tomhoq/following{/other_user}', 'gists_url': 'https://api.github.com/users/tomhoq/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/tomhoq/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/tomhoq/subscriptions', 'organizations_url': 'https://api.github.com/users/tomhoq/orgs', 'repos_url': 'https://api.github.com/users/tomhoq/repos', 'events_url': 'https://api.github.com/users/tomhoq/events{/privacy}', 'received_events_url': 'https://api.github.com/users/tomhoq/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,3,2024-09-03T21:00:48Z,2024-10-27T13:30:40Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Validation

### Bug

I noticed on one of the val batch files after training yolov5l that some of the images in the val_batch_labels.jpg had labels in them that weren't supposed to be there. I checked the label file of the image where I saw it happen and it was correct, so where did the new labels come from?

### Environment

yolov5l - OS: Windows 10, Python 3.12.3

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13295/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13295/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13292,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13292/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13292/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13292/events,https://github.com/ultralytics/yolov5/issues/13292,2501458898,I_kwDOD8jP_s6VGTvS,13292,Low disk space causes memory leak,"{'login': 'oliver408i', 'id': 75344601, 'node_id': 'MDQ6VXNlcjc1MzQ0NjAx', 'avatar_url': 'https://avatars.githubusercontent.com/u/75344601?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/oliver408i', 'html_url': 'https://github.com/oliver408i', 'followers_url': 'https://api.github.com/users/oliver408i/followers', 'following_url': 'https://api.github.com/users/oliver408i/following{/other_user}', 'gists_url': 'https://api.github.com/users/oliver408i/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/oliver408i/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/oliver408i/subscriptions', 'organizations_url': 'https://api.github.com/users/oliver408i/orgs', 'repos_url': 'https://api.github.com/users/oliver408i/repos', 'events_url': 'https://api.github.com/users/oliver408i/events{/privacy}', 'received_events_url': 'https://api.github.com/users/oliver408i/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,3,2024-09-02T18:45:00Z,2024-10-27T13:30:41Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Training

### Bug

Having only a few gbs of disk space left when running yolov5's train.py causes a memory leak that will cause the computer to lag and eventually kill the yolov5 process. For example, I had ~2 gb of disk space left, and the after a few epochs of training, the ""out of application memory"" prompt starts popping up, and after a few more epochs, the process is killed by the system for using too much ram.

### Environment

YOLOv5 🚀 v7.0-358-gc07b9a8b Python-3.12.5 torch-2.4.0 MPS
MacOS 15. Macbook pro m2 (16 GB ram)

### Minimal Reproducible Example

Simply run a decently large dataset (in my case, 300 images) on at least 10 epochs. Using CPU or mps doesn't matter in this case.

### Additional

I'm not sure if this is a global problem or just with Macos specifically, as I haven't been able to test it out. I suggest the program to warn the user about low disk space, because the system ram warning made it seem like it was my ram at fault instead of my disk space. Everything works as normal after I cleared up the disk space, using the exact same setup as before.

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13292/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13292/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13291,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13291/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13291/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13291/events,https://github.com/ultralytics/yolov5/issues/13291,2500146866,I_kwDOD8jP_s6VBTay,13291,"tried to run yolov5 ""detect.py"" with pretrained model yolov8x.pt and xView.yaml","{'login': 'plt2mek', 'id': 17291549, 'node_id': 'MDQ6VXNlcjE3MjkxNTQ5', 'avatar_url': 'https://avatars.githubusercontent.com/u/17291549?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/plt2mek', 'html_url': 'https://github.com/plt2mek', 'followers_url': 'https://api.github.com/users/plt2mek/followers', 'following_url': 'https://api.github.com/users/plt2mek/following{/other_user}', 'gists_url': 'https://api.github.com/users/plt2mek/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/plt2mek/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/plt2mek/subscriptions', 'organizations_url': 'https://api.github.com/users/plt2mek/orgs', 'repos_url': 'https://api.github.com/users/plt2mek/repos', 'events_url': 'https://api.github.com/users/plt2mek/events{/privacy}', 'received_events_url': 'https://api.github.com/users/plt2mek/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,1,2024-09-02T06:50:31Z,2024-10-27T13:30:42Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug


///////////////////////////////////////////////////////////////
My results 👍 
//////////////////////////////////////////////////////////////
detect: weights=yolov8x.pt, source=E:\IA\splitting_3, data=data\xView.yaml, imgsz=[1024, 1024], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5  2024-8-28 Python-3.9.7 torch-2.4.0+cpu CPU

Traceback (most recent call last):
  File ""I:\pythonProject5\detect.py"", line 442, in <module>
    main(opt)
  File ""I:\pythonProject5\detect.py"", line 437, in main
    run(**vars(opt))
  File ""I:\pythonProject5\.venv\lib\site-packages\torch\utils\_contextlib.py"", line 116, in decorate_context
    return func(*args, **kwargs)
  File ""I:\pythonProject5\detect.py"", line 168, in run
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
  File ""I:\pythonProject5\models\common.py"", line 489, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""I:\pythonProject5\models\experimental.py"", line 98, in attempt_load
    ckpt = torch.load(attempt_download(w), map_location=""cpu"")  # load
  File ""I:\pythonProject5\.venv\lib\site-packages\ultralytics\utils\patches.py"", line 86, in torch_load
    return _torch_load(*args, **kwargs)
  File ""I:\pythonProject5\.venv\lib\site-packages\torch\serialization.py"", line 1065, in load
    with _open_file_like(f, 'rb') as opened_file:
  File ""I:\pythonProject5\.venv\lib\site-packages\torch\serialization.py"", line 468, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File ""I:\pythonProject5\.venv\lib\site-packages\torch\serialization.py"", line 449, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'yolov8x.pt'

### Environment

_No response_

### Minimal Reproducible Example

my changes in the default code :
 parser.add_argument(""--weights"", nargs=""+"", type=str, default=ROOT / ""yolov8x.pt"", help=""model path or triton URL"")
    #parser.add_argument(""--source"", type=str, default=ROOT / ""data/images"", help=""file/dir/URL/glob/screen/0(webcam)"")
    parser.add_argument(""--source"", type=str, default= ""E:\IA\splitting_3"", help=""file/dir/URL/glob/screen/0(webcam)"")
    parser.add_argument(""--data"", type=str, default=ROOT / ""data/xView.yaml"", help=""(optional) dataset.yaml path"")

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13291/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13291/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13281,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13281/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13281/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13281/events,https://github.com/ultralytics/yolov5/issues/13281,2485346764,I_kwDOD8jP_s6UI2HM,13281,incorrect detections for cars after fine-tuning yolov5l,"{'login': 'anisha150213', 'id': 20923342, 'node_id': 'MDQ6VXNlcjIwOTIzMzQy', 'avatar_url': 'https://avatars.githubusercontent.com/u/20923342?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/anisha150213', 'html_url': 'https://github.com/anisha150213', 'followers_url': 'https://api.github.com/users/anisha150213/followers', 'following_url': 'https://api.github.com/users/anisha150213/following{/other_user}', 'gists_url': 'https://api.github.com/users/anisha150213/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/anisha150213/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/anisha150213/subscriptions', 'organizations_url': 'https://api.github.com/users/anisha150213/orgs', 'repos_url': 'https://api.github.com/users/anisha150213/repos', 'events_url': 'https://api.github.com/users/anisha150213/events{/privacy}', 'received_events_url': 'https://api.github.com/users/anisha150213/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-08-25T15:55:24Z,2024-10-27T13:30:42Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi, 
I fine-tuned the yolov5l model with a custom dataset. Images are from paranoma video. I have two training classes: car and person and around 8k images, the number of instances of car is approximately 6k. The original image dimension is 1980x1080 and trained with 640x640. 
I trained my model with 50, 100, 300, 400 and 500. With all the models, I faced the same issue.  I used different iou-threshold in testing. But nothing worked that much. Can anyone please explain why fine-tuning is not providing better results?
Please take a look at the attachment for reference (screenshot).
[reference_yolov5l.zip](https://github.com/user-attachments/files/16741023/reference_yolov5l.zip)

Thanks

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13281/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13281/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13280,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13280/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13280/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13280/events,https://github.com/ultralytics/yolov5/issues/13280,2485312633,I_kwDOD8jP_s6UItx5,13280,Split features map of data,"{'login': 'letriluan', 'id': 75682959, 'node_id': 'MDQ6VXNlcjc1NjgyOTU5', 'avatar_url': 'https://avatars.githubusercontent.com/u/75682959?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/letriluan', 'html_url': 'https://github.com/letriluan', 'followers_url': 'https://api.github.com/users/letriluan/followers', 'following_url': 'https://api.github.com/users/letriluan/following{/other_user}', 'gists_url': 'https://api.github.com/users/letriluan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/letriluan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/letriluan/subscriptions', 'organizations_url': 'https://api.github.com/users/letriluan/orgs', 'repos_url': 'https://api.github.com/users/letriluan/repos', 'events_url': 'https://api.github.com/users/letriluan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/letriluan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-08-25T14:54:59Z,2024-08-25T23:20:44Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi everyone,

I am working with two types of data: RGB and IR images. I want to apply the CSSA method (as described in this repository: [CSSA GitHub](https://github.com/artrela/mulitmodal-cssa/tree/main)). To do this, I need to extract feature maps from the data before feeding them into the CSSA model. I want to apply CSSA before C3 stage on the image below.

Could you please advise on the best way to split the RGB and IR data within the pipeline? Additionally, which specific files or parts of the codebase would need modification to implement this process effectively?

Thanks in advance for your help!

![z5766315506026_8c3d4b6213254826830eaa65c9a493f3](https://github.com/user-attachments/assets/b861731a-24b3-4ef2-980e-af57f4d59fd3)


![686898a0-ee48-4d27-a33b-19b7d7923d09](https://github.com/user-attachments/assets/bef92478-d0a4-4c88-a32f-7b5d6d9bbe0d)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13280/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13280/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13274,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13274/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13274/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13274/events,https://github.com/ultralytics/yolov5/issues/13274,2482407247,I_kwDOD8jP_s6T9odP,13274,Artificial Neural Network - interpreting model.save output,"{'login': 'Vin-G', 'id': 179201847, 'node_id': 'U_kgDOCq5nNw', 'avatar_url': 'https://avatars.githubusercontent.com/u/179201847?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Vin-G', 'html_url': 'https://github.com/Vin-G', 'followers_url': 'https://api.github.com/users/Vin-G/followers', 'following_url': 'https://api.github.com/users/Vin-G/following{/other_user}', 'gists_url': 'https://api.github.com/users/Vin-G/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Vin-G/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Vin-G/subscriptions', 'organizations_url': 'https://api.github.com/users/Vin-G/orgs', 'repos_url': 'https://api.github.com/users/Vin-G/repos', 'events_url': 'https://api.github.com/users/Vin-G/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Vin-G/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-08-23T06:25:35Z,2024-10-27T13:30:43Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have implemented an Artificial Neural Network... for a regression problem with 2 hidden layers (activation PRelU). I have saved my model in an hdf5 file and am trying to interpret the results from model.save (kernel, bias, and alpha)... I can see the tables, heatmap, and charts of these. Now, how do I interpret them and understand which nodes are useful, do I need to change the bias etc.?

Tried reading many online resources, but haven't found anything very useful on what my next steps should be.

![kernel1](https://github.com/user-attachments/assets/476ccb60-5d8c-4c48-81a6-edd178730778)
![kernel](https://github.com/user-attachments/assets/5c0f002a-c55d-4b1d-b8d5-8ddda73c1f7d)
![bias](https://github.com/user-attachments/assets/c69d8091-83e0-4c3a-87ad-e9c31f632205)
![alpha](https://github.com/user-attachments/assets/a3b61658-c476-4c9d-a0fc-460678bd7508)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13274/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13274/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13273,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13273/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13273/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13273/events,https://github.com/ultralytics/yolov5/issues/13273,2482152221,I_kwDOD8jP_s6T8qMd,13273,Installation on Windows 7 32 bits,"{'login': 'KnightInsight', 'id': 129138747, 'node_id': 'U_kgDOB7KAOw', 'avatar_url': 'https://avatars.githubusercontent.com/u/129138747?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/KnightInsight', 'html_url': 'https://github.com/KnightInsight', 'followers_url': 'https://api.github.com/users/KnightInsight/followers', 'following_url': 'https://api.github.com/users/KnightInsight/following{/other_user}', 'gists_url': 'https://api.github.com/users/KnightInsight/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/KnightInsight/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/KnightInsight/subscriptions', 'organizations_url': 'https://api.github.com/users/KnightInsight/orgs', 'repos_url': 'https://api.github.com/users/KnightInsight/repos', 'events_url': 'https://api.github.com/users/KnightInsight/events{/privacy}', 'received_events_url': 'https://api.github.com/users/KnightInsight/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,3,2024-08-23T03:12:47Z,2024-08-23T18:28:27Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi, may I know is yolov5 able to install on windows 7 32 bits?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13273/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13273/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13269,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13269/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13269/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13269/events,https://github.com/ultralytics/yolov5/issues/13269,2474622201,I_kwDOD8jP_s6Tf7z5,13269,Video inference with YOLOv5 model in python,"{'login': 'mayurkatre18', 'id': 132425375, 'node_id': 'U_kgDOB-Smnw', 'avatar_url': 'https://avatars.githubusercontent.com/u/132425375?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mayurkatre18', 'html_url': 'https://github.com/mayurkatre18', 'followers_url': 'https://api.github.com/users/mayurkatre18/followers', 'following_url': 'https://api.github.com/users/mayurkatre18/following{/other_user}', 'gists_url': 'https://api.github.com/users/mayurkatre18/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mayurkatre18/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mayurkatre18/subscriptions', 'organizations_url': 'https://api.github.com/users/mayurkatre18/orgs', 'repos_url': 'https://api.github.com/users/mayurkatre18/repos', 'events_url': 'https://api.github.com/users/mayurkatre18/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mayurkatre18/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,3,2024-08-20T03:07:44Z,2024-10-27T13:30:44Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question
I have trained yolov5 model for instance segmentation and saved model in .pt format. Now I have to make video inference from this .pt model. Please provide me solution for this.
Thank you.

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13269/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13269/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13267,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13267/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13267/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13267/events,https://github.com/ultralytics/yolov5/issues/13267,2473031439,I_kwDOD8jP_s6TZ3cP,13267,Yolov5 Int8 export in PyTorch,"{'login': 'Praveen-mvp', 'id': 78363617, 'node_id': 'MDQ6VXNlcjc4MzYzNjE3', 'avatar_url': 'https://avatars.githubusercontent.com/u/78363617?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Praveen-mvp', 'html_url': 'https://github.com/Praveen-mvp', 'followers_url': 'https://api.github.com/users/Praveen-mvp/followers', 'following_url': 'https://api.github.com/users/Praveen-mvp/following{/other_user}', 'gists_url': 'https://api.github.com/users/Praveen-mvp/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Praveen-mvp/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Praveen-mvp/subscriptions', 'organizations_url': 'https://api.github.com/users/Praveen-mvp/orgs', 'repos_url': 'https://api.github.com/users/Praveen-mvp/repos', 'events_url': 'https://api.github.com/users/Praveen-mvp/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Praveen-mvp/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,10,2024-08-19T10:36:36Z,2024-10-27T13:30:44Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

Exporting my model into PyTorch itself

### Use case

Hi Team , I would like to have code or command for exporting my model in Int8 but in Pytorch istself , So is there any way or code for doing it , Bzc i can able to save my model in pytorch itself on YoloV8 by

torch.save(model.export(format=""onnx"", int8=True), 'yolo-quant.pt')

But i tried these same step on YoloV5 but i can't able to convert it. So Please share your knoweledge regarding this.

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!","{'login': 'Praveen-mvp', 'id': 78363617, 'node_id': 'MDQ6VXNlcjc4MzYzNjE3', 'avatar_url': 'https://avatars.githubusercontent.com/u/78363617?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Praveen-mvp', 'html_url': 'https://github.com/Praveen-mvp', 'followers_url': 'https://api.github.com/users/Praveen-mvp/followers', 'following_url': 'https://api.github.com/users/Praveen-mvp/following{/other_user}', 'gists_url': 'https://api.github.com/users/Praveen-mvp/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Praveen-mvp/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Praveen-mvp/subscriptions', 'organizations_url': 'https://api.github.com/users/Praveen-mvp/orgs', 'repos_url': 'https://api.github.com/users/Praveen-mvp/repos', 'events_url': 'https://api.github.com/users/Praveen-mvp/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Praveen-mvp/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13267/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13267/timeline,,reopened,,
https://api.github.com/repos/ultralytics/yolov5/issues/13265,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13265/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13265/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13265/events,https://github.com/ultralytics/yolov5/issues/13265,2472096401,I_kwDOD8jP_s6TWTKR,13265,A Error which blast my mind....,"{'login': 'sumansingh-coder', 'id': 70953348, 'node_id': 'MDQ6VXNlcjcwOTUzMzQ4', 'avatar_url': 'https://avatars.githubusercontent.com/u/70953348?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/sumansingh-coder', 'html_url': 'https://github.com/sumansingh-coder', 'followers_url': 'https://api.github.com/users/sumansingh-coder/followers', 'following_url': 'https://api.github.com/users/sumansingh-coder/following{/other_user}', 'gists_url': 'https://api.github.com/users/sumansingh-coder/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/sumansingh-coder/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/sumansingh-coder/subscriptions', 'organizations_url': 'https://api.github.com/users/sumansingh-coder/orgs', 'repos_url': 'https://api.github.com/users/sumansingh-coder/repos', 'events_url': 'https://api.github.com/users/sumansingh-coder/events{/privacy}', 'received_events_url': 'https://api.github.com/users/sumansingh-coder/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,1,2024-08-18T18:41:32Z,2024-08-19T06:09:49Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

Tried onnx version 17 and version 12 still the same error
![Screenshot from 2024-08-19 00-08-52](https://github.com/user-attachments/assets/435c5da7-0c15-4db5-aa10-565d89fc02a1)


Here is the code

#include <fstream>

#include <opencv2/opencv.hpp>

std::vector<std::string> load_class_list()
{
    std::vector<std::string> class_list;
    std::ifstream ifs(""/home/suman-singh/Downloads/yolov5-master/temp.txt"");
    std::string line;
    while (getline(ifs, line))
    {
        class_list.push_back(line);
    }
    return class_list;
}

void load_net(cv::dnn::Net &net, bool is_cuda)
{
    auto result = cv::dnn::readNet(""/home/suman-singh/Downloads/yolov5-master/yolov5s.onnx"");
    if (is_cuda)
    {
        std::cout << ""Attempty to use CUDA\n"";
        result.setPreferableBackend(cv::dnn::DNN_BACKEND_CUDA);
        result.setPreferableTarget(cv::dnn::DNN_TARGET_CUDA_FP16);
    }
    else
    {
        std::cout << ""Running on CPU\n"";
        result.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);
        result.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);
    }
    net = result;
}

const std::vector<cv::Scalar> colors = {cv::Scalar(255, 255, 0), cv::Scalar(0, 255, 0), cv::Scalar(0, 255, 255), cv::Scalar(255, 0, 0)};

const float INPUT_WIDTH = 640.0;
const float INPUT_HEIGHT = 640.0;
const float SCORE_THRESHOLD = 0.2;
const float NMS_THRESHOLD = 0.4;
const float CONFIDENCE_THRESHOLD = 0.4;

struct Detection
{
    int class_id;
    float confidence;
    cv::Rect box;
};

cv::Mat format_yolov5(const cv::Mat &source) {
    int col = source.cols;
    int row = source.rows;
    int _max = MAX(col, row);
    cv::Mat result = cv::Mat::zeros(_max, _max, CV_8UC3);
    source.copyTo(result(cv::Rect(0, 0, col, row)));
    return result;
}

void detect(cv::Mat &image, cv::dnn::Net &net, std::vector<Detection> &output, const std::vector<std::string> &className) {
    cv::Mat blob;

    auto input_image = format_yolov5(image);

    cv::dnn::blobFromImage(input_image, blob, 1./255., cv::Size(INPUT_WIDTH, INPUT_HEIGHT), cv::Scalar(), true, false);
    net.setInput(blob);
    std::vector<cv::Mat> outputs;
    net.forward(outputs, net.getUnconnectedOutLayersNames());

    float x_factor = input_image.cols / INPUT_WIDTH;
    float y_factor = input_image.rows / INPUT_HEIGHT;

    float *data = (float *)outputs[0].data;

    const int dimensions = 85;
    const int rows = 25200;

    std::vector<int> class_ids;
    std::vector<float> confidences;
    std::vector<cv::Rect> boxes;

    for (int i = 0; i < rows; ++i) {

        float confidence = data[4];
        if (confidence >= CONFIDENCE_THRESHOLD) {

            float * classes_scores = data + 5;
            cv::Mat scores(1, className.size(), CV_32FC1, classes_scores);
            cv::Point class_id;
            double max_class_score;
            minMaxLoc(scores, 0, &max_class_score, 0, &class_id);
            if (max_class_score > SCORE_THRESHOLD) {

                confidences.push_back(confidence);

                class_ids.push_back(class_id.x);

                float x = data[0];
                float y = data[1];
                float w = data[2];
                float h = data[3];
                int left = int((x - 0.5 * w) * x_factor);
                int top = int((y - 0.5 * h) * y_factor);
                int width = int(w * x_factor);
                int height = int(h * y_factor);
                boxes.push_back(cv::Rect(left, top, width, height));
            }

        }

        data += 85;

    }

    std::vector<int> nms_result;
    cv::dnn::NMSBoxes(boxes, confidences, SCORE_THRESHOLD, NMS_THRESHOLD, nms_result);
    for (int i = 0; i < nms_result.size(); i++) {
        int idx = nms_result[i];
        Detection result;
        result.class_id = class_ids[idx];
        result.confidence = confidences[idx];
        result.box = boxes[idx];
        output.push_back(result);
    }
}

int main(int argc, char **argv)
{

    std::vector<std::string> class_list = load_class_list();

    cv::Mat frame;
    cv::VideoCapture capture(0);

    cv::dnn::Net net;
    load_net(net, true);

    while (true)
    {
        capture.read(frame);

        std::vector<Detection> output;
        detect(frame, net, output, class_list);

        int detections = output.size();

        for (int i = 0; i < detections; ++i)
        {

            auto detection = output[i];
            auto box = detection.box;
            auto classId = detection.class_id;
            const auto color = colors[classId % colors.size()];
            cv::rectangle(frame, box, color, 3);

            cv::rectangle(frame, cv::Point(box.x, box.y - 20), cv::Point(box.x + box.width, box.y), color, cv::FILLED);
            cv::putText(frame, class_list[classId].c_str(), cv::Point(box.x, box.y - 5), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
        }

        cv::imshow(""output"", frame);

        if (cv::waitKey(1) != -1)
        {
            capture.release();
            std::cout << ""finished by user\n"";
            break;
        }
    }

    return 0;
}


### Environment

_No response_

### Minimal Reproducible Example

# i want my webcam to open and take video but it closes immediately

### Additional

Plzz help fast

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13265/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13265/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13262,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13262/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13262/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13262/events,https://github.com/ultralytics/yolov5/issues/13262,2466943997,I_kwDOD8jP_s6TCpP9,13262,"Similar mAP when splitting data into train, val and test","{'login': 'n-patricia', 'id': 5142054, 'node_id': 'MDQ6VXNlcjUxNDIwNTQ=', 'avatar_url': 'https://avatars.githubusercontent.com/u/5142054?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/n-patricia', 'html_url': 'https://github.com/n-patricia', 'followers_url': 'https://api.github.com/users/n-patricia/followers', 'following_url': 'https://api.github.com/users/n-patricia/following{/other_user}', 'gists_url': 'https://api.github.com/users/n-patricia/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/n-patricia/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/n-patricia/subscriptions', 'organizations_url': 'https://api.github.com/users/n-patricia/orgs', 'repos_url': 'https://api.github.com/users/n-patricia/repos', 'events_url': 'https://api.github.com/users/n-patricia/events{/privacy}', 'received_events_url': 'https://api.github.com/users/n-patricia/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-08-14T22:30:13Z,2024-10-27T13:30:45Z,,NONE,,"### Question

Hi,
I use yolov5x with this setting (train: 70%, val: 10%, test: 20%)
```
train: images/train  # train images (relative to 'path') 128 images
val: images/val  # val images (relative to 'path') 128 images
test: images/test # test images (optional)
``` 
I get similar mAP starts from epoch 18. The columns here are precision, recall, mAP0.5, mAP0.95.
<img width=""510"" alt=""Screen Shot 2024-08-15 at 05 20 30"" src=""https://github.com/user-attachments/assets/7339f0e8-66e0-4f69-ba7f-7a1809e315ba"">

However when I don't divide the training data, the metrics keep increasing until 300 epochs.
```
train: images/  # train images (relative to 'path') 128 images
val: images/  # val images (relative to 'path') 128 images
test: # test images (optional)
```
<img width=""520"" alt=""Screen Shot 2024-08-15 at 05 36 24"" src=""https://github.com/user-attachments/assets/a1b218e4-d30e-4fab-9afa-0e046da1176e"">

I use hyp-scratch-low for both experiments. The reason I do this is bacause I want to try my custom dataset like GlobalWheat2020 after this. Do I miss anything?


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13262/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13262/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13257,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13257/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13257/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13257/events,https://github.com/ultralytics/yolov5/issues/13257,2463186054,I_kwDOD8jP_s6S0TyG,13257,Multiple threads using yolov5 model concurrent inference failed,"{'login': 'cucyuan', 'id': 97577752, 'node_id': 'U_kgDOBdDrGA', 'avatar_url': 'https://avatars.githubusercontent.com/u/97577752?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/cucyuan', 'html_url': 'https://github.com/cucyuan', 'followers_url': 'https://api.github.com/users/cucyuan/followers', 'following_url': 'https://api.github.com/users/cucyuan/following{/other_user}', 'gists_url': 'https://api.github.com/users/cucyuan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/cucyuan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/cucyuan/subscriptions', 'organizations_url': 'https://api.github.com/users/cucyuan/orgs', 'repos_url': 'https://api.github.com/users/cucyuan/repos', 'events_url': 'https://api.github.com/users/cucyuan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/cucyuan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-08-13T12:06:27Z,2024-10-27T13:30:46Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

  When I used the yolov5 model for concurrent inference in two threads, after running for some time, the cuda occupancy suddenly reached 100%, and then the program stuck. 
  In addition, I've set inplace=False, but it doesn't work, i hope get help, thank you!!!
![1723550610576](https://github.com/user-attachments/assets/5c5d6d0b-7ea2-4280-8b55-44c6bb3f042d)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13257/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13257/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13254,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13254/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13254/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13254/events,https://github.com/ultralytics/yolov5/issues/13254,2457334020,I_kwDOD8jP_s6Sd_EE,13254,Multiple GPU Hyperparameter evolution,"{'login': 'glitchyordis', 'id': 99534415, 'node_id': 'U_kgDOBe7GTw', 'avatar_url': 'https://avatars.githubusercontent.com/u/99534415?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glitchyordis', 'html_url': 'https://github.com/glitchyordis', 'followers_url': 'https://api.github.com/users/glitchyordis/followers', 'following_url': 'https://api.github.com/users/glitchyordis/following{/other_user}', 'gists_url': 'https://api.github.com/users/glitchyordis/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glitchyordis/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glitchyordis/subscriptions', 'organizations_url': 'https://api.github.com/users/glitchyordis/orgs', 'repos_url': 'https://api.github.com/users/glitchyordis/repos', 'events_url': 'https://api.github.com/users/glitchyordis/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glitchyordis/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,5,2024-08-09T07:51:23Z,2024-08-20T16:44:13Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I've performed normal training with multiple GPU with the m6 model on 3 GPUs, and I could fit a batch_size of 57. However, when I tried the multi GPU code for hyperparameter evolution, I could only specify a batch size of about 18.

How does the multi GPU hyperparameter evolution differs from single GPU run? Does it speed up the progress?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13254/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13254/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13252,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13252/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13252/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13252/events,https://github.com/ultralytics/yolov5/issues/13252,2457102711,I_kwDOD8jP_s6SdGl3,13252,"Hi @7rkMnpl,","{'login': '7rkMnpl', 'id': 138571977, 'node_id': 'U_kgDOCEJwyQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/138571977?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/7rkMnpl', 'html_url': 'https://github.com/7rkMnpl', 'followers_url': 'https://api.github.com/users/7rkMnpl/followers', 'following_url': 'https://api.github.com/users/7rkMnpl/following{/other_user}', 'gists_url': 'https://api.github.com/users/7rkMnpl/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/7rkMnpl/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/7rkMnpl/subscriptions', 'organizations_url': 'https://api.github.com/users/7rkMnpl/orgs', 'repos_url': 'https://api.github.com/users/7rkMnpl/repos', 'events_url': 'https://api.github.com/users/7rkMnpl/events{/privacy}', 'received_events_url': 'https://api.github.com/users/7rkMnpl/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,,[],,2,2024-08-09T04:57:44Z,2024-10-27T13:30:46Z,,NONE,,"              Hi @7rkMnpl,

To integrate a custom callback with early stopping in YOLOv5, you would need to modify the training script to include your custom callback logic. Here's a general outline of how you can achieve this:

1. **Create Your Custom Callback:**
   Define your custom callback class. For example, you might want to create a callback that monitors a specific metric and stops training based on that metric.

   ```python
   class CustomEarlyStopping:
       def __init__(self, patience=10, min_delta=0):
           self.patience = patience
           self.min_delta = min_delta
           self.best_score = None
           self.counter = 0

       def __call__(self, current_score):
           if self.best_score is None:
               self.best_score = current_score
           elif current_score < self.best_score + self.min_delta:
               self.counter += 1
               if self.counter >= self.patience:
                   return True
           else:
               self.best_score = current_score
               self.counter = 0
           return False
   ```

2. **Integrate the Callback into the Training Loop:**
   Modify the training loop in `train.py` to include your custom callback. You will need to check the callback condition at the end of each epoch.

   ```python
   from train import train

   # Initialize your custom callback
   custom_early_stopping = CustomEarlyStopping(patience=10, min_delta=0.01)

   # Modify the training loop to include the callback check
   for epoch in range(epochs):
       # Training code...
       
       # Calculate your custom metric (e.g., recall)
       current_score = calculate_recall()

       # Check the custom early stopping condition
       if custom_early_stopping(current_score):
           print(f""Early stopping at epoch {epoch}"")
           break
   ```

3. **Run Your Training Script:**
   Execute your modified training script to train your YOLOv5 model with the custom early stopping callback.

This is a basic example to get you started. Depending on your specific requirements, you might need to adjust the callback logic and how you integrate it into the training loop.

Feel free to ask if you have any further questions or need additional assistance. Happy training! 😊

_Originally posted by @glenn-jocher in https://github.com/ultralytics/yolov5/issues/5561#issuecomment-2275619501_
            ",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13252/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13252/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13250,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13250/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13250/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13250/events,https://github.com/ultralytics/yolov5/issues/13250,2452936990,I_kwDOD8jP_s6SNNke,13250,What prevents me from using the AMP function？,"{'login': 'thgpddl', 'id': 48787805, 'node_id': 'MDQ6VXNlcjQ4Nzg3ODA1', 'avatar_url': 'https://avatars.githubusercontent.com/u/48787805?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/thgpddl', 'html_url': 'https://github.com/thgpddl', 'followers_url': 'https://api.github.com/users/thgpddl/followers', 'following_url': 'https://api.github.com/users/thgpddl/following{/other_user}', 'gists_url': 'https://api.github.com/users/thgpddl/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/thgpddl/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/thgpddl/subscriptions', 'organizations_url': 'https://api.github.com/users/thgpddl/orgs', 'repos_url': 'https://api.github.com/users/thgpddl/repos', 'events_url': 'https://api.github.com/users/thgpddl/events{/privacy}', 'received_events_url': 'https://api.github.com/users/thgpddl/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-08-07T08:52:11Z,2024-08-07T14:43:43Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Thank you very much for your work. I would like to be able to use the AMP function, but when training on my device it says `AMP checks failed ❌, disabling Automatic Mixed Precision.` My device situation is as follows:
```bash
pytorch=2.0
CUDA=11.8
4070Ti
```

 I would like to know what are the factors that prevent AMP from working? Like CUDA version, graphics hardware, or other factors, because I really want to use the AMP feature!

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13250/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13250/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13249,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13249/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13249/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13249/events,https://github.com/ultralytics/yolov5/issues/13249,2452936867,I_kwDOD8jP_s6SNNij,13249,What prevents me from using the AMP function？,"{'login': 'thgpddl', 'id': 48787805, 'node_id': 'MDQ6VXNlcjQ4Nzg3ODA1', 'avatar_url': 'https://avatars.githubusercontent.com/u/48787805?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/thgpddl', 'html_url': 'https://github.com/thgpddl', 'followers_url': 'https://api.github.com/users/thgpddl/followers', 'following_url': 'https://api.github.com/users/thgpddl/following{/other_user}', 'gists_url': 'https://api.github.com/users/thgpddl/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/thgpddl/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/thgpddl/subscriptions', 'organizations_url': 'https://api.github.com/users/thgpddl/orgs', 'repos_url': 'https://api.github.com/users/thgpddl/repos', 'events_url': 'https://api.github.com/users/thgpddl/events{/privacy}', 'received_events_url': 'https://api.github.com/users/thgpddl/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-08-07T08:52:08Z,2024-08-07T12:57:39Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Thank you very much for your work. I would like to be able to use the AMP function, but when training on my device it says `AMP checks failed ❌, disabling Automatic Mixed Precision.` My device situation is as follows:
```bash
pytorch=2.0
CUDA=11.8
4070Ti
```

 I would like to know what are the factors that prevent AMP from working? Like CUDA version, graphics hardware, or other factors, because I really want to use the AMP feature!

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13249/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13249/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13247,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13247/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13247/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13247/events,https://github.com/ultralytics/yolov5/issues/13247,2452414789,I_kwDOD8jP_s6SLOFF,13247,Request for YOLOv5 v6.2 Source Code under GPL-3.0 License,"{'login': 'akmalulkhairin', 'id': 32617884, 'node_id': 'MDQ6VXNlcjMyNjE3ODg0', 'avatar_url': 'https://avatars.githubusercontent.com/u/32617884?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/akmalulkhairin', 'html_url': 'https://github.com/akmalulkhairin', 'followers_url': 'https://api.github.com/users/akmalulkhairin/followers', 'following_url': 'https://api.github.com/users/akmalulkhairin/following{/other_user}', 'gists_url': 'https://api.github.com/users/akmalulkhairin/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/akmalulkhairin/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/akmalulkhairin/subscriptions', 'organizations_url': 'https://api.github.com/users/akmalulkhairin/orgs', 'repos_url': 'https://api.github.com/users/akmalulkhairin/repos', 'events_url': 'https://api.github.com/users/akmalulkhairin/events{/privacy}', 'received_events_url': 'https://api.github.com/users/akmalulkhairin/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-08-07T05:01:44Z,2024-10-20T19:51:28Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Dear Ultralytics Team,

I am writing to request access to the source code for YOLOv5 version 6.2, which was released under the GPL-3.0 license. As per the terms of the GPL-3.0, I understand that the source code should be made available to anyone who requests it.

Could you please provide the source code for YOLOv5 v6.2, or direct me to where I can obtain it? Thank you for your attention to this matter and for your contributions to the open-source community.

Regards,

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13247/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13247/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13246,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13246/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13246/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13246/events,https://github.com/ultralytics/yolov5/issues/13246,2450578573,I_kwDOD8jP_s6SENyN,13246, divide the objects into small and large categories based on the size of the bonding boxes,"{'login': 'EmmaLevine94', 'id': 172018685, 'node_id': 'U_kgDOCkDL_Q', 'avatar_url': 'https://avatars.githubusercontent.com/u/172018685?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/EmmaLevine94', 'html_url': 'https://github.com/EmmaLevine94', 'followers_url': 'https://api.github.com/users/EmmaLevine94/followers', 'following_url': 'https://api.github.com/users/EmmaLevine94/following{/other_user}', 'gists_url': 'https://api.github.com/users/EmmaLevine94/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/EmmaLevine94/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/EmmaLevine94/subscriptions', 'organizations_url': 'https://api.github.com/users/EmmaLevine94/orgs', 'repos_url': 'https://api.github.com/users/EmmaLevine94/repos', 'events_url': 'https://api.github.com/users/EmmaLevine94/events{/privacy}', 'received_events_url': 'https://api.github.com/users/EmmaLevine94/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,8,2024-08-06T10:53:11Z,2024-10-20T19:51:27Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello. I had a question that was not similar. I want to divide the objects into small and large categories based on the size of the bonding boxes that are produced during training. I want the threshold that I define to be different for each of these categories. How can I access the bonding boxes that are generated during the training? In which module are network predicates generated on training data?
Thank you

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13246/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13246/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13245,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13245/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13245/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13245/events,https://github.com/ultralytics/yolov5/issues/13245,2450491666,I_kwDOD8jP_s6SD4kS,13245,more details about training procedure,"{'login': 'NGtesig', 'id': 126691251, 'node_id': 'U_kgDOB40nsw', 'avatar_url': 'https://avatars.githubusercontent.com/u/126691251?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/NGtesig', 'html_url': 'https://github.com/NGtesig', 'followers_url': 'https://api.github.com/users/NGtesig/followers', 'following_url': 'https://api.github.com/users/NGtesig/following{/other_user}', 'gists_url': 'https://api.github.com/users/NGtesig/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/NGtesig/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/NGtesig/subscriptions', 'organizations_url': 'https://api.github.com/users/NGtesig/orgs', 'repos_url': 'https://api.github.com/users/NGtesig/repos', 'events_url': 'https://api.github.com/users/NGtesig/events{/privacy}', 'received_events_url': 'https://api.github.com/users/NGtesig/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-08-06T10:10:48Z,2024-10-20T19:51:25Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi,
I have a question related to the training procedure of yolov5. Specifically I was wondering if adaptive training is applied and if the validation loss has a role in this case; I need to understand if validation set is used just to verify the generalization ability of the network or it is involved also in the optimization of the training process changing for example the learning rate or other hyperparameters. 
Thank you in advance!
Noemi




### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13245/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13245/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13244,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13244/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13244/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13244/events,https://github.com/ultralytics/yolov5/pull/13244,2449364107,PR_kwDOD8jP_s53fZyT,13244,Update torch.cuda.amp to torch.amp,"{'login': 'jacobdbrown4', 'id': 77401292, 'node_id': 'MDQ6VXNlcjc3NDAxMjky', 'avatar_url': 'https://avatars.githubusercontent.com/u/77401292?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/jacobdbrown4', 'html_url': 'https://github.com/jacobdbrown4', 'followers_url': 'https://api.github.com/users/jacobdbrown4/followers', 'following_url': 'https://api.github.com/users/jacobdbrown4/following{/other_user}', 'gists_url': 'https://api.github.com/users/jacobdbrown4/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/jacobdbrown4/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/jacobdbrown4/subscriptions', 'organizations_url': 'https://api.github.com/users/jacobdbrown4/orgs', 'repos_url': 'https://api.github.com/users/jacobdbrown4/repos', 'events_url': 'https://api.github.com/users/jacobdbrown4/events{/privacy}', 'received_events_url': 'https://api.github.com/users/jacobdbrown4/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,,[],,18,2024-08-05T19:55:14Z,2024-12-17T22:43:12Z,,NONE,,"`torch.cuda.amp` is deprecated as of Pytorch 2.4. This PR updates use to `torch.amp`. This gets rid of the

```
FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(amp):
```

 warning as mentioned in #13226. 

<!--
Thank you 🙏 for your contribution to [Ultralytics](https://ultralytics.com) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. **Check for Existing Contributions**: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. **Link Related Issues**: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. **Elaborate Your Changes**: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. **Ultralytics Contributor License Agreement (CLA)**: To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    _I have read the CLA Document and I sign the CLA_

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.
--->


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Update to use latest CUDA AMP (Automatic Mixed Precision) API across various files for better compatibility and performance.

### 📊 Key Changes
- Replaced `torch.cuda.amp.autocast` with `torch.amp.autocast(""cuda"")` in multiple files.
- Replaced `torch.cuda.amp.GradScaler` with `torch.amp.GradScaler(""cuda"")`.

### 🎯 Purpose & Impact
- **Improved Compatibility**: Ensures that the code remains compatible with the latest PyTorch changes, reducing the risk of future issues.
- **Performance**: Leverages CUDA's improved automatic mixed precision to potentially enhance computational efficiency.
- **Maintenance**: Simplifies code adjustments related to AMP, making future updates easier to manage.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13244/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13244/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13244', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13244', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13244.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13244.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13243,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13243/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13243/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13243/events,https://github.com/ultralytics/yolov5/issues/13243,2447838872,I_kwDOD8jP_s6R5w6Y,13243,Exporting trained yolov5 model (trained on custom dataset) to 'saved model' format changes the no. of classes and the name of classes to default coco128 values,"{'login': 'ssingh17j', 'id': 177511764, 'node_id': 'U_kgDOCpSdVA', 'avatar_url': 'https://avatars.githubusercontent.com/u/177511764?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ssingh17j', 'html_url': 'https://github.com/ssingh17j', 'followers_url': 'https://api.github.com/users/ssingh17j/followers', 'following_url': 'https://api.github.com/users/ssingh17j/following{/other_user}', 'gists_url': 'https://api.github.com/users/ssingh17j/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ssingh17j/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ssingh17j/subscriptions', 'organizations_url': 'https://api.github.com/users/ssingh17j/orgs', 'repos_url': 'https://api.github.com/users/ssingh17j/repos', 'events_url': 'https://api.github.com/users/ssingh17j/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ssingh17j/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,2,2024-08-05T07:38:31Z,2024-10-27T13:30:48Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Export

### Bug

I trained yolov5s model to detect various logos (amazon, ups, fedex etc). The model detects the logos well.
The command used for training is:
```python train.py --weights yolov5s.pt --epoch 100 --data C:\projects\logo_detector\yolov5\datasetv3\data.yaml```

The command used for detecting logos is:
```python detect.py --weights best.pt --source 0```

Screenshot of trained yolov5s model detecting the logos:
![yolov5s model](https://github.com/user-attachments/assets/80179804-737c-4a5b-91c9-37971f6121c8)

When I use export.py to convert the above model to saved model format, the model starts giving wrong output.
The command used for exporting the model is:
```python export.py --weights best.pt --data C:\projects\logo_detector\yolov5\datasetv3\data.yaml --include saved_model```

The command used for detection of logos using this saved model is:
```python detect.py --weights best_saved_model --source 0```

Screenshot of yolov5s saved model giving wrong output is:
![yolov5s saved model](https://github.com/user-attachments/assets/fc8af90d-e4ac-41af-86c8-6cb07d5101eb)

As far as I can understand, the model starts giving output according to the default coco128.yaml file. But I have not specified this file in my commands, so I cannot understand the reason behind this behaviour. Please let me know how to get correct output.

### Environment

- I have used the default git repository for yolov5
- OS: Windows 10 Pro
- Python: 3.12.3

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13243/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13243/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13241,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13241/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13241/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13241/events,https://github.com/ultralytics/yolov5/issues/13241,2446068306,I_kwDOD8jP_s6RzApS,13241,pulling out model's layer intermediates,"{'login': 'LindyZh', 'id': 33186187, 'node_id': 'MDQ6VXNlcjMzMTg2MTg3', 'avatar_url': 'https://avatars.githubusercontent.com/u/33186187?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/LindyZh', 'html_url': 'https://github.com/LindyZh', 'followers_url': 'https://api.github.com/users/LindyZh/followers', 'following_url': 'https://api.github.com/users/LindyZh/following{/other_user}', 'gists_url': 'https://api.github.com/users/LindyZh/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/LindyZh/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/LindyZh/subscriptions', 'organizations_url': 'https://api.github.com/users/LindyZh/orgs', 'repos_url': 'https://api.github.com/users/LindyZh/repos', 'events_url': 'https://api.github.com/users/LindyZh/events{/privacy}', 'received_events_url': 'https://api.github.com/users/LindyZh/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-08-03T04:19:00Z,2024-10-27T13:30:48Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I'm trying to adapt the model architecture (append attention head, etc) of the existing structure but this requires me to pull out the layer intermediate (output from the 8th layer) in my custom pytorch class. 

I understand we could use our pretrain weights like follows with a tensor input
`model = torch.hub.load('./yolov5', 'custom', path='best.pt', source='local')
results = model(torch.zeros(16,3,320,640))`

but how can I use the intermediate layer result instead of letting the input running through the entire data?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13241/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13241/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13240,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13240/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13240/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13240/events,https://github.com/ultralytics/yolov5/issues/13240,2444429514,I_kwDOD8jP_s6RswjK,13240,How to specify yolov5 to train multiple folders?,"{'login': 'kahvia1244', 'id': 73689867, 'node_id': 'MDQ6VXNlcjczNjg5ODY3', 'avatar_url': 'https://avatars.githubusercontent.com/u/73689867?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/kahvia1244', 'html_url': 'https://github.com/kahvia1244', 'followers_url': 'https://api.github.com/users/kahvia1244/followers', 'following_url': 'https://api.github.com/users/kahvia1244/following{/other_user}', 'gists_url': 'https://api.github.com/users/kahvia1244/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/kahvia1244/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/kahvia1244/subscriptions', 'organizations_url': 'https://api.github.com/users/kahvia1244/orgs', 'repos_url': 'https://api.github.com/users/kahvia1244/repos', 'events_url': 'https://api.github.com/users/kahvia1244/events{/privacy}', 'received_events_url': 'https://api.github.com/users/kahvia1244/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-08-02T08:48:33Z,2024-08-02T14:06:21Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I have some training data stored in multiple folders, but I don't want them to be mixed together. How can I specify multiple training folders?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13240/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13240/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13233,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13233/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13233/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13233/events,https://github.com/ultralytics/yolov5/issues/13233,2438996300,I_kwDOD8jP_s6RYCFM,13233,'RandomSampler' object has no attribute 'set_epoch',"{'login': 'lili084', 'id': 151527364, 'node_id': 'U_kgDOCQgfxA', 'avatar_url': 'https://avatars.githubusercontent.com/u/151527364?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/lili084', 'html_url': 'https://github.com/lili084', 'followers_url': 'https://api.github.com/users/lili084/followers', 'following_url': 'https://api.github.com/users/lili084/following{/other_user}', 'gists_url': 'https://api.github.com/users/lili084/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/lili084/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/lili084/subscriptions', 'organizations_url': 'https://api.github.com/users/lili084/orgs', 'repos_url': 'https://api.github.com/users/lili084/repos', 'events_url': 'https://api.github.com/users/lili084/events{/privacy}', 'received_events_url': 'https://api.github.com/users/lili084/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-07-31T02:48:50Z,2024-10-20T19:51:08Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I'm using train.py to train my own data and I'm getting this error, I'm not sure how it's happening
        if RANK != -1:
            train_loader.sampler.set_epoch(epoch)

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13233/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13233/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13232,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13232/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13232/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13232/events,https://github.com/ultralytics/yolov5/pull/13232,2438883296,PR_kwDOD8jP_s527ssF,13232,fix kerasmodel,"{'login': 'SangbumChoi', 'id': 34004152, 'node_id': 'MDQ6VXNlcjM0MDA0MTUy', 'avatar_url': 'https://avatars.githubusercontent.com/u/34004152?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/SangbumChoi', 'html_url': 'https://github.com/SangbumChoi', 'followers_url': 'https://api.github.com/users/SangbumChoi/followers', 'following_url': 'https://api.github.com/users/SangbumChoi/following{/other_user}', 'gists_url': 'https://api.github.com/users/SangbumChoi/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/SangbumChoi/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/SangbumChoi/subscriptions', 'organizations_url': 'https://api.github.com/users/SangbumChoi/orgs', 'repos_url': 'https://api.github.com/users/SangbumChoi/repos', 'events_url': 'https://api.github.com/users/SangbumChoi/events{/privacy}', 'received_events_url': 'https://api.github.com/users/SangbumChoi/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,,[],,0,2024-07-31T00:33:05Z,2024-10-27T13:30:49Z,,CONTRIBUTOR,,"Since there is some deprecation of keras model usage I updated the following logic

<!--
Thank you 🙏 for your contribution to [Ultralytics](https://ultralytics.com) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. **Check for Existing Contributions**: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. **Link Related Issues**: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. **Elaborate Your Changes**: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. **Ultralytics Contributor License Agreement (CLA)**: To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    _I have read the CLA Document and I sign the CLA_

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.
--->


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhanced TensorFlow model export functionality.

### 📊 Key Changes
- Introduced a new `KerasModel` class for model export.
- Modified the export process to use `KerasModel` instead of directly calling `tf_model.predict`.
- Changed the export format for Keras models to `.h5` instead of TensorFlow's default format.

### 🎯 Purpose & Impact
- **Improved Usability**: Simplifies the TensorFlow model export process by encapsulating configurations within a `KerasModel` class.
- **Consistency**: Ensures the exported Keras models are saved in a more universally accessible `.h5` format.
- **Flexibility**: Facilitates better management of model configurations and predictions, making the codebase more modular and user-friendly.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13232/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13232/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13232', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13232', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13232.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13232.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13231,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13231/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13231/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13231/events,https://github.com/ultralytics/yolov5/issues/13231,2438875995,I_kwDOD8jP_s6RXktb,13231,How to modify the network structure of the YOLOv5 classification model,"{'login': 'lielumao', 'id': 177002533, 'node_id': 'U_kgDOCozYJQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/177002533?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/lielumao', 'html_url': 'https://github.com/lielumao', 'followers_url': 'https://api.github.com/users/lielumao/followers', 'following_url': 'https://api.github.com/users/lielumao/following{/other_user}', 'gists_url': 'https://api.github.com/users/lielumao/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/lielumao/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/lielumao/subscriptions', 'organizations_url': 'https://api.github.com/users/lielumao/orgs', 'repos_url': 'https://api.github.com/users/lielumao/repos', 'events_url': 'https://api.github.com/users/lielumao/events{/privacy}', 'received_events_url': 'https://api.github.com/users/lielumao/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-07-31T00:23:10Z,2024-10-20T19:51:05Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I tried to change the example of YOLOv5 model=YOLO ('yolov5s-cls. yaml '). load ('yolov5s-cls. pt') to the corresponding YOLOv5-cls yaml and pt files, but encountered an error AttributeError: Can't get attribute 'Classification Model' on<module 'models. yolo' from'D: \ \ anaco \ \ envs \ \ yolo8 \ \ Lib \ \ site packages \ \ ultralytics \ \ models \ \ yolo \ \ __init__. py '>. How can I solve this problem? I tried importing only the YAML file and it ran correctly. But this cannot read the weight of the PT file. Or is there any way to operate in yolov5 master to change the yolov5 classification network structure.
![problem](https://github.com/user-attachments/assets/3e8d3117-97f2-48f4-9024-f700f6820db2)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13231/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13231/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13226,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13226/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13226/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13226/events,https://github.com/ultralytics/yolov5/issues/13226,2433932096,I_kwDOD8jP_s6REttA,13226,关于yolov5在mac设备上使用mps加速出现的各种问题,"{'login': 'xxxkkw', 'id': 168389027, 'node_id': 'U_kgDOCglpow', 'avatar_url': 'https://avatars.githubusercontent.com/u/168389027?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/xxxkkw', 'html_url': 'https://github.com/xxxkkw', 'followers_url': 'https://api.github.com/users/xxxkkw/followers', 'following_url': 'https://api.github.com/users/xxxkkw/following{/other_user}', 'gists_url': 'https://api.github.com/users/xxxkkw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/xxxkkw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/xxxkkw/subscriptions', 'organizations_url': 'https://api.github.com/users/xxxkkw/orgs', 'repos_url': 'https://api.github.com/users/xxxkkw/repos', 'events_url': 'https://api.github.com/users/xxxkkw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/xxxkkw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,2,2024-07-28T13:27:27Z,2024-10-27T13:30:49Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Training, Detection

### Bug

首先从训练模型讲起，我使用的设备是一台MacOS 14的设备，m1max芯片，如果使用
```
python train.py --device mps
```
也就是仅使用官方的训练数据，训练的过程中会出现
```
  Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
  0%|          | 0/8 [00:00<?, ?it/s]/Users/xiongkaiwen/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(amp):
```
虽然这并不影响训练的过程，最终还是可以正常的输出训练好的模型。
在我使用这个训练好的模型对 yolov5/data/images 文件夹内的图片进行检测，检测结果是正常的，但当我使用这个训练好的模型进行检测的时候，最终输出的视频文件是乱的，体现在
<img width=""598"" alt=""截屏2024-07-28 21 04 31"" src=""https://github.com/user-attachments/assets/98bc023b-2003-424f-ad27-6eaeccf1fa75"">
这个是我在视频里面截取的一帧，并且整个视频中框都呈现类似的错误，而我如果换用cpu进行检测的时候，检测结果就正常了
<img width=""426"" alt=""截屏2024-07-28 21 02 45"" src=""https://github.com/user-attachments/assets/ee2afdaf-efa6-45db-9fde-ad04bd9e1e29"">
并且，如果我使用yolov5文件夹内的yolov5s.pt进行检测的时候，这种问题又消失了，检测的结果就是正常的，这就让人非常不能理解，我认为yolov5s.pt文件的训练集与我使用该命令的数据集
```
python train.py --device mps
```
应该是一致的，为什么会出现这样的错误？

还有，我在使用我自己的数据集的过程中，我曾经在服务器上训练好了一个模型，并且在那边使用的是cuda，并且确定这个模型文件是可用的，在服务器上对视频进行识别是正常的，但在我的设备上，使用这个模型对视频文件进行检测，结果就类似于我给出的图片一致，如果使用mps加速，结果就出现错乱，但使用cpu，结果就是符合预期的，我想知道这到底是什么问题。




### Environment

YOLOv5 🚀 v7.0-348-g6deb2d75 Python-3.11.9 torch-2.5.0.dev20240727 CPU
Apple M1 Max 32G
MacOS 14.5 (23F79)

### Minimal Reproducible Example

我使用的是anaconda创建版本为Python 3.11.9的虚拟环境，并使用
```
git clone https://github.com/ultralytics/yolov5.git
pip install -r requirements.txt
cd yolov5
```
在此时，删除现有的pytorch，安装最新版的nightly版
```
pip uninstall torch
pip uninstall torchvision
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
```
此时我所有包的版本如下：
```
Package            Version
------------------ ------------------
certifi            2024.7.4
charset-normalizer 3.3.2
contourpy          1.2.1
cycler             0.12.1
filelock           3.15.4
fonttools          4.53.1
fsspec             2024.6.1
gitdb              4.0.11
GitPython          3.1.43
idna               3.7
Jinja2             3.1.4
kiwisolver         1.4.5
MarkupSafe         2.1.5
matplotlib         3.9.1
mpmath             1.3.0
networkx           3.3
numpy              1.26.4
opencv-python      4.10.0.84
packaging          24.1
pandas             2.2.2
pillow             10.4.0
pip                24.1.2
psutil             6.0.0
py-cpuinfo         9.0.0
pyparsing          3.1.2
python-dateutil    2.9.0.post0
pytz               2024.1
PyYAML             6.0.2rc1
requests           2.32.3
scipy              1.14.0
seaborn            0.13.2
setuptools         71.1.0
six                1.16.0
smmap              5.0.1
sympy              1.13.1
thop               0.1.1-2209072238
torch              2.5.0.dev20240727
torchaudio         2.4.0
torchvision        0.20.0.dev20240727
tqdm               4.66.4
typing_extensions  4.12.2
tzdata             2024.1
ultralytics        8.2.66
ultralytics-thop   2.0.0
urllib3            2.2.2
wheel              0.43.0
```
按照这个步骤应该就能跟我的环境一致，然后就能按照我的步骤还原问题


### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13226/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13226/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13218,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13218/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13218/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13218/events,https://github.com/ultralytics/yolov5/issues/13218,2429146718,I_kwDOD8jP_s6QydZe,13218,about training and exporting img size,"{'login': 'wzf19947', 'id': 30069226, 'node_id': 'MDQ6VXNlcjMwMDY5MjI2', 'avatar_url': 'https://avatars.githubusercontent.com/u/30069226?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/wzf19947', 'html_url': 'https://github.com/wzf19947', 'followers_url': 'https://api.github.com/users/wzf19947/followers', 'following_url': 'https://api.github.com/users/wzf19947/following{/other_user}', 'gists_url': 'https://api.github.com/users/wzf19947/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/wzf19947/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/wzf19947/subscriptions', 'organizations_url': 'https://api.github.com/users/wzf19947/orgs', 'repos_url': 'https://api.github.com/users/wzf19947/repos', 'events_url': 'https://api.github.com/users/wzf19947/events{/privacy}', 'received_events_url': 'https://api.github.com/users/wzf19947/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-07-25T06:39:23Z,2024-10-20T19:50:52Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I've done some experiments and find that when I train two models with img size of 640*640 and 480*320,  and  export them into ONNX with size of 480*320,  I find the 640*640 trained model get better inference results on  test sets with inference  size of 480*320.  Is it normal ?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13218/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13218/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13216,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13216/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13216/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13216/events,https://github.com/ultralytics/yolov5/issues/13216,2427941425,I_kwDOD8jP_s6Qt3Ix,13216,gpu memory usage is low but out of memory,"{'login': 'leooobreak', 'id': 90808389, 'node_id': 'MDQ6VXNlcjkwODA4Mzg5', 'avatar_url': 'https://avatars.githubusercontent.com/u/90808389?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/leooobreak', 'html_url': 'https://github.com/leooobreak', 'followers_url': 'https://api.github.com/users/leooobreak/followers', 'following_url': 'https://api.github.com/users/leooobreak/following{/other_user}', 'gists_url': 'https://api.github.com/users/leooobreak/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/leooobreak/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/leooobreak/subscriptions', 'organizations_url': 'https://api.github.com/users/leooobreak/orgs', 'repos_url': 'https://api.github.com/users/leooobreak/repos', 'events_url': 'https://api.github.com/users/leooobreak/events{/privacy}', 'received_events_url': 'https://api.github.com/users/leooobreak/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-07-24T15:52:07Z,2024-10-27T13:30:50Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

When training yolov5, I found that the GPU memory was not used, GPU memory usage is versy low, and the memory increased very quickly, resulting in out of memory. I would like to know how to use the GPU for training?  
![40a297508ad327424914be98cf4f7fdc](https://github.com/user-attachments/assets/27fd1848-a5fc-4136-9243-b1656395198c)

command is `python .\train.py --device 0 --epochs 1 --batch-size 16`

![image](https://github.com/user-attachments/assets/8b5916f1-fec5-4466-b8bb-c425661f29da)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13216/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13216/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13215,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13215/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13215/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13215/events,https://github.com/ultralytics/yolov5/issues/13215,2427725333,I_kwDOD8jP_s6QtCYV,13215,?????,"{'login': 'thestars-maker', 'id': 66953155, 'node_id': 'MDQ6VXNlcjY2OTUzMTU1', 'avatar_url': 'https://avatars.githubusercontent.com/u/66953155?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/thestars-maker', 'html_url': 'https://github.com/thestars-maker', 'followers_url': 'https://api.github.com/users/thestars-maker/followers', 'following_url': 'https://api.github.com/users/thestars-maker/following{/other_user}', 'gists_url': 'https://api.github.com/users/thestars-maker/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/thestars-maker/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/thestars-maker/subscriptions', 'organizations_url': 'https://api.github.com/users/thestars-maker/orgs', 'repos_url': 'https://api.github.com/users/thestars-maker/repos', 'events_url': 'https://api.github.com/users/thestars-maker/events{/privacy}', 'received_events_url': 'https://api.github.com/users/thestars-maker/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}]",open,False,,[],,2,2024-07-24T14:19:09Z,2024-10-20T19:50:44Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

yeugaiyuelaiji

### Environment

sss

### Minimal Reproducible Example

sss

### Additional

sss

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13215/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13215/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13214,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13214/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13214/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13214/events,https://github.com/ultralytics/yolov5/issues/13214,2427382066,I_kwDOD8jP_s6Qruky,13214,yolov5 Ip camera,"{'login': 'FratCan', 'id': 79118451, 'node_id': 'MDQ6VXNlcjc5MTE4NDUx', 'avatar_url': 'https://avatars.githubusercontent.com/u/79118451?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/FratCan', 'html_url': 'https://github.com/FratCan', 'followers_url': 'https://api.github.com/users/FratCan/followers', 'following_url': 'https://api.github.com/users/FratCan/following{/other_user}', 'gists_url': 'https://api.github.com/users/FratCan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/FratCan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/FratCan/subscriptions', 'organizations_url': 'https://api.github.com/users/FratCan/orgs', 'repos_url': 'https://api.github.com/users/FratCan/repos', 'events_url': 'https://api.github.com/users/FratCan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/FratCan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-07-24T11:49:16Z,2024-10-27T13:30:51Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

YoloV5 has a latency problem with ip camera. When I use the webcam, it works normally via CPU with default yoloV5 or custom trained model, but when I switch to Ip camera the video comes very late. i connected Ip camera using openCv and RTSP. how can i solve this delay? 

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13214/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13214/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13213,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13213/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13213/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13213/events,https://github.com/ultralytics/yolov5/issues/13213,2426458940,I_kwDOD8jP_s6QoNM8,13213,AttributeError: 'tuple' object has no attribute 'to',"{'login': 'stillbetter', 'id': 42489440, 'node_id': 'MDQ6VXNlcjQyNDg5NDQw', 'avatar_url': 'https://avatars.githubusercontent.com/u/42489440?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/stillbetter', 'html_url': 'https://github.com/stillbetter', 'followers_url': 'https://api.github.com/users/stillbetter/followers', 'following_url': 'https://api.github.com/users/stillbetter/following{/other_user}', 'gists_url': 'https://api.github.com/users/stillbetter/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/stillbetter/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/stillbetter/subscriptions', 'organizations_url': 'https://api.github.com/users/stillbetter/orgs', 'repos_url': 'https://api.github.com/users/stillbetter/repos', 'events_url': 'https://api.github.com/users/stillbetter/events{/privacy}', 'received_events_url': 'https://api.github.com/users/stillbetter/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-07-24T02:33:35Z,2024-10-27T13:30:51Z,,NONE,,"https://github.com/ultralytics/yolov5/blob/d6112173f5b2b809ec7f3ff1f8048ac0e465092c/models/experimental.py#L99


I got an error like:

```
  File ""export.py"", line 1346, in run
    model = attempt_load(weights, device=device, inplace=True, fuse=True)  # load FP32 model
  File ""/home/mi/PycharmProjects/yolov5/models/experimental.py"", line 99, in attempt_load
    ckpt = (ckpt.get(""ema"") or ckpt[""model""]).to(device).float()  # FP32 model
AttributeError: 'tuple' object has no attribute 'to'

```
Should I just remove ckpt.get(""ema"") or ckpt[""model""] in the code?

",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13213/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13213/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13211,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13211/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13211/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13211/events,https://github.com/ultralytics/yolov5/issues/13211,2424120465,I_kwDOD8jP_s6QfSSR,13211,The question with repeated training,"{'login': 'arkerman', 'id': 63221199, 'node_id': 'MDQ6VXNlcjYzMjIxMTk5', 'avatar_url': 'https://avatars.githubusercontent.com/u/63221199?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arkerman', 'html_url': 'https://github.com/arkerman', 'followers_url': 'https://api.github.com/users/arkerman/followers', 'following_url': 'https://api.github.com/users/arkerman/following{/other_user}', 'gists_url': 'https://api.github.com/users/arkerman/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arkerman/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arkerman/subscriptions', 'organizations_url': 'https://api.github.com/users/arkerman/orgs', 'repos_url': 'https://api.github.com/users/arkerman/repos', 'events_url': 'https://api.github.com/users/arkerman/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arkerman/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,5,2024-07-23T02:39:50Z,2024-10-20T19:50:38Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I now have 100 defect images. I first used the pre-trained model of yolov5s to train and get best.pt. After a week, I have another 100 images. I don’t want to add up the 100 images twice and re-train them. Instead, I want to keep the weights of best.pt and only train the next 100 images. What do I need to do?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13211/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13211/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13209,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13209/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13209/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13209/events,https://github.com/ultralytics/yolov5/issues/13209,2422981692,I_kwDOD8jP_s6Qa8Q8,13209,5d in Onnx,"{'login': 'Manueljohnson063', 'id': 44712542, 'node_id': 'MDQ6VXNlcjQ0NzEyNTQy', 'avatar_url': 'https://avatars.githubusercontent.com/u/44712542?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Manueljohnson063', 'html_url': 'https://github.com/Manueljohnson063', 'followers_url': 'https://api.github.com/users/Manueljohnson063/followers', 'following_url': 'https://api.github.com/users/Manueljohnson063/following{/other_user}', 'gists_url': 'https://api.github.com/users/Manueljohnson063/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Manueljohnson063/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Manueljohnson063/subscriptions', 'organizations_url': 'https://api.github.com/users/Manueljohnson063/orgs', 'repos_url': 'https://api.github.com/users/Manueljohnson063/repos', 'events_url': 'https://api.github.com/users/Manueljohnson063/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Manueljohnson063/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-07-22T14:10:04Z,2024-10-20T19:50:35Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi , I have a 5d reshape  in my onnx model .My board is not supporting the 5d operation can you please help me to convert this 5d in to  lesser diamension.
(like 2 4d's )
@glenn-jocher 

### Additional
![image](https://github.com/user-attachments/assets/35aa0415-6378-4c3a-92b7-7ad7416a8e0a)

(With out adding the preprocessing code   by using onnx iteslf )",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13209/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13209/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13208,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13208/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13208/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13208/events,https://github.com/ultralytics/yolov5/issues/13208,2422771559,I_kwDOD8jP_s6QaI9n,13208,"Can i use custom model as pretrained model, and train again?","{'login': 'shengjieH', 'id': 118937588, 'node_id': 'U_kgDOBxbX9A', 'avatar_url': 'https://avatars.githubusercontent.com/u/118937588?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/shengjieH', 'html_url': 'https://github.com/shengjieH', 'followers_url': 'https://api.github.com/users/shengjieH/followers', 'following_url': 'https://api.github.com/users/shengjieH/following{/other_user}', 'gists_url': 'https://api.github.com/users/shengjieH/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/shengjieH/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/shengjieH/subscriptions', 'organizations_url': 'https://api.github.com/users/shengjieH/orgs', 'repos_url': 'https://api.github.com/users/shengjieH/repos', 'events_url': 'https://api.github.com/users/shengjieH/events{/privacy}', 'received_events_url': 'https://api.github.com/users/shengjieH/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-07-22T12:36:52Z,2024-10-20T19:50:33Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello,

I have two questions:
1. I used yolov5s.pt as pretrained model when i firstly train my custom model, however, my custom model is really special, it's not about classifying human, cars or trees. It's a defect detection, which is used to detect one object defective or not. In this case, it seems the pretrained model yolov5s.pt does not has too much connection with my custom dataset. In this case, is it still good to use yolov5s.pt as pretrained model?

2. Now i have already trained my custom model, and want to improve the perfromance. Can i use the current custom model as pretrained model and train it again (use new dataset), does this method works?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13208/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13208/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13207,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13207/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13207/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13207/events,https://github.com/ultralytics/yolov5/issues/13207,2422077524,I_kwDOD8jP_s6QXfhU,13207,tensorflow.python.framework.errors_impl.FailedPreconditionError: logs\loss_2024_07_22_11_59_02 is not a directory,"{'login': 'Mr-ChenSH', 'id': 56282416, 'node_id': 'MDQ6VXNlcjU2MjgyNDE2', 'avatar_url': 'https://avatars.githubusercontent.com/u/56282416?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Mr-ChenSH', 'html_url': 'https://github.com/Mr-ChenSH', 'followers_url': 'https://api.github.com/users/Mr-ChenSH/followers', 'following_url': 'https://api.github.com/users/Mr-ChenSH/following{/other_user}', 'gists_url': 'https://api.github.com/users/Mr-ChenSH/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Mr-ChenSH/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Mr-ChenSH/subscriptions', 'organizations_url': 'https://api.github.com/users/Mr-ChenSH/orgs', 'repos_url': 'https://api.github.com/users/Mr-ChenSH/repos', 'events_url': 'https://api.github.com/users/Mr-ChenSH/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Mr-ChenSH/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-07-22T06:44:56Z,2024-10-20T19:50:29Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

tensorflow.python.framework.errors_impl.FailedPreconditionError: logs\loss_2024_07_22_11_59_02 is not a directory

what is the wrong？

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13207/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13207/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13204,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13204/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13204/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13204/events,https://github.com/ultralytics/yolov5/issues/13204,2421309607,I_kwDOD8jP_s6QUkCn,13204,AttributeError: 'DetectMultiBackend' object has no attribute 'input_details',"{'login': 'Kelly02140', 'id': 175905155, 'node_id': 'U_kgDOCnwZgw', 'avatar_url': 'https://avatars.githubusercontent.com/u/175905155?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Kelly02140', 'html_url': 'https://github.com/Kelly02140', 'followers_url': 'https://api.github.com/users/Kelly02140/followers', 'following_url': 'https://api.github.com/users/Kelly02140/following{/other_user}', 'gists_url': 'https://api.github.com/users/Kelly02140/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Kelly02140/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Kelly02140/subscriptions', 'organizations_url': 'https://api.github.com/users/Kelly02140/orgs', 'repos_url': 'https://api.github.com/users/Kelly02140/repos', 'events_url': 'https://api.github.com/users/Kelly02140/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Kelly02140/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,1,2024-07-21T09:16:21Z,2024-07-21T12:57:09Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I am doing a YOLOv5 project with DeepSort added to give each detected object a unique ID. I use yolov5n.pt as the weight to test a short video and It all works well. However, when I try to put my own trained weight profile to test the video, it gives me this error: 'AttributeError: 'DetectMultiBackend' object has no attribute 'input_details' Could anyone help me with this problem?
![image](https://github.com/user-attachments/assets/1e1c72a9-8507-41d9-9f82-20afb7f622b8)
![image](https://github.com/user-attachments/assets/103612bd-9514-4356-a293-f9fa00c7feb4)



### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13204/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13204/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13203,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13203/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13203/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13203/events,https://github.com/ultralytics/yolov5/issues/13203,2420520532,I_kwDOD8jP_s6QRjZU,13203,Overlapping Bounding Boxes of Different Classes,"{'login': 'toigni', 'id': 151803746, 'node_id': 'U_kgDOCQxXYg', 'avatar_url': 'https://avatars.githubusercontent.com/u/151803746?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/toigni', 'html_url': 'https://github.com/toigni', 'followers_url': 'https://api.github.com/users/toigni/followers', 'following_url': 'https://api.github.com/users/toigni/following{/other_user}', 'gists_url': 'https://api.github.com/users/toigni/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/toigni/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/toigni/subscriptions', 'organizations_url': 'https://api.github.com/users/toigni/orgs', 'repos_url': 'https://api.github.com/users/toigni/repos', 'events_url': 'https://api.github.com/users/toigni/events{/privacy}', 'received_events_url': 'https://api.github.com/users/toigni/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,2,2024-07-20T03:00:00Z,2024-10-20T19:50:24Z,,NONE,,"### Search before asking

- [ ] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I annotate the small bounding box in Class B to be covered by the bounding box in Class A

![Screenshot_20240720-111135~2](https://github.com/user-attachments/assets/1eaee8a0-7b5e-4089-b282-7f6aea991d45)

Despite increasing the amount of training data, the result of the detect after training is the appearance of a Class B bounding box of the same size as the Class A bounding box.

![Screenshot_20240720-111142~2](https://github.com/user-attachments/assets/38a1b3ff-d227-46cc-9860-9a4fcce80b95)


Here are my questions:
Is this issue the same as the one discussed in Issue #2172?
Do you know if this has been improved in YOLOv8?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13203/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13203/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13199,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13199/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13199/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13199/events,https://github.com/ultralytics/yolov5/issues/13199,2415065092,I_kwDOD8jP_s6P8vgE,13199,How to reduce the size of label and fontsize,"{'login': 'Kelly02140', 'id': 175905155, 'node_id': 'U_kgDOCnwZgw', 'avatar_url': 'https://avatars.githubusercontent.com/u/175905155?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Kelly02140', 'html_url': 'https://github.com/Kelly02140', 'followers_url': 'https://api.github.com/users/Kelly02140/followers', 'following_url': 'https://api.github.com/users/Kelly02140/following{/other_user}', 'gists_url': 'https://api.github.com/users/Kelly02140/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Kelly02140/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Kelly02140/subscriptions', 'organizations_url': 'https://api.github.com/users/Kelly02140/orgs', 'repos_url': 'https://api.github.com/users/Kelly02140/repos', 'events_url': 'https://api.github.com/users/Kelly02140/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Kelly02140/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-07-18T02:20:46Z,2024-10-20T19:50:20Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I am trying to reduce the labeling size since my images are only 240*240 and I could not see clearly without doing this. However, I have read that some others have posted this question before and I could not find neither 'plot_one_box' nor 'box_label'. Could anyone help me with it?
![image](https://github.com/user-attachments/assets/77a0f5ef-c5aa-409f-96e7-06ae743f2fbf)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13199/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13199/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13195,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13195/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13195/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13195/events,https://github.com/ultralytics/yolov5/issues/13195,2413421976,I_kwDOD8jP_s6P2eWY,13195,只训练COCO数据集中的car和person两类,"{'login': 'stillbetter', 'id': 42489440, 'node_id': 'MDQ6VXNlcjQyNDg5NDQw', 'avatar_url': 'https://avatars.githubusercontent.com/u/42489440?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/stillbetter', 'html_url': 'https://github.com/stillbetter', 'followers_url': 'https://api.github.com/users/stillbetter/followers', 'following_url': 'https://api.github.com/users/stillbetter/following{/other_user}', 'gists_url': 'https://api.github.com/users/stillbetter/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/stillbetter/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/stillbetter/subscriptions', 'organizations_url': 'https://api.github.com/users/stillbetter/orgs', 'repos_url': 'https://api.github.com/users/stillbetter/repos', 'events_url': 'https://api.github.com/users/stillbetter/events{/privacy}', 'received_events_url': 'https://api.github.com/users/stillbetter/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,4,2024-07-17T11:55:01Z,2024-10-20T19:50:13Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

你好，我的目标是检测人和车，所以请问如果我直接使用coco数据集，如何当dataloader只输出person和car的标签和图像进行训练，而不会把其他类别的bbox输出。


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13195/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13195/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13189,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13189/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13189/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13189/events,https://github.com/ultralytics/yolov5/issues/13189,2408078944,I_kwDOD8jP_s6PiF5g,13189,pip dependencies,"{'login': 'karmakaragradwip02', 'id': 99462819, 'node_id': 'U_kgDOBe2uow', 'avatar_url': 'https://avatars.githubusercontent.com/u/99462819?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/karmakaragradwip02', 'html_url': 'https://github.com/karmakaragradwip02', 'followers_url': 'https://api.github.com/users/karmakaragradwip02/followers', 'following_url': 'https://api.github.com/users/karmakaragradwip02/following{/other_user}', 'gists_url': 'https://api.github.com/users/karmakaragradwip02/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/karmakaragradwip02/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/karmakaragradwip02/subscriptions', 'organizations_url': 'https://api.github.com/users/karmakaragradwip02/orgs', 'repos_url': 'https://api.github.com/users/karmakaragradwip02/repos', 'events_url': 'https://api.github.com/users/karmakaragradwip02/events{/privacy}', 'received_events_url': 'https://api.github.com/users/karmakaragradwip02/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,3,2024-07-15T07:43:00Z,2024-10-20T19:50:06Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

# I am encountering this error when i am running the code in colab:
------------------------------------------------------------------------------------------------------------------
!git clone https://github.com/ultralytics/yolov5.git  
%cd yolov5
!pip install -qr requirements.txt
import torch
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.
imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
Setup complete. Using torch 2.3.0+cu121 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)
------------------------------------------------------------------------------------------------------------------

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13189/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13189/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13187,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13187/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13187/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13187/events,https://github.com/ultralytics/yolov5/issues/13187,2405025454,I_kwDOD8jP_s6PWcau,13187,"Hello author, can YOLOv5 be downloaded directly from third-party libraries like YOLOv5 and trained directly? I downloaded the yolov5 library and encountered an error when trying to run it","{'login': 'yxl23', 'id': 115678682, 'node_id': 'U_kgDOBuUd2g', 'avatar_url': 'https://avatars.githubusercontent.com/u/115678682?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/yxl23', 'html_url': 'https://github.com/yxl23', 'followers_url': 'https://api.github.com/users/yxl23/followers', 'following_url': 'https://api.github.com/users/yxl23/following{/other_user}', 'gists_url': 'https://api.github.com/users/yxl23/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/yxl23/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/yxl23/subscriptions', 'organizations_url': 'https://api.github.com/users/yxl23/orgs', 'repos_url': 'https://api.github.com/users/yxl23/repos', 'events_url': 'https://api.github.com/users/yxl23/events{/privacy}', 'received_events_url': 'https://api.github.com/users/yxl23/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,2,2024-07-12T08:20:32Z,2024-08-13T00:24:23Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I am using Gradio to integrate YOLOv5 and YOLOv5. YOLOv5 can directly import YOLO from ultralytics by downloading an ultralytics library, but I encountered this error while using YOLOv5
![image](https://github.com/user-attachments/assets/c11b0944-c4d9-4acc-822f-a77d8b85b335)
![image](https://github.com/user-attachments/assets/cdb5dfa7-5103-4717-bfa4-3bcf4b2e832d)


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13187/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13187/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13182,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13182/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13182/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13182/events,https://github.com/ultralytics/yolov5/issues/13182,2402092735,I_kwDOD8jP_s6PLQa_,13182,yolov5,"{'login': 'shangjin900000', 'id': 143427572, 'node_id': 'U_kgDOCIyH9A', 'avatar_url': 'https://avatars.githubusercontent.com/u/143427572?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/shangjin900000', 'html_url': 'https://github.com/shangjin900000', 'followers_url': 'https://api.github.com/users/shangjin900000/followers', 'following_url': 'https://api.github.com/users/shangjin900000/following{/other_user}', 'gists_url': 'https://api.github.com/users/shangjin900000/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/shangjin900000/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/shangjin900000/subscriptions', 'organizations_url': 'https://api.github.com/users/shangjin900000/orgs', 'repos_url': 'https://api.github.com/users/shangjin900000/repos', 'events_url': 'https://api.github.com/users/shangjin900000/events{/privacy}', 'received_events_url': 'https://api.github.com/users/shangjin900000/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,3,2024-07-11T02:32:11Z,2024-10-20T19:49:54Z,,NONE,,,,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13182/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13182/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13179,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13179/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13179/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13179/events,https://github.com/ultralytics/yolov5/issues/13179,2398804940,I_kwDOD8jP_s6O-tvM,13179,Understanding operation inside non_max_suppression() function,"{'login': 'Avaneesh-S', 'id': 110843612, 'node_id': 'U_kgDOBptW3A', 'avatar_url': 'https://avatars.githubusercontent.com/u/110843612?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Avaneesh-S', 'html_url': 'https://github.com/Avaneesh-S', 'followers_url': 'https://api.github.com/users/Avaneesh-S/followers', 'following_url': 'https://api.github.com/users/Avaneesh-S/following{/other_user}', 'gists_url': 'https://api.github.com/users/Avaneesh-S/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Avaneesh-S/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Avaneesh-S/subscriptions', 'organizations_url': 'https://api.github.com/users/Avaneesh-S/orgs', 'repos_url': 'https://api.github.com/users/Avaneesh-S/repos', 'events_url': 'https://api.github.com/users/Avaneesh-S/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Avaneesh-S/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,9,2024-07-09T17:49:28Z,2024-08-06T22:20:39Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I am processing batch of 10 videos at same time and running Yolov5 on them. (every batch contains one frame from each video, so in batches of 10 at a time). While using **viztracer** for profiling my application, I found that in the non_max_suppression() in [general.py](https://github.com/ultralytics/yolov5/blob/master/utils/general.py#L882) at the following line:
![image](https://github.com/ultralytics/yolov5/assets/110843612/9ec954c0-c6d0-411a-b7af-df5399a456f3)
this operation takes a long time on the first iteration of the 'for' loop (that is for image 1 or index 0) and for all other subsequent iterations it runs very fast. 
specifically suppose ' v = xc[xi] ' then the operation ' x = x[v] ' is the one taking the most time (not v=xc[xi]).  

**It is seen that if non_max_suppression() executes for 100ms around 80ms is taken by this operation in the first iteration of the 'for' loop for every batch**. 

I want to understand **why this is happening** and **why only on the first iteration** and **if there is any way to reduce this time** since I am trying to optimize my application to improve average FPS and optimizing this operation would optimize the entire non_max_supression.

### Additional

Additionally, I have gone through the same implementation in Yolov8 and found that it is different. Is it more optimized there? I have tried to manually replace the Yolov5's non_max_suppression() with the Yolov8's but it didn't give required output, I think its because the prediction tensors are a bit different for them (am I right?). ",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13179/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13179/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13178,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13178/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13178/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13178/events,https://github.com/ultralytics/yolov5/issues/13178,2398547293,I_kwDOD8jP_s6O9u1d,13178,how do i export my yolov5s model to torchscript then download that model as yolov5s.torchscript file? i have no di,"{'login': 'Lene9029', 'id': 166233538, 'node_id': 'U_kgDOCeiFwg', 'avatar_url': 'https://avatars.githubusercontent.com/u/166233538?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Lene9029', 'html_url': 'https://github.com/Lene9029', 'followers_url': 'https://api.github.com/users/Lene9029/followers', 'following_url': 'https://api.github.com/users/Lene9029/following{/other_user}', 'gists_url': 'https://api.github.com/users/Lene9029/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Lene9029/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Lene9029/subscriptions', 'organizations_url': 'https://api.github.com/users/Lene9029/orgs', 'repos_url': 'https://api.github.com/users/Lene9029/repos', 'events_url': 'https://api.github.com/users/Lene9029/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Lene9029/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,3,2024-07-09T15:34:02Z,2024-10-20T19:49:49Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

how do i export my yolov5s model to torchscript then download that model as yolov5s.torchscript file? like in the picture
 i added.

![torchscript](https://github.com/ultralytics/yolov5/assets/166233538/614e1edf-1132-4eb1-82c1-ec43f7add3f6)

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13178/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13178/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13176,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13176/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13176/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13176/events,https://github.com/ultralytics/yolov5/issues/13176,2396640170,I_kwDOD8jP_s6O2dOq,13176,Training with HIP/ROCm,"{'login': 'JijaProGamer', 'id': 100029228, 'node_id': 'U_kgDOBfZTLA', 'avatar_url': 'https://avatars.githubusercontent.com/u/100029228?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/JijaProGamer', 'html_url': 'https://github.com/JijaProGamer', 'followers_url': 'https://api.github.com/users/JijaProGamer/followers', 'following_url': 'https://api.github.com/users/JijaProGamer/following{/other_user}', 'gists_url': 'https://api.github.com/users/JijaProGamer/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/JijaProGamer/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/JijaProGamer/subscriptions', 'organizations_url': 'https://api.github.com/users/JijaProGamer/orgs', 'repos_url': 'https://api.github.com/users/JijaProGamer/repos', 'events_url': 'https://api.github.com/users/JijaProGamer/events{/privacy}', 'received_events_url': 'https://api.github.com/users/JijaProGamer/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,3,2024-07-08T21:51:50Z,2024-10-20T19:49:45Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

As pytorch 2.3 seems to support ROC https://pytorch.org/docs/stable/notes/hip.html

With minimal code changes (only TF32 support is not present, but it uses the same cuda device as before), there should be a way to set up ultralytics to work with a amd gpu on Linux, especially when the changes should be minimal.

### Use case

And GPUs are 2-3x cheaper and have 2-3x more VRAM than their Nvidia counterparts, the only thing holding them back is the ROCm support in ultralytics.

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13176/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13176/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13173,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13173/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13173/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13173/events,https://github.com/ultralytics/yolov5/issues/13173,2394057636,I_kwDOD8jP_s6Osmuk,13173, Saving Early Stopping Patience Value in last.pt Checkpoint,"{'login': 'mabubakarsaleem', 'id': 97425579, 'node_id': 'U_kgDOBc6Yqw', 'avatar_url': 'https://avatars.githubusercontent.com/u/97425579?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mabubakarsaleem', 'html_url': 'https://github.com/mabubakarsaleem', 'followers_url': 'https://api.github.com/users/mabubakarsaleem/followers', 'following_url': 'https://api.github.com/users/mabubakarsaleem/following{/other_user}', 'gists_url': 'https://api.github.com/users/mabubakarsaleem/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mabubakarsaleem/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mabubakarsaleem/subscriptions', 'organizations_url': 'https://api.github.com/users/mabubakarsaleem/orgs', 'repos_url': 'https://api.github.com/users/mabubakarsaleem/repos', 'events_url': 'https://api.github.com/users/mabubakarsaleem/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mabubakarsaleem/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,2,2024-07-07T13:31:17Z,2024-08-08T00:23:26Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello,

I have a question regarding the checkpointing mechanism in YOLOv5, specifically related to saving and resuming the training process.
When training a YOLOv5 model, the last.pt checkpoint saves the model's weights and optimizer state. However, it appears that training process parameters, such as the early stopping patience value, are not included in this checkpoint.
**If my training is interrupted and I restart from the last.pt checkpoint, does the **patience value reset to zero, or does it continue from the previously recorded value?****

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13173/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13173/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13172,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13172/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13172/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13172/events,https://github.com/ultralytics/yolov5/issues/13172,2393917364,I_kwDOD8jP_s6OsEe0,13172,error in cmd,"{'login': 'mojtabat96', 'id': 90424421, 'node_id': 'MDQ6VXNlcjkwNDI0NDIx', 'avatar_url': 'https://avatars.githubusercontent.com/u/90424421?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mojtabat96', 'html_url': 'https://github.com/mojtabat96', 'followers_url': 'https://api.github.com/users/mojtabat96/followers', 'following_url': 'https://api.github.com/users/mojtabat96/following{/other_user}', 'gists_url': 'https://api.github.com/users/mojtabat96/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mojtabat96/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mojtabat96/subscriptions', 'organizations_url': 'https://api.github.com/users/mojtabat96/orgs', 'repos_url': 'https://api.github.com/users/mojtabat96/repos', 'events_url': 'https://api.github.com/users/mojtabat96/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mojtabat96/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,3,2024-07-07T06:39:58Z,2024-10-20T19:49:40Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

_No response_

### Bug

hello when I run this code i get these problems!
python detect.py --weights yolov5m.pt --source 0
---------
C:\Users\mojta\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\cuda\__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ..\c10\cuda\CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count
detect: weights=['yolov5m.pt'], source=0, data=data\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
fatal: cannot change to 'C:\Users\mojta\OneDrive\Desktop\New': No such file or directory
YOLOv5  2024-7-4 Python-3.11.1 torch-2.3.1+cu121 CPU

Traceback (most recent call last):
  File ""C:\Users\mojta\OneDrive\Desktop\New folder\yolov5\detect.py"", line 313, in <module>
    main(opt)
  File ""C:\Users\mojta\OneDrive\Desktop\New folder\yolov5\detect.py"", line 308, in main
    run(**vars(opt))
  File ""C:\Users\mojta\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\_contextlib.py"", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mojta\OneDrive\Desktop\New folder\yolov5\detect.py"", line 116, in run
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mojta\OneDrive\Desktop\New folder\yolov5\models\common.py"", line 467, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mojta\OneDrive\Desktop\New folder\yolov5\models\experimental.py"", line 98, in attempt_load
    ckpt = torch.load(attempt_download(w), map_location=""cpu"")  # load
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mojta\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\serialization.py"", line 1004, in load
    with _open_zipfile_reader(opened_file) as opened_zipfile:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mojta\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\serialization.py"", line 456, in __init__
    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory



### Environment

_No response_

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13172/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13172/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13171,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13171/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13171/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13171/events,https://github.com/ultralytics/yolov5/issues/13171,2393577743,I_kwDOD8jP_s6OqxkP,13171,The GPU is not used when running detection with YOLOv5,"{'login': 'Angelinnp', 'id': 167752920, 'node_id': 'U_kgDOCf-02A', 'avatar_url': 'https://avatars.githubusercontent.com/u/167752920?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Angelinnp', 'html_url': 'https://github.com/Angelinnp', 'followers_url': 'https://api.github.com/users/Angelinnp/followers', 'following_url': 'https://api.github.com/users/Angelinnp/following{/other_user}', 'gists_url': 'https://api.github.com/users/Angelinnp/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Angelinnp/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Angelinnp/subscriptions', 'organizations_url': 'https://api.github.com/users/Angelinnp/orgs', 'repos_url': 'https://api.github.com/users/Angelinnp/repos', 'events_url': 'https://api.github.com/users/Angelinnp/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Angelinnp/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,6,2024-07-06T14:15:08Z,2024-10-20T19:49:38Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Multi-GPU

### Bug

![WhatsApp Image 2024-07-04 at 09 58 08](https://github.com/ultralytics/yolov5/assets/167752920/0737bb00-8c51-4ec8-8efd-66503ca78695)
When I run the YOLOv5 detection code, it still uses CPU. And it causes the detection process to be slow, I get fps = 0.4. For installation, CUDA has been activated but the CUDA on the Jetson nano is still not used. Please give me an explanation why it happened and what is the solution?
The following are the versions of CUDA 10.2.300 and pytorch 2.3.1 that I have installed.
I use the virtual environment Python 3.8.0. Please tell which version of Pytorch and CUDA suits my python virtual environment. Please help me
![WhatsApp Image 2024-07-05 at 21 29 04](https://github.com/ultralytics/yolov5/assets/167752920/8714a8d8-9658-4e30-8ce2-fcabf72fbdcb)
![versi cuda](https://github.com/ultralytics/yolov5/assets/167752920/dabdbddd-c993-4a3c-a701-a4ed4e371f07)


### Environment

- YOLO : YOLO v5 CUDA 10.2.300 and pytorch 2.3.1 Python 3.8.0

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13171/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13171/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13170,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13170/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13170/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13170/events,https://github.com/ultralytics/yolov5/issues/13170,2393490865,I_kwDOD8jP_s6OqcWx,13170,Problems with prediction ratios in multi-class training,"{'login': 'zengweigit', 'id': 33178471, 'node_id': 'MDQ6VXNlcjMzMTc4NDcx', 'avatar_url': 'https://avatars.githubusercontent.com/u/33178471?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/zengweigit', 'html_url': 'https://github.com/zengweigit', 'followers_url': 'https://api.github.com/users/zengweigit/followers', 'following_url': 'https://api.github.com/users/zengweigit/following{/other_user}', 'gists_url': 'https://api.github.com/users/zengweigit/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/zengweigit/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/zengweigit/subscriptions', 'organizations_url': 'https://api.github.com/users/zengweigit/orgs', 'repos_url': 'https://api.github.com/users/zengweigit/repos', 'events_url': 'https://api.github.com/users/zengweigit/events{/privacy}', 'received_events_url': 'https://api.github.com/users/zengweigit/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,5,2024-07-06T09:29:59Z,2024-10-20T19:49:36Z,,NONE,,"### Search before asking

- [x] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello, I am using YOLOV5. When I train a custom model, the prediction ratio of no_helmet is 96 when I only have one category. After I add a wrong_glove category, the prediction ratio of no_helmet is only 90. The same dataset is used for both trainings. Can you give me some optimization suggestions?

![lQLPKHUwzzysStvNAyPNB_GwJEEXr2MfKnwGc2ytUrl1AA_2033_803](https://github.com/ultralytics/yolov5/assets/33178471/77ed2a74-f255-4121-8007-a1676a09da8c)

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13170/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13170/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13161,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13161/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13161/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13161/events,https://github.com/ultralytics/yolov5/issues/13161,2388188984,I_kwDOD8jP_s6OWN84,13161,How can I process the features during inference?,"{'login': 'Yangchen-nudt', 'id': 155145106, 'node_id': 'U_kgDOCT9Tkg', 'avatar_url': 'https://avatars.githubusercontent.com/u/155145106?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Yangchen-nudt', 'html_url': 'https://github.com/Yangchen-nudt', 'followers_url': 'https://api.github.com/users/Yangchen-nudt/followers', 'following_url': 'https://api.github.com/users/Yangchen-nudt/following{/other_user}', 'gists_url': 'https://api.github.com/users/Yangchen-nudt/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Yangchen-nudt/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Yangchen-nudt/subscriptions', 'organizations_url': 'https://api.github.com/users/Yangchen-nudt/orgs', 'repos_url': 'https://api.github.com/users/Yangchen-nudt/repos', 'events_url': 'https://api.github.com/users/Yangchen-nudt/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Yangchen-nudt/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,7,2024-07-03T09:50:35Z,2024-10-20T19:49:22Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

So much thank if developers can see my question and chat with me :)
I use yolov5 project with ByteTrack(which is a two stage method: detect, then associate) to achieve multi-object tracking. But I found that there existing some missed detection:
![2024-07-03 17-27-01屏幕截图](https://github.com/ultralytics/yolov5/assets/155145106/3f54527b-140f-4797-9760-b0f406dfb5bb)
As shown in the pic, the car in the Bottom Right side cannot be detected (maybe due to the shadow cast on the car)
However, i can inform the yolov5 algorithm the probable position of the undetected car, because it's detected in the previous tracking.
So i think maybe i can enhance the three feature maps before the detect head. Specifically speaking, I generate one Gaussian distribution heatmap(the probable position is the peak point), and element-wise multiply the heatmap with the feature map. In this case, I want to let the yolov5 pay more attention to the probable position.
Then when it comes to the pratical coding, I meet some problems cause I'm not that familiar with pytorch. I don't know how to extract the features before the Detect Head during inference, process them and them feed them back to the final Detect Head.
I notice before the non_max_suppression, the detected result is given by:
`# Inference
        with dt[1]:
            visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False
            if model.xml and im.shape[0] > 1:
                pred = None
                for image in ims:
                    if pred is None:
                        pred = model(image, augment=augment, visualize=visualize).unsqueeze(0)
                    else:
                        pred = torch.cat((pred, model(image, augment=augment, visualize=visualize).unsqueeze(0)), dim=0)
                pred = [pred, None]
            else:
                pred = model(im, augment=augment, visualize=visualize)`
and the model is loaded with my trained weight. What should I do if i want to extract the feature map and then feed it back to the final Detect head?

I'll appreciate it for any instructions given to me. Long for your reply

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13161/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13161/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13150,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13150/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13150/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13150/events,https://github.com/ultralytics/yolov5/pull/13150,2381566996,PR_kwDOD8jP_s5z88vP,13150,modify default value of stride to 64 in the function letterbox,"{'login': 'TommeyChang', 'id': 15918318, 'node_id': 'MDQ6VXNlcjE1OTE4MzE4', 'avatar_url': 'https://avatars.githubusercontent.com/u/15918318?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/TommeyChang', 'html_url': 'https://github.com/TommeyChang', 'followers_url': 'https://api.github.com/users/TommeyChang/followers', 'following_url': 'https://api.github.com/users/TommeyChang/following{/other_user}', 'gists_url': 'https://api.github.com/users/TommeyChang/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/TommeyChang/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/TommeyChang/subscriptions', 'organizations_url': 'https://api.github.com/users/TommeyChang/orgs', 'repos_url': 'https://api.github.com/users/TommeyChang/repos', 'events_url': 'https://api.github.com/users/TommeyChang/events{/privacy}', 'received_events_url': 'https://api.github.com/users/TommeyChang/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,8,2024-06-29T07:51:22Z,2024-09-16T14:56:38Z,,NONE,,"<!--
Thank you 🙏 for your contribution to [Ultralytics](https://ultralytics.com) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. **Check for Existing Contributions**: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. **Link Related Issues**: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. **Elaborate Your Changes**: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. **Ultralytics Contributor License Agreement (CLA)**: To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    _I have read the CLA Document and I sign the CLA_

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.
--->
When the default value of stride is 32, it confronts an error when the width or height of the image is resized to 864.
I fix the bug from setting the stride to 64. Thus, I suggest to change the default value.

---
    I have read the CLA Document and I sign the CLA
---

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Small update to the image preprocessing in YOLOv5 to allow more flexible stride options.

### 📊 Key Changes
- Modified the `letterbox` function's `stride` parameter from a default of `32` to `64`.

### 🎯 Purpose & Impact
- **Improved Flexibility**: By increasing the default `stride` value, images can be resized and padded with more flexible stride options.
- **Potential Performance Impact**: This may affect model inference times or performance based on how images are processed, possibly improving efficiency for certain applications.
- **User Convenience**: Users may experience improved outcomes in training and inference without needing to manually adjust stride settings.

Overall, this change aims to optimize image preprocessing, benefiting both developers and end-users by making the model slightly more adaptable and efficient. 📈✨",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13150/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13150/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13150', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13150', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13150.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13150.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13144,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13144/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13144/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13144/events,https://github.com/ultralytics/yolov5/issues/13144,2379104336,I_kwDOD8jP_s6NzkBQ,13144,How to increase FPS camera capture inside the Raspberry Pi 4B 8GB with best.onnx model,"{'login': 'Killuagg', 'id': 168774427, 'node_id': 'U_kgDOCg9LGw', 'avatar_url': 'https://avatars.githubusercontent.com/u/168774427?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Killuagg', 'html_url': 'https://github.com/Killuagg', 'followers_url': 'https://api.github.com/users/Killuagg/followers', 'following_url': 'https://api.github.com/users/Killuagg/following{/other_user}', 'gists_url': 'https://api.github.com/users/Killuagg/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Killuagg/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Killuagg/subscriptions', 'organizations_url': 'https://api.github.com/users/Killuagg/orgs', 'repos_url': 'https://api.github.com/users/Killuagg/repos', 'events_url': 'https://api.github.com/users/Killuagg/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Killuagg/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,13,2024-06-27T21:16:08Z,2024-10-20T19:49:02Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Detection

### Bug

Hi, i am currently trying to make traffic sign detection and recognition by using the YOLOv5 Pytorch with Yolov5s model. I am using detect.py file to run the model and the FPS i get is only 1 FPS. The dataset contain around 2K images with 200 epochs. I run the code with:
python detect.py --weights best.onnx --img 640 --conf 0.7 --source 0

Is there any modify to the code so that i can get more than 4FPS?

### Environment

-Raspberry Pi 4B with 8GB Ram
-Webcam
-Model best.onnx
-Train using Yolov5 Pytorch

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13144/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13144/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13124,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13124/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13124/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13124/events,https://github.com/ultralytics/yolov5/issues/13124,2369457059,I_kwDOD8jP_s6NOwuj,13124,Model distillation for yolov5,"{'login': 'anazkhan', 'id': 106157248, 'node_id': 'U_kgDOBlPUwA', 'avatar_url': 'https://avatars.githubusercontent.com/u/106157248?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/anazkhan', 'html_url': 'https://github.com/anazkhan', 'followers_url': 'https://api.github.com/users/anazkhan/followers', 'following_url': 'https://api.github.com/users/anazkhan/following{/other_user}', 'gists_url': 'https://api.github.com/users/anazkhan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/anazkhan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/anazkhan/subscriptions', 'organizations_url': 'https://api.github.com/users/anazkhan/orgs', 'repos_url': 'https://api.github.com/users/anazkhan/repos', 'events_url': 'https://api.github.com/users/anazkhan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/anazkhan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,22,2024-06-24T07:27:59Z,2024-11-03T17:23:19Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello,
can you please guide me on how to perform model distillation for yolov5 where yolov5n is the student model and yolov5l is the teacher model . it will be helpful if you can explain the steps in detail and the code involved as i am not able to find a proper guide online.
Thanks in Advance

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13124/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13124/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13117,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13117/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13117/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13117/events,https://github.com/ultralytics/yolov5/pull/13117,2365699546,PR_kwDOD8jP_s5zI96O,13117,"Refactor YOLOv5 code for readability, maintainability, and efficiency","{'login': 'sanowl', 'id': 99511815, 'node_id': 'U_kgDOBe5uBw', 'avatar_url': 'https://avatars.githubusercontent.com/u/99511815?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/sanowl', 'html_url': 'https://github.com/sanowl', 'followers_url': 'https://api.github.com/users/sanowl/followers', 'following_url': 'https://api.github.com/users/sanowl/following{/other_user}', 'gists_url': 'https://api.github.com/users/sanowl/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/sanowl/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/sanowl/subscriptions', 'organizations_url': 'https://api.github.com/users/sanowl/orgs', 'repos_url': 'https://api.github.com/users/sanowl/repos', 'events_url': 'https://api.github.com/users/sanowl/events{/privacy}', 'received_events_url': 'https://api.github.com/users/sanowl/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,2,2024-06-21T04:41:32Z,2024-09-16T14:56:38Z,,NONE,,"This pull request refactors the YOLOv5 codebase to enhance readability, maintainability, and efficiency. Key improvements include:

- Added comprehensive comments and docstrings for better clarity.
- Introduced type hints to improve code understanding and maintainability.
- Enhanced modularity by structuring functions and classes.
- Reformatted the code according to PEP 8 guidelines for improved readability.
- Improved error handling during model testing.

These changes aim to make the code more maintainable, readable, and easier to understand for current and future developers.



## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Minor typo correction in the YOLOv5 classification model code.

### 📊 Key Changes
- Fixed a typo in the constructor docstring: corrected ""cuttoff"" to ""cutoff"".

### 🎯 Purpose & Impact
- **Improved Readability**: Enhances documentation accuracy and readability 💻✨.
- **User Confidence**: Small corrections can build overall confidence in the quality and maintainability of the codebase.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13117/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13117/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13117', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13117', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13117.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13117.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13057,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13057/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13057/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13057/events,https://github.com/ultralytics/yolov5/issues/13057,2328434467,I_kwDOD8jP_s6KyRcj,13057,yolov5 Tensortt errors ?,"{'login': 'Janeqs-cx', 'id': 124816825, 'node_id': 'U_kgDOB3CNuQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/124816825?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Janeqs-cx', 'html_url': 'https://github.com/Janeqs-cx', 'followers_url': 'https://api.github.com/users/Janeqs-cx/followers', 'following_url': 'https://api.github.com/users/Janeqs-cx/following{/other_user}', 'gists_url': 'https://api.github.com/users/Janeqs-cx/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Janeqs-cx/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Janeqs-cx/subscriptions', 'organizations_url': 'https://api.github.com/users/Janeqs-cx/orgs', 'repos_url': 'https://api.github.com/users/Janeqs-cx/repos', 'events_url': 'https://api.github.com/users/Janeqs-cx/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Janeqs-cx/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,11,2024-05-31T19:04:00Z,2024-10-20T19:47:01Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I was trying to run tensort with my trained best.engine version. I checked best.engine file and it's working fine with tensort but when tried to run with script by yolov5 it's give these errors : 


PS C:\Users\Janek\Desktop\Val-sz> & c:/Users/Janek/Desktop/Val-sz/cheats-env/Scripts/python.exe c:/Users/Janek/Desktop/Val-sz/scripts/dxcam_main.py
YOLOv5  2022-11-22 Python-3.10.5 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6144MiB)

Loading C:\Users\Janek\Desktop\Val-sz\scripts\best.engine for TensorRT inference...
[05/31/2024-21:01:11] [TRT] [I] [MemUsageChange] Init CUDA: CPU +297, GPU +0, now: CPU 11292, GPU 1015 (MiB)
[05/31/2024-21:01:11] [TRT] [I] Loaded engine size: 10 MiB
[05/31/2024-21:01:11] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[05/31/2024-21:01:11] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
C:\Users\Janek\Desktop\Val-sz\cheats-env\lib\site-packages\tensorrt\__init__.py:331: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  bool: np.bool,
Traceback (most recent call last):
  File ""C:\Users\Janek\Desktop\Val-sz\yolov5\hubconf.py"", line 49, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""C:\Users\Janek\Desktop\Val-sz\yolov5\models\common.py"", line 406, in __init__
    dtype = trt.nptype(model.get_binding_dtype(i))
  File ""C:\Users\Janek\Desktop\Val-sz\cheats-env\lib\site-packages\tensorrt\__init__.py"", line 331, in nptype
    bool: np.bool,
  File ""C:\Users\Janek\Desktop\Val-sz\cheats-env\lib\site-packages\numpy\__init__.py"", line 338, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically 
wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Janek\Desktop\Val-sz\yolov5\hubconf.py"", line 60, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""C:\Users\Janek\Desktop\Val-sz\yolov5\models\experimental.py"", line 79, in attempt_load
    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load
  File ""C:\Users\Janek\Desktop\Val-sz\cheats-env\lib\site-packages\torch\serialization.py"", line 713, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File ""C:\Users\Janek\Desktop\Val-sz\cheats-env\lib\site-packages\torch\serialization.py"", line 920, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: unpickling stack underflow

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""c:\Users\Janek\Desktop\Val-sz\scripts\dxcam_main.py"", line 104, in <module>
    model = torch.hub.load(r'C:\Users\Janek\Desktop\Val-sz\yolov5' , 'custom', path= r'C:\Users\Janek\Desktop\Val-sz\scripts\best.engine',source='local').cpu()
  File ""C:\Users\Janek\Desktop\Val-sz\cheats-env\lib\site-packages\torch\hub.py"", line 540, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""C:\Users\Janek\Desktop\Val-sz\cheats-env\lib\site-packages\torch\hub.py"", line 569, in _load_local
    model = entry(*args, **kwargs)
  File ""C:\Users\Janek\Desktop\Val-sz\yolov5\hubconf.py"", line 83, in custom
    return _create(path, autoshape=autoshape, verbose=_verbose, device=device)
  File ""C:\Users\Janek\Desktop\Val-sz\yolov5\hubconf.py"", line 78, in _create
    raise Exception(s) from e
Exception: unpickling stack underflow. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.


Can someone explain and help me fix it?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13057/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13057/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/13048,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13048/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13048/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13048/events,https://github.com/ultralytics/yolov5/pull/13048,2321470503,PR_kwDOD8jP_s5wyXYT,13048,Colab,"{'login': 'Leedong414', 'id': 165615367, 'node_id': 'U_kgDOCd8XBw', 'avatar_url': 'https://avatars.githubusercontent.com/u/165615367?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Leedong414', 'html_url': 'https://github.com/Leedong414', 'followers_url': 'https://api.github.com/users/Leedong414/followers', 'following_url': 'https://api.github.com/users/Leedong414/following{/other_user}', 'gists_url': 'https://api.github.com/users/Leedong414/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Leedong414/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Leedong414/subscriptions', 'organizations_url': 'https://api.github.com/users/Leedong414/orgs', 'repos_url': 'https://api.github.com/users/Leedong414/repos', 'events_url': 'https://api.github.com/users/Leedong414/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Leedong414/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,2,2024-05-28T16:20:03Z,2024-09-16T14:56:38Z,,NONE,,"

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Integration of TTS for Detected Classes Announcement in YOLOv5 Detection 🎉

### 📊 Key Changes
- Added a new Jupyter notebook example to demonstrate YOLOv5 usage with Google Colab, voice synthesis, and audio processing.
- Enhanced `detect.py` to save detected classes to a text file and use Text-To-Speech (TTS) to announce detected objects.

### 🎯 Purpose & Impact
- **Usability & Accessibility**: The addition of TTS to announce detected classes improves accessibility for visually impaired users and provides a more interactive experience for all users.
- **Education & Demonstration**: The new notebook makes it easier for beginners to experiment with YOLOv5 in an accessible and interactive environment like Google Colab.
- **Customization & Flexibility**: Users can now get audible feedback on detections, making it useful for real-time applications and projects where visual monitoring is not feasible.

This update broadens YOLOv5's appeal and utility across different user bases, from developers seeking to create accessible applications to educators and hobbyists interested in easy-to-use, interactive AI tools. 🚀",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13048/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13048/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13048', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13048', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13048.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13048.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13018,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13018/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13018/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13018/events,https://github.com/ultralytics/yolov5/pull/13018,2300451846,PR_kwDOD8jP_s5vq2LP,13018,Highlight the closest target with a different color in predictions,"{'login': '1260635600', 'id': 117345984, 'node_id': 'U_kgDOBv6OwA', 'avatar_url': 'https://avatars.githubusercontent.com/u/117345984?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/1260635600', 'html_url': 'https://github.com/1260635600', 'followers_url': 'https://api.github.com/users/1260635600/followers', 'following_url': 'https://api.github.com/users/1260635600/following{/other_user}', 'gists_url': 'https://api.github.com/users/1260635600/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/1260635600/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/1260635600/subscriptions', 'organizations_url': 'https://api.github.com/users/1260635600/orgs', 'repos_url': 'https://api.github.com/users/1260635600/repos', 'events_url': 'https://api.github.com/users/1260635600/events{/privacy}', 'received_events_url': 'https://api.github.com/users/1260635600/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,1,2024-05-16T13:41:35Z,2024-09-16T14:56:38Z,,NONE,,"    _I have read the CLA Document and I sign the CLA_

This pull request adds a feature to highlight the closest detected target with a different color in the predictions made by YOLOv5. The closest target is determined based on its distance from a reference point.

**Changes made:**
- Added a function `find_closest_target` in `detect.py` to calculate and identify the closest target.
- Updated the drawing function to change the color of the closest target.
- Modified the `detect` function to incorporate the new highlighting feature.
- Added relevant tests to ensure the functionality works as expected.

**Testing:**
- Verified the changes using sample images to ensure the closest target is correctly highlighted.
- Ran all existing unit tests and added new ones for the new feature.

This feature enhances the detection capabilities of YOLOv5, making it easier to identify the nearest object, which can be useful in applications like autonomous navigation and object tracking.


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhanced object detection in YOLOv5 with closer object highlight and streamlined code for performance.

### 📊 Key Changes
- **Numpy Integration:** Added numpy for advanced numerical calculations.
- **Code Simplification:** Simplified detection algorithms removing redundant conditions, focusing on streamlining and performance optimization.
- **Closest Object Highlight:** Implemented functionality to calculate and highlight the object closest to the image center, making it stand out by marking it in green.
- **Code Cleanup:** Removed unnecessary comments and simplified block comments for clarity and conciseness.

### 🎯 Purpose & Impact
- **Purpose:** 
  - To make the detection process more intuitive by visually emphasizing the object closest to the image center.
  - To improve the readability and performance of the code by removing redundant operations and simplifying complex constructs.
- **Impact:** 
  - **Developers:** These changes make the codebase cleaner, enhancing maintainability and ease of future enhancements.
  - **Users:** Users benefit from the new feature that highlights the closest object, potentially improving usability in applications requiring focus on central objects, such as autonomous navigation or surveillance.

📈 _Expect upgrades in performance and user experience for applications leveraging YOLOv5 for object detection._ 🕵️‍♂️🔍",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13018/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13018/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13018', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13018', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13018.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13018.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/13005,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/13005/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/13005/comments,https://api.github.com/repos/ultralytics/yolov5/issues/13005/events,https://github.com/ultralytics/yolov5/pull/13005,2291539143,PR_kwDOD8jP_s5vMMDW,13005,New Feature: added cmd line arg for saving only positives,"{'login': 'GarbageHaus', 'id': 90212322, 'node_id': 'MDQ6VXNlcjkwMjEyMzIy', 'avatar_url': 'https://avatars.githubusercontent.com/u/90212322?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/GarbageHaus', 'html_url': 'https://github.com/GarbageHaus', 'followers_url': 'https://api.github.com/users/GarbageHaus/followers', 'following_url': 'https://api.github.com/users/GarbageHaus/following{/other_user}', 'gists_url': 'https://api.github.com/users/GarbageHaus/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/GarbageHaus/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/GarbageHaus/subscriptions', 'organizations_url': 'https://api.github.com/users/GarbageHaus/orgs', 'repos_url': 'https://api.github.com/users/GarbageHaus/repos', 'events_url': 'https://api.github.com/users/GarbageHaus/events{/privacy}', 'received_events_url': 'https://api.github.com/users/GarbageHaus/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,3,2024-05-12T23:03:35Z,2024-09-16T14:56:38Z,,NONE,,"Added a simple command line argument (default False) where if set to true, only the images and videos which contain a positive identification are saved to the output.
Currently outputting the images/video in detect.py is all or nothing. This addition prevents creating duplicate files which contain no detections, while allowing for positive detections to be saved.
Location in code is not extremely efficient, but is present at that location for readability and minimal intrusiveness.

I have read the CLA Document and I sign the CLA


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Introducing a new option to save only positive detections in YOLOv5 📸✅

### 📊 Key Changes
- Added a new flag `savepositives` to the detection script. This allows users to choose to save only images or videos that contain positive detections (detections that the model is confident about).

### 🎯 Purpose & Impact
- **Efficiency Boost**: This change helps save storage space and makes it easier for users to review positive detections by not saving images or videos without any detections. 🚀
- **User-Friendly**: It enhances the usability of YOLOv5 for various projects, especially those where users are only interested in instances where the model finds something of interest. 🎉
- **Potential Impact**: This addition could significantly benefit users running detection tasks in resource-constrained environments or dealing with large datasets where filtering out no-detection outputs manually would be impractical. 📈",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/13005/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/13005/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/13005', 'html_url': 'https://github.com/ultralytics/yolov5/pull/13005', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/13005.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/13005.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12914,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12914/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12914/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12914/events,https://github.com/ultralytics/yolov5/pull/12914,2241571747,PR_kwDOD8jP_s5skVP3,12914,Updated detect.py to save images in images/ directory when save_txt is True,"{'login': 'harshdhamecha', 'id': 62664549, 'node_id': 'MDQ6VXNlcjYyNjY0NTQ5', 'avatar_url': 'https://avatars.githubusercontent.com/u/62664549?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/harshdhamecha', 'html_url': 'https://github.com/harshdhamecha', 'followers_url': 'https://api.github.com/users/harshdhamecha/followers', 'following_url': 'https://api.github.com/users/harshdhamecha/following{/other_user}', 'gists_url': 'https://api.github.com/users/harshdhamecha/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/harshdhamecha/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/harshdhamecha/subscriptions', 'organizations_url': 'https://api.github.com/users/harshdhamecha/orgs', 'repos_url': 'https://api.github.com/users/harshdhamecha/repos', 'events_url': 'https://api.github.com/users/harshdhamecha/events{/privacy}', 'received_events_url': 'https://api.github.com/users/harshdhamecha/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,0,2024-04-13T13:53:02Z,2024-09-16T14:56:38Z,,CONTRIBUTOR,,"Updated detect.py to save images in the images directory:

Earlier, inference images were saved in the `detect/exp` directory, and labels were saved in the `detect/exp/labels` directory. The proposed changes save images in the `detect/exp/images` directory to better organize and distinguish images from labels and crops. 
<!--
Thank you 🙏 for your contribution to [Ultralytics](https://ultralytics.com) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. **Check for Existing Contributions**: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. **Link Related Issues**: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. **Elaborate Your Changes**: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. **Ultralytics Contributor License Agreement (CLA)**: To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    _I have read the CLA Document and I sign the CLA_

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.
--->


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhanced File Organization for Detection Outputs 📁✨

### 📊 Key Changes
- Introduced separate directories for images and labels when `save_txt` is set to `true`.
- Images will now be saved in an ""images"" folder, and label files in a ""labels"" folder within the specified project directory.

### 🎯 Purpose & Impact
- **Improved Organization**: Creates a cleaner directory structure by segregating images and labels, making it simpler for users to navigate and manage their output files.
- **Enhanced Usability**: This change is especially beneficial for projects requiring separate handling or analysis of images and label files, streamlining workflows.
- **Potential Impact**: Users who rely on the existing file structure may need to adjust their post-detection processes to accommodate these new directories. However, the overall impact is positive, promoting a more organized and efficient file management approach.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12914/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12914/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12914', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12914', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12914.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12914.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12857,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12857/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12857/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12857/events,https://github.com/ultralytics/yolov5/issues/12857,2212222150,I_kwDOD8jP_s6D29TG,12857,ultralytics>=8.0.232 does not install on Yolov5,"{'login': 'gilmotta3', 'id': 147286779, 'node_id': 'U_kgDOCMdq-w', 'avatar_url': 'https://avatars.githubusercontent.com/u/147286779?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/gilmotta3', 'html_url': 'https://github.com/gilmotta3', 'followers_url': 'https://api.github.com/users/gilmotta3/followers', 'following_url': 'https://api.github.com/users/gilmotta3/following{/other_user}', 'gists_url': 'https://api.github.com/users/gilmotta3/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/gilmotta3/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/gilmotta3/subscriptions', 'organizations_url': 'https://api.github.com/users/gilmotta3/orgs', 'repos_url': 'https://api.github.com/users/gilmotta3/repos', 'events_url': 'https://api.github.com/users/gilmotta3/events{/privacy}', 'received_events_url': 'https://api.github.com/users/gilmotta3/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2242989015, 'node_id': 'MDU6TGFiZWwyMjQyOTg5MDE1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/Stale', 'name': 'Stale', 'color': 'ededed', 'default': False, 'description': 'Stale and schedule for closing soon'}]",open,False,,[],,29,2024-03-28T02:26:09Z,2024-10-20T19:42:25Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Other

### Bug

I wonder how this was tested, the ultralytics>=8.0.232 does not install on Jetson Nano no matter what I do. This was added 2 months ago but in the past this package wasn't there . Now pip install it is broken!

pip3 install -r requirements.txt does not work anymore due to the addition of ultralytics.

Collecting ultralytics>=8.0.232 (from -r requirements.txt (line 18))
  Could not find a version that satisfies the requirement ultralytics>=8.0.232 (from -r requirements.txt (line 18)) (from versions: )
No matching distribution found for ultralytics>=8.0.232 (from -r requirements.txt (line 18))

### Environment

Yolov5, Jetson Nano and Ubuntu 18.04 LTS by NVIDIA, Python 3.6.9

This is a Jetson Nano with CUDA so I cannot  upgrade to Pytorch 2.0,etc.

### Minimal Reproducible Example

Collecting ultralytics>=8.0.232 (from -r requirements.txt (line 18))
  Could not find a version that satisfies the requirement ultralytics>=8.0.232 (from -r requirements.txt (line 18)) (from versions: )
No matching distribution found for ultralytics>=8.0.232 (from -r requirements.txt (line 18))

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12857/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12857/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/12842,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12842/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12842/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12842/events,https://github.com/ultralytics/yolov5/pull/12842,2203706759,PR_kwDOD8jP_s5qjakx,12842,Removed manual accounting of field's count,"{'login': 'igeni', 'id': 5280697, 'node_id': 'MDQ6VXNlcjUyODA2OTc=', 'avatar_url': 'https://avatars.githubusercontent.com/u/5280697?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/igeni', 'html_url': 'https://github.com/igeni', 'followers_url': 'https://api.github.com/users/igeni/followers', 'following_url': 'https://api.github.com/users/igeni/following{/other_user}', 'gists_url': 'https://api.github.com/users/igeni/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/igeni/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/igeni/subscriptions', 'organizations_url': 'https://api.github.com/users/igeni/orgs', 'repos_url': 'https://api.github.com/users/igeni/repos', 'events_url': 'https://api.github.com/users/igeni/events{/privacy}', 'received_events_url': 'https://api.github.com/users/igeni/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,5,2024-03-23T05:31:33Z,2024-09-16T14:56:38Z,,NONE,,"Removed manual accounting of field's count and added option to change text justification

<!--
Thank you 🙏 for your contribution to [Ultralytics](https://ultralytics.com) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. **Check for Existing Contributions**: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. **Link Related Issues**: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. **Elaborate Your Changes**: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. **Ultralytics Contributor License Agreement (CLA)**: To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    _I have read the CLA Document and I hereby sign the CLA_

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.
--->

_I have read the CLA Document and I hereby sign the CLA_

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Refactoring log messages for simplicity and consistency 🛠️✨

### 📊 Key Changes
- Simplified the logging format in training and validation scripts.
- Changed log string concatenation to a more concise and dynamic generation method using list comprehensions.
- Removed verbose, repetitive code blocks for logging, replaced with cleaner, one-line statements.

### 🎯 Purpose & Impact
- **Purpose:** To make the codebase easier to maintain and understand by streamlining the generation of log messages. This change supports cleaner code practices and reduces clutter.
- **Impact:** Users will experience no direct impact on functionality, but developers working on or with YOLOv5 will find the code more accessible and easier to modify or debug. The change also ensures that log messages maintain a consistent format, improving readability for users monitoring training or validation processes.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12842/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12842/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12842', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12842', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12842.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12842.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12785,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12785/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12785/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12785/events,https://github.com/ultralytics/yolov5/pull/12785,2169617019,PR_kwDOD8jP_s5ovRHy,12785,Fix: NotImplementedError: cannot instantiate 'PosixPath' on your system on Windows platform,"{'login': 'abdulhakkeempa', 'id': 92361680, 'node_id': 'U_kgDOBYFT0A', 'avatar_url': 'https://avatars.githubusercontent.com/u/92361680?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/abdulhakkeempa', 'html_url': 'https://github.com/abdulhakkeempa', 'followers_url': 'https://api.github.com/users/abdulhakkeempa/followers', 'following_url': 'https://api.github.com/users/abdulhakkeempa/following{/other_user}', 'gists_url': 'https://api.github.com/users/abdulhakkeempa/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/abdulhakkeempa/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/abdulhakkeempa/subscriptions', 'organizations_url': 'https://api.github.com/users/abdulhakkeempa/orgs', 'repos_url': 'https://api.github.com/users/abdulhakkeempa/repos', 'events_url': 'https://api.github.com/users/abdulhakkeempa/events{/privacy}', 'received_events_url': 'https://api.github.com/users/abdulhakkeempa/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,8,2024-03-05T16:09:44Z,2024-09-16T14:56:38Z,,NONE,,"When the inference code was run on the Windows platform, it raised an error: NotImplementedError: cannot instantiate 'PosixPath' on your system. This issue has been fixed by adding three lines of code to detect.py. After testing, it was found to work fine. Closes ultralytics/yolov5#10240.


## Changes made
```
# Updating PosixPath on Windows for compatibility
if sys.platform == ""win32"":
    temp = pathlib.PosixPath
    pathlib.PosixPath = pathlib.WindowsPath
    del temp
```


<!--
Thank you 🙏 for your contribution to [Ultralytics](https://ultralytics.com) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. **Check for Existing Contributions**: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
2. **Link Related Issues**: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
3. **Elaborate Your Changes**: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.
4. **Ultralytics Contributor License Agreement (CLA)**: To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:



For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.
--->
_I have read the CLA Document and I hereby sign the CLA_



## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Improved Windows compatibility in YOLOv5's detect.py script 🔍💻

### 📊 Key Changes
- Added a compatibility fix for Windows environments involving the `pathlib` module.

### 🎯 Purpose & Impact
- The change ensures that the YOLOv5 detection script can run smoothly on Windows systems by addressing path handling issues.
- Users on Windows will experience fewer issues related to file paths, leading to a more pleasant development or deployment experience.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12785/reactions', 'total_count': 2, '+1': 2, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12785/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12785', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12785', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12785.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12785.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12706,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12706/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12706/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12706/events,https://github.com/ultralytics/yolov5/pull/12706,2117232298,PR_kwDOD8jP_s5l9CfS,12706,CORS Updated,"{'login': 'atif275', 'id': 128026115, 'node_id': 'U_kgDOB6GGAw', 'avatar_url': 'https://avatars.githubusercontent.com/u/128026115?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/atif275', 'html_url': 'https://github.com/atif275', 'followers_url': 'https://api.github.com/users/atif275/followers', 'following_url': 'https://api.github.com/users/atif275/following{/other_user}', 'gists_url': 'https://api.github.com/users/atif275/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/atif275/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/atif275/subscriptions', 'organizations_url': 'https://api.github.com/users/atif275/orgs', 'repos_url': 'https://api.github.com/users/atif275/repos', 'events_url': 'https://api.github.com/users/atif275/events{/privacy}', 'received_events_url': 'https://api.github.com/users/atif275/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,2,2024-02-04T17:48:44Z,2024-09-16T14:56:38Z,,NONE,,"

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Introducing a web application for streaming and running object detection on videos.

### 📊 Key Changes
- Added `app.py` to create a Flask web app with endpoints to start/stop the video stream, list videos, and run detection.
- Modified `detect.py` to change the default detection source to the ""videos"" directory.
- Added `static/script.js` for handling UI interactions like starting/stopping streams and triggering video detections.
- Created `static/style.css` to apply styles to the web application's UI elements.
- Developed `templates/index.html` to set up the structure and layout of the web front-end.

### 🎯 Purpose & Impact
- Enables users to interact with YOLOv5 object detection via a user-friendly web interface.
- Adds functionality for live streaming video that can be started or stopped and processed for object detection.
- Provides capabilities to select and play videos, as well as initiate detection on demand, enhancing the accessibility and user experience of the object detection system.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12706/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12706/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12706', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12706', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12706.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12706.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12610,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12610/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12610/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12610/events,https://github.com/ultralytics/yolov5/pull/12610,2075499434,PR_kwDOD8jP_s5jvsXb,12610,translucent line for visibility,"{'login': 'mucunwuxian', 'id': 9916906, 'node_id': 'MDQ6VXNlcjk5MTY5MDY=', 'avatar_url': 'https://avatars.githubusercontent.com/u/9916906?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mucunwuxian', 'html_url': 'https://github.com/mucunwuxian', 'followers_url': 'https://api.github.com/users/mucunwuxian/followers', 'following_url': 'https://api.github.com/users/mucunwuxian/following{/other_user}', 'gists_url': 'https://api.github.com/users/mucunwuxian/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mucunwuxian/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mucunwuxian/subscriptions', 'organizations_url': 'https://api.github.com/users/mucunwuxian/orgs', 'repos_url': 'https://api.github.com/users/mucunwuxian/repos', 'events_url': 'https://api.github.com/users/mucunwuxian/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mucunwuxian/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,10,2024-01-11T00:59:42Z,2024-09-16T14:56:38Z,,CONTRIBUTOR,,"Thank you 🙏 for your contribution to [Ultralytics](https://ultralytics.com) 🚀! Your effort in enhancing our repositories is greatly appreciated. To streamline the process and assist us in integrating your Pull Request (PR) effectively, please follow these steps:

1. **Check for Existing Contributions**: Before submitting, kindly explore existing PRs to ensure your contribution is unique and complementary.
  
**-> I checked that there are no similar PRs.**

<br/>
<br/>

2. **Link Related Issues**: If your PR addresses an open issue, please link it in your submission. This helps us better understand the context and impact of your contribution.
  
**-> I created an issue. https://github.com/ultralytics/yolov5/issues/12612**

<br/>
<br/>

3. **Elaborate Your Changes**: Clearly articulate the purpose of your PR. Whether it's a bug fix or a new feature, a detailed description aids in a smoother integration process.

**-> I added an argument to make the bounding box line translucent to improve visibility of results.
How about this?**
  
<br/>
<br/>

4. **Ultralytics Contributor License Agreement (CLA)**: To uphold the quality and integrity of our project, we require all contributors to sign the CLA. Please confirm your agreement by commenting below:

    _I have read the CLA Document and I hereby sign the CLA_

**-> I have read the CLA Document and I hereby sign the CLA.**

<br/>
<br/>

For more detailed guidance and best practices on contributing, refer to our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing). Your adherence to these guidelines ensures a faster and more effective review process.


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 📊 Key Changes
- Imported the `numpy` library to manipulate image data.
- Added a new parameter `line_alpha` for bounding box transparency in the `detect.py` script.

### 🎯 Purpose & Impact
The purpose of introducing `line_alpha` is to enhance the visibility of detection results by making the bounding boxes translucent. This change can help users discern background details that might be important for context without compromising the visibility of the bounding box itself. The impact is improved visual analysis for the user, especially in situations where seeing the background information is just as critical as seeing the object detections.

### 🌟 Summary
Introducing 🔎 translucent bounding boxes in Ultralytics' YOLOv5 for better visibility and context during object detection.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12610/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12610/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12610', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12610', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12610.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12610.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12599,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12599/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12599/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12599/events,https://github.com/ultralytics/yolov5/pull/12599,2070326054,PR_kwDOD8jP_s5jeB0Y,12599,Copy-Paste augmentation,"{'login': 'Arno1235', 'id': 67476721, 'node_id': 'MDQ6VXNlcjY3NDc2NzIx', 'avatar_url': 'https://avatars.githubusercontent.com/u/67476721?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Arno1235', 'html_url': 'https://github.com/Arno1235', 'followers_url': 'https://api.github.com/users/Arno1235/followers', 'following_url': 'https://api.github.com/users/Arno1235/following{/other_user}', 'gists_url': 'https://api.github.com/users/Arno1235/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Arno1235/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Arno1235/subscriptions', 'organizations_url': 'https://api.github.com/users/Arno1235/orgs', 'repos_url': 'https://api.github.com/users/Arno1235/repos', 'events_url': 'https://api.github.com/users/Arno1235/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Arno1235/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,9,2024-01-08T12:12:07Z,2024-09-16T14:56:38Z,,NONE,,"Currently the Copy-Paste augmentation only flips the copied object and places it if it doesn't overlap too much.
This code places the copied object randomly on the image and places it if it doesn't overlap too much (like the cited paper explains https://arxiv.org/abs/2012.07177).

Possible improvements:
- The copied object could also be augmented (flip, scale, ...) before placing it on the image.


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 📊 Key Changes
- Added `shift_array` function to handle image translation.
- Improved `copy_paste` augmentation method to include random translation with boundary checks and segment translation.

### 🎯 Purpose & Impact
The changes introduce a more diverse Copy-Paste augmentation which can enhance model robustness by training it on images with objects pasted in variable positions. It makes the training process closer to real-world scenarios where objects can appear anywhere in the frame, thus helping the model generalize better. This could potentially improve object detection accuracy in unseen data.

### 🌟 Summary
Implemented enhanced Copy-Paste augmentation for better object detection model training. 🎨✂️📌",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12599/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12599/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12599', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12599', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12599.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12599.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12465,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12465/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12465/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12465/events,https://github.com/ultralytics/yolov5/pull/12465,2024145962,PR_kwDOD8jP_s5hEehz,12465,a good day,"{'login': 'tacyi', 'id': 31798276, 'node_id': 'MDQ6VXNlcjMxNzk4Mjc2', 'avatar_url': 'https://avatars.githubusercontent.com/u/31798276?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/tacyi', 'html_url': 'https://github.com/tacyi', 'followers_url': 'https://api.github.com/users/tacyi/followers', 'following_url': 'https://api.github.com/users/tacyi/following{/other_user}', 'gists_url': 'https://api.github.com/users/tacyi/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/tacyi/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/tacyi/subscriptions', 'organizations_url': 'https://api.github.com/users/tacyi/orgs', 'repos_url': 'https://api.github.com/users/tacyi/repos', 'events_url': 'https://api.github.com/users/tacyi/events{/privacy}', 'received_events_url': 'https://api.github.com/users/tacyi/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,4,2023-12-04T15:36:56Z,2024-09-16T14:56:38Z,,NONE,,"<!--
Thank you for submitting a YOLOv5 🚀 Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing) for more details.

Note that Copilot will summarize this PR below, do not modify the 'copilot:all' line.
-->

<!--
copilot:all
-->
### <samp>🤖[[deprecated]](https://githubnext.com/copilot-for-prs-sunset) Generated by Copilot at d75e918</samp>

### Summary
😊🙃🤨

<!--
1.  😊 This emoji conveys a positive and friendly emotion, which may match the intention of the greeting. It could also suggest that the change is harmless and not a serious issue.
2.  🙃 This emoji conveys a playful or sarcastic emotion, which may imply that the greeting is a joke or a prank. It could also suggest that the change is not very important or relevant to the project.
3.  🤨 This emoji conveys a skeptical or questioning emotion, which may indicate that the greeting is unexpected or inappropriate. It could also suggest that the change is a potential problem or a violation of the code style or standards.
-->
Added a greeting to `train.py`. This is a cosmetic change that does not alter the logic or performance of the training script.

> _`greeting` in code_
> _a friendly gesture or a joke?_
> _autumn leaves fall_

### Walkthrough
* Add a greeting to the first line of the file `train.py` ([link](https://github.com/ultralytics/yolov5/pull/12465/files?diff=unified&w=0#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L1-R1))




## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 📊 Key Changes
The PR includes a change in the `train.py` script, although the exact modifications are not shown in the provided diff snippet.

### 🎯 Purpose & Impact
The purpose of the change is unclear due to the lack of context. Normally, changes to `train.py` could involve updating training configurations, introducing new features, optimizing performance, or fixing bugs. The impact would be changes to how users train their YOLOv5 models, potentially making it easier, more efficient, or more effective.

### 🌟 Summary
""Train script update – the outcome is a mystery 🕵️‍♂️🔍 but it's geared for an improved YOLOv5 training experience. Stay tuned for the reveal!""",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12465/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12465/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12465', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12465', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12465.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12465.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12264,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12264/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12264/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12264/events,https://github.com/ultralytics/yolov5/pull/12264,1955583718,PR_kwDOD8jP_s5dcxsl,12264,Implementation of : HIC-YOLOv5: Improved YOLOv5 for Small Object Detection,"{'login': 'aash1999', 'id': 39939476, 'node_id': 'MDQ6VXNlcjM5OTM5NDc2', 'avatar_url': 'https://avatars.githubusercontent.com/u/39939476?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/aash1999', 'html_url': 'https://github.com/aash1999', 'followers_url': 'https://api.github.com/users/aash1999/followers', 'following_url': 'https://api.github.com/users/aash1999/following{/other_user}', 'gists_url': 'https://api.github.com/users/aash1999/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/aash1999/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/aash1999/subscriptions', 'organizations_url': 'https://api.github.com/users/aash1999/orgs', 'repos_url': 'https://api.github.com/users/aash1999/repos', 'events_url': 'https://api.github.com/users/aash1999/events{/privacy}', 'received_events_url': 'https://api.github.com/users/aash1999/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,34,2023-10-21T17:10:34Z,2024-11-02T15:26:25Z,,NONE,,"This repository contains the code for HIC-YOLOv5, an improved version of YOLOv5 tailored for small object detection. The improvements are based on the paper [HIC-YOLOv5: Improved YOLOv5 For Small Object Detection](https://arxiv.org/pdf/2309.16393v1.pdf).

HIC-YOLOv5 incorporates Channel Attention Block (CBAM) and Involution modules for enhanced object detection, making it suitable for both CPU and GPU training.

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 📊 Key Changes
- New hyperparameter file for small object detection, `hyp.hic-yolov5s.yaml`, tailored to the VisDrone Dataset.
- Introduction of `ChannelAttention` and `SpatialAttention` modules in `common.py` to enhance feature representation.
- Implementation of `CBAM` module, combining channel and spatial attention for richness in feature maps.
- Addition of `Involution` module, a novel operation to address limitations of convolutions.
- Creation of `yolov5s-cbam-involution.yaml` architecture with CBAM and Involution integrated into the YOLOv5s model.

### 🎯 Purpose & Impact
- The PR aims to improve YOLOv5's ability to detect small objects, a common challenge in drone and surveillance applications.
- Attention mechanisms (CBAM) and involution help in capturing better feature representations without significantly increasing computational cost.
- Users can expect improved performance on datasets with small objects without major changes to their existing workflows.

### 🌟 Summary
""YOLOv5 enhancements with attention mechanisms and involution for boosting small object detection performance."" 🛸🔍","{'login': 'aash1999', 'id': 39939476, 'node_id': 'MDQ6VXNlcjM5OTM5NDc2', 'avatar_url': 'https://avatars.githubusercontent.com/u/39939476?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/aash1999', 'html_url': 'https://github.com/aash1999', 'followers_url': 'https://api.github.com/users/aash1999/followers', 'following_url': 'https://api.github.com/users/aash1999/following{/other_user}', 'gists_url': 'https://api.github.com/users/aash1999/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/aash1999/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/aash1999/subscriptions', 'organizations_url': 'https://api.github.com/users/aash1999/orgs', 'repos_url': 'https://api.github.com/users/aash1999/repos', 'events_url': 'https://api.github.com/users/aash1999/events{/privacy}', 'received_events_url': 'https://api.github.com/users/aash1999/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12264/reactions', 'total_count': 3, '+1': 1, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 2}",https://api.github.com/repos/ultralytics/yolov5/issues/12264/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12264', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12264', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12264.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12264.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/12209,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12209/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12209/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12209/events,https://github.com/ultralytics/yolov5/pull/12209,1931785838,PR_kwDOD8jP_s5cMSPR,12209,fix bug for trt inference,"{'login': 'AllenZYJ', 'id': 34624932, 'node_id': 'MDQ6VXNlcjM0NjI0OTMy', 'avatar_url': 'https://avatars.githubusercontent.com/u/34624932?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AllenZYJ', 'html_url': 'https://github.com/AllenZYJ', 'followers_url': 'https://api.github.com/users/AllenZYJ/followers', 'following_url': 'https://api.github.com/users/AllenZYJ/following{/other_user}', 'gists_url': 'https://api.github.com/users/AllenZYJ/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AllenZYJ/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AllenZYJ/subscriptions', 'organizations_url': 'https://api.github.com/users/AllenZYJ/orgs', 'repos_url': 'https://api.github.com/users/AllenZYJ/repos', 'events_url': 'https://api.github.com/users/AllenZYJ/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AllenZYJ/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,11,2023-10-08T12:23:15Z,2024-09-16T14:56:38Z,,NONE,,"<!--
Thank you for submitting a YOLOv5 🚀 Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing) for more details.

Note that Copilot will summarize this PR below, do not modify the 'copilot:all' line.
-->
When I was doing inference with ”engine“ on “Nvidia agx” device, I found that ”segment/predict.py“ would report a dimension mismatch error. The reason was that the output branch selection was wrong. This simple change fixes that error, and allows smooth inference on trt devices. 
<!--
copilot:all
-->
### <samp>🤖 Generated by Copilot at 19c8663</samp>

### Summary
🐛🚀🧠

<!--
1.  🐛 - This emoji represents a bug fix, since the change fixes a bug that causes incorrect detection results when using TensorRT.
2.  🚀 - This emoji represents a performance improvement, since the change uses TensorRT to accelerate the inference of the YOLOv5 model.
3.  🧠 - This emoji represents a machine learning or artificial intelligence feature, since the change involves a deep learning model and an inference engine.
-->
Fix output order bug in `models/common.py` for TensorRT. Hardcode output names to match YOLOv5 output layers.

> _`y` variable_
> _hardcoded for TensorRT_
> _autumn bug fixing_

### Walkthrough
* Fix incorrect detection results when using TensorRT by hardcoding output names to match output layers in YOLOv5 model ([link](https://github.com/ultralytics/yolov5/pull/12209/files?diff=unified&w=0#diff-cfb1ff087a99a34369673c9f34bdcd22f2d429ab3599a89f386c5de1fd9a2566L552-R552))




## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 📊 Key Changes
- Adjusted tensor output retrieval in `forward` method during TensorRT inference.

### 🎯 Purpose & Impact
- 🛠️ Fixes a bug in TensorRT inference that could lead to incorrect tensor outputs, ensuring the model's predictions are accurate.
- 🏃‍♂️ Increases reliability for users deploying YOLOv5 models with TensorRT, which can improve performance on compatible hardware.

### 🌟 Summary
Fixed a crucial bug in YOLOv5's TensorRT inference to ensure correct output tensors are retrieved, bolstering performance and reliability. 🐛➡️🔧","{'login': 'AllenZYJ', 'id': 34624932, 'node_id': 'MDQ6VXNlcjM0NjI0OTMy', 'avatar_url': 'https://avatars.githubusercontent.com/u/34624932?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AllenZYJ', 'html_url': 'https://github.com/AllenZYJ', 'followers_url': 'https://api.github.com/users/AllenZYJ/followers', 'following_url': 'https://api.github.com/users/AllenZYJ/following{/other_user}', 'gists_url': 'https://api.github.com/users/AllenZYJ/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AllenZYJ/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AllenZYJ/subscriptions', 'organizations_url': 'https://api.github.com/users/AllenZYJ/orgs', 'repos_url': 'https://api.github.com/users/AllenZYJ/repos', 'events_url': 'https://api.github.com/users/AllenZYJ/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AllenZYJ/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12209/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/12209/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/12209', 'html_url': 'https://github.com/ultralytics/yolov5/pull/12209', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/12209.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/12209.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/11869,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/11869/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/11869/comments,https://api.github.com/repos/ultralytics/yolov5/issues/11869/events,https://github.com/ultralytics/yolov5/pull/11869,1806746173,PR_kwDOD8jP_s5Vnb3w,11869,Mise en place dossier vidéo,"{'login': 'ptardien91', 'id': 129768267, 'node_id': 'U_kgDOB7wbSw', 'avatar_url': 'https://avatars.githubusercontent.com/u/129768267?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ptardien91', 'html_url': 'https://github.com/ptardien91', 'followers_url': 'https://api.github.com/users/ptardien91/followers', 'following_url': 'https://api.github.com/users/ptardien91/following{/other_user}', 'gists_url': 'https://api.github.com/users/ptardien91/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ptardien91/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ptardien91/subscriptions', 'organizations_url': 'https://api.github.com/users/ptardien91/orgs', 'repos_url': 'https://api.github.com/users/ptardien91/repos', 'events_url': 'https://api.github.com/users/ptardien91/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ptardien91/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,3,2023-07-16T22:53:11Z,2024-09-16T14:56:38Z,,NONE,,"

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 📊 Key Changes
- **Added two new detection scripts**: `detect2.py` and `detect3.py`. These scripts presumably contain similar functionalities to the existing `detect.py` but with some modifications tailored for different use cases or setups.
- **File permission changes**: Some shell scripts in `data/scripts` have changed from mode `100755` to `100644`, which means they are no longer executable by default but still readable and writable by the owner.

### 🎯 Purpose & Impact
- The `detect2.py` and `detect3.py` scripts likely offer additional or altered detection capabilities for processing images and videos, which may include various source inputs and format support.
- The changes in file permissions could be for security reasons, to reduce the risk of executing untrusted scripts, or simply to align with a repository standard.
- These new scripts may contain different functionalities or improvements that could benefit users who need tailored detection features.

### 🌟 Summary
New specialized detection scripts were introduced in the Ultralytics YOLOv5 repository, enhancing the toolbox for handling different data sources and formats. 🛠️✨",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/11869/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/11869/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/11869', 'html_url': 'https://github.com/ultralytics/yolov5/pull/11869', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/11869.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/11869.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/11813,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/11813/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/11813/comments,https://api.github.com/repos/ultralytics/yolov5/issues/11813/events,https://github.com/ultralytics/yolov5/pull/11813,1788505071,PR_kwDOD8jP_s5Uph4e,11813,added lighter yolov5 config files,"{'login': 'jere357', 'id': 22777913, 'node_id': 'MDQ6VXNlcjIyNzc3OTEz', 'avatar_url': 'https://avatars.githubusercontent.com/u/22777913?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/jere357', 'html_url': 'https://github.com/jere357', 'followers_url': 'https://api.github.com/users/jere357/followers', 'following_url': 'https://api.github.com/users/jere357/following{/other_user}', 'gists_url': 'https://api.github.com/users/jere357/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/jere357/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/jere357/subscriptions', 'organizations_url': 'https://api.github.com/users/jere357/orgs', 'repos_url': 'https://api.github.com/users/jere357/repos', 'events_url': 'https://api.github.com/users/jere357/events{/privacy}', 'received_events_url': 'https://api.github.com/users/jere357/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",[],open,False,,[],,7,2023-07-04T21:44:37Z,2024-09-16T14:56:38Z,,NONE,,"Hello, this PR containts 3 config files for much lighter yolov5 detection models

The smallest yolov5 model on the repo currently is yolov5n and it scores like 37 mAP on COCO. This makes the model look bad when it actually performs really well on real world tasks, The mAP is low because COCO is a very difficult dataset and has 80 classes, while in most real world situations you will usually have only several classes in yout dataset, my personal problem was ""roughly detecting shelves"" in a store and that dataset was solvable with only femto configuration. I think adding these couple of files here may encourage people to try lighter and faster models because the yolov5n is a deceptively good object detection model, benchmarking it on 80 classes is unrealistic for many real world uses of the yolov object detector :)

Feel free to open a discussion about this in the comments, 
maybe casually mention these configs somewhere in the docs


<!--
Thank you for submitting a YOLOv5 🚀 Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ✅ [Contributing Guide](https://docs.ultralytics.com/help/contributing) for more details.

Note that Copilot will summarize this PR below, do not modify the 'copilot:all' line.
-->

<!--
copilot:all
-->
### <samp>🤖 Generated by Copilot at f134a68</samp>

### Summary
:zap::rocket::bulb:

<!--
1.  :zap: for `yolov5femto.yaml`, because it is the smallest and fastest model and the lightning bolt emoji implies speed and efficiency.
2.  :rocket: for `yolov5micro.yaml`, because it is also a small and fast model and the rocket emoji implies power and performance.
3.  :bulb: for `yolov5pico.yaml`, because it is a small and fast model that can be used for edge applications and the light bulb emoji implies innovation and intelligence.
-->
This pull request adds three new YAML files that define very small and fast YOLOv5 models with different depth and width multipliers. These files are `yolov5femto.yaml`, `yolov5micro.yaml`, and `yolov5pico.yaml`. They are intended to offer more choices for users who need minimal models for resource-constrained applications.

> _`yolov5` models_
> _smaller and faster options_
> _autumn of deep learning_

### Walkthrough
*  Add three new YAML files for very small and fast YOLOv5 models: `yolov5femto.yaml`, `yolov5micro.yaml`, and `yolov5pico.yaml` ([link](https://github.com/ultralytics/yolov5/pull/11813/files?diff=unified&w=0#diff-ee8764cb29b35431172db16d7aaa87ff607971a7878f5489a1a6f39c662a8166R1-R48), [link](https://github.com/ultralytics/yolov5/pull/11813/files?diff=unified&w=0#diff-7a3231cafd6f3221302c96a8e892e1a53422c05b2b2b0d27e054efd1a1f5b57bR1-R48), [link](https://github.com/ultralytics/yolov5/pull/11813/files?diff=unified&w=0#diff-1558405a41f58c4c4ea500b7a7c16945859ce4479a366649f69d1799a40ed44eR1-R48))




## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 📊 Key Changes
- New YOLOv5 configurations named `yolov5femto.yaml`, `yolov5micro.yaml`, and `yolov5pico.yaml` have been added, each with varying `depth_multiple` and `width_multiple` values to create lighter models.

### 🎯 Purpose & Impact
- The addition of these lighter configurations is aimed at enabling the YOLOv5 object detection model to run on devices with limited computational resources, such as edge devices or systems with low processing power. This could greatly expand the applicability of the YOLOv5 model in real-world scenarios where computational efficiency is key.

### 🌟 Summary
New YOLOv5 configurations introduced for resource-constrained environments, enhancing the model's versatility for edge computing. 🚀",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/11813/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/11813/timeline,,,False,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/pulls/11813', 'html_url': 'https://github.com/ultralytics/yolov5/pull/11813', 'diff_url': 'https://github.com/ultralytics/yolov5/pull/11813.diff', 'patch_url': 'https://github.com/ultralytics/yolov5/pull/11813.patch', 'merged_at': None}"
https://api.github.com/repos/ultralytics/yolov5/issues/11485,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/11485/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/11485/comments,https://api.github.com/repos/ultralytics/yolov5/issues/11485/events,https://github.com/ultralytics/yolov5/issues/11485,1695801666,I_kwDOD8jP_s5lE-FC,11485,How to display real-time MP4 processing results,"{'login': 'hnulmz3', 'id': 103308249, 'node_id': 'U_kgDOBihb2Q', 'avatar_url': 'https://avatars.githubusercontent.com/u/103308249?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/hnulmz3', 'html_url': 'https://github.com/hnulmz3', 'followers_url': 'https://api.github.com/users/hnulmz3/followers', 'following_url': 'https://api.github.com/users/hnulmz3/following{/other_user}', 'gists_url': 'https://api.github.com/users/hnulmz3/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/hnulmz3/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/hnulmz3/subscriptions', 'organizations_url': 'https://api.github.com/users/hnulmz3/orgs', 'repos_url': 'https://api.github.com/users/hnulmz3/repos', 'events_url': 'https://api.github.com/users/hnulmz3/events{/privacy}', 'received_events_url': 'https://api.github.com/users/hnulmz3/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,46,2023-05-04T11:11:28Z,2024-10-20T19:09:26Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Using decect.py to test MP4 video has only one result output and an intermediate 'Video 1/1 (469/486).......... 640x384 (no detections), text display of 80.6ms', what should I do if I want to display the video in real time?

### Additional

Sorry, I'm a green hand",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/11485/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/11485/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/11120,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/11120/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/11120/comments,https://api.github.com/repos/ultralytics/yolov5/issues/11120/events,https://github.com/ultralytics/yolov5/issues/11120,1610317188,I_kwDOD8jP_s5f-32E,11120,How to increase mAP@0.5 and recall value ,"{'login': 'muttahirul', 'id': 121252824, 'node_id': 'U_kgDOBzor2A', 'avatar_url': 'https://avatars.githubusercontent.com/u/121252824?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/muttahirul', 'html_url': 'https://github.com/muttahirul', 'followers_url': 'https://api.github.com/users/muttahirul/followers', 'following_url': 'https://api.github.com/users/muttahirul/following{/other_user}', 'gists_url': 'https://api.github.com/users/muttahirul/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/muttahirul/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/muttahirul/subscriptions', 'organizations_url': 'https://api.github.com/users/muttahirul/orgs', 'repos_url': 'https://api.github.com/users/muttahirul/repos', 'events_url': 'https://api.github.com/users/muttahirul/events{/privacy}', 'received_events_url': 'https://api.github.com/users/muttahirul/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}]",open,False,,[],,50,2023-03-05T18:52:17Z,2024-10-20T19:00:36Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question
Hi @glenn-jocher ,
I trained a custom data using yolov5m pre-trained weight to detect weather a person is pedestrian or not. My data has two classes. I use minibatch size = 16 and epochs=100. These are the hyperparameter I used: 
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 0.05
cls: 0.5
cls_pw: 1.0
obj: 1.0
obj_pw: 1.0
iou_t: 0.2
anchor_t: 4.0
fl_gamma: 0.0
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
I have 2550 train image and 451 validation image. I also added 2% background image with no labels as per previous issues suggestions. 
I got only 0.508 mAP @0.5 and very low recall value. From result, I can also see the val/obj loss and val/class loss is increasing. 
Also from confusion matrix, I got 0% correctly predicted background which is very confusing me.
Could you give any suggestion or direction to increase mAP value,please?

![results](https://user-images.githubusercontent.com/121252824/222979321-665fb72a-235f-4b06-b82e-ab8a8c928cfc.png)
![train_batch1](https://user-images.githubusercontent.com/121252824/222979322-1caba020-167a-44b8-8ef7-3e8d24b26d05.jpg)
![confusion_matrix](https://user-images.githubusercontent.com/121252824/222979304-44c09c1c-0acf-4d77-a6e6-e23e94f0b542.png)
![F1_curve](https://user-images.githubusercontent.com/121252824/222979310-4395d877-1260-4f06-8120-58e08f9f4687.png)
![labels](https://user-images.githubusercontent.com/121252824/222979311-70e3b7d1-b1b4-49bd-931d-bffa5107d0b1.jpg)
![P_curve](https://user-images.githubusercontent.com/121252824/222979313-8880bf03-d92d-4306-96b4-88ffe0434e7f.png)
![PR_curve](https://user-images.githubusercontent.com/121252824/222979317-6956d156-97f3-4b29-9494-01ebaf31be5a.png)
![R_curve](https://user-images.githubusercontent.com/121252824/222979319-07f70bf3-47ad-4a5e-b03b-a6654a821bf6.png)




### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/11120/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/11120/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/11028,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/11028/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/11028/comments,https://api.github.com/repos/ultralytics/yolov5/issues/11028/events,https://github.com/ultralytics/yolov5/issues/11028,1591930761,I_kwDOD8jP_s5e4u-J,11028,"NEW Classification Datasets: `imagenet10`, `imagenet100`, `imagenet1000`","{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,7,2023-02-20T14:04:51Z,2023-09-18T09:56:52Z,,MEMBER,,"All, FYI I've created 3 new classification datasets for use with debugging/tests/benchmarks: `imagenet10`, `imagenet100`, `imagenet1000`.

These are super small versions of imagenet that train/val in seconds with only 1 image per class (with all 1000 classes, only 100 classes, and only 10 classes). They are reduced in size to `imgsz=160` and compressed with PIL so that i.e. imagenet10 is only 70kB, imagenet1000 is only 7MB.

### CI 

I've migrated our [YOLOv8](https://github.com/ultralytics/ultralytics) CI, tests and benchmarks to use them, i.e. benchmarks are now on imagenet100 (top5 accuracy is 0.71 for YOLOv8n-cls on imagenet100). 
https://github.com/ultralytics/ultralytics/actions/runs/4223103056/jobs/7332424420

<img width=""635"" alt=""Screenshot 2023-02-20 at 14 56 41"" src=""https://user-images.githubusercontent.com/26833433/220128254-cee45a94-83b5-41a5-9ade-6cc77681e3bc.png"">

### Download

You can download them here:
https://github.com/ultralytics/yolov5/releases/download/v1.0/imagenet10.zip
https://github.com/ultralytics/yolov5/releases/download/v1.0/imagenet100.zip
https://github.com/ultralytics/yolov5/releases/download/v1.0/imagenet1000.zip

### Usage

```bash
pip install ultralytics

yolo train model=yolov8n-cls.pt data=imagenet100
```
or
```python
from ultralytics import YOLO

model = YOLO('yolov8n-cls.pt')
results = model.train(data='imagenet100', imgsz=160)
```
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/11028/reactions', 'total_count': 1, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 1, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/11028/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/10926,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/10926/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/10926/comments,https://api.github.com/repos/ultralytics/yolov5/issues/10926/events,https://github.com/ultralytics/yolov5/issues/10926,1575711704,I_kwDOD8jP_s5d63PY,10926,NEW Ultralytics YOLOv8 🚀 is here!,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,1,2023-02-08T08:42:33Z,2023-03-26T15:36:09Z,,MEMBER,,"<div align=""center"">
  <p>
    <a href=""https://ultralytics.com/yolov8"" target=""_blank"">
      <img width=""100%"" src=""https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png""></a>
  </p>

[English](README.md) | [简体中文](README.zh-CN.md)
<br>

<div>
    <a href=""https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml""><img src=""https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml/badge.svg"" alt=""Ultralytics CI""></a>
    <a href=""https://zenodo.org/badge/latestdoi/264818686""><img src=""https://zenodo.org/badge/264818686.svg"" alt=""YOLOv8 Citation""></a>
    <a href=""https://hub.docker.com/r/ultralytics/ultralytics""><img src=""https://img.shields.io/docker/pulls/ultralytics/ultralytics?logo=docker"" alt=""Docker Pulls""></a>
    <br>
    <a href=""https://console.paperspace.com/github/ultralytics/ultralytics""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""/></a>
    <a href=""https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a>
    <a href=""https://www.kaggle.com/ultralytics/yolov8""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
  </div>
  <br>

[Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics), developed by [Ultralytics](https://ultralytics.com), is a cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility. YOLOv8 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection, image segmentation and image classification tasks.

To request an Enterprise License please complete the form at [Ultralytics Licensing](https://ultralytics.com/license).

<img width=""100%"" src=""https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/yolo-comparison-plots.png""></a>

<div align=""center"">
  <a href=""https://github.com/ultralytics"" style=""text-decoration:none;"">
    <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-social-github.png"" width=""2%"" alt="""" /></a>
  <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png"" width=""2%"" alt="""" />
  <a href=""https://www.linkedin.com/company/ultralytics"" style=""text-decoration:none;"">
    <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-social-linkedin.png"" width=""2%"" alt="""" /></a>
  <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png"" width=""2%"" alt="""" />
  <a href=""https://twitter.com/ultralytics"" style=""text-decoration:none;"">
    <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-social-twitter.png"" width=""2%"" alt="""" /></a>
  <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png"" width=""2%"" alt="""" />
  <a href=""https://youtube.com/ultralytics"" style=""text-decoration:none;"">
    <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-social-youtube.png"" width=""2%"" alt="""" /></a>
  <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png"" width=""2%"" alt="""" />
  <a href=""https://www.tiktok.com/@ultralytics"" style=""text-decoration:none;"">
    <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-social-tiktok.png"" width=""2%"" alt="""" /></a>
  <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png"" width=""2%"" alt="""" />
  <a href=""https://www.instagram.com/ultralytics/"" style=""text-decoration:none;"">
    <img src=""https://github.com/ultralytics/assets/raw/main/social/logo-social-instagram.png"" width=""2%"" alt="""" /></a>
</div>
</div>

## <div align=""center"">Documentation</div>

See below for a quickstart installation and usage example, and see the [YOLOv8 Docs](https://docs.ultralytics.com) for full documentation on training, validation, prediction and deployment.

<details open>
<summary>Install</summary>

Pip install the ultralytics package including all [requirements.txt](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) in a [**Python>=3.7**](https://www.python.org/) environment with [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/).

```bash
pip install ultralytics
```

</details>

<details open>
<summary>Usage</summary>

#### CLI

YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command:

```bash
yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'
```

`yolo` can be used for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See the YOLOv8
[CLI Docs](https://docs.ultralytics.com/usage/cli) for examples.

#### Python

YOLOv8 may also be used directly in a Python environment, and accepts the same [arguments](https://docs.ultralytics.com/usage/cfg/) as in the CLI example above:

```python
from ultralytics import YOLO

# Load a model
model = YOLO(""yolov8n.yaml"")  # build a new model from scratch
model = YOLO(""yolov8n.pt"")  # load a pretrained model (recommended for training)

# Use the model
model.train(data=""coco128.yaml"", epochs=3)  # train the model
metrics = model.val()  # evaluate model performance on the validation set
results = model(""https://ultralytics.com/images/bus.jpg"")  # predict on an image
success = model.export(format=""onnx"")  # export the model to ONNX format
```

[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models) download automatically from the latest Ultralytics [release](https://github.com/ultralytics/assets/releases). See YOLOv8 [Python Docs](https://docs.ultralytics.com/usage/python) for more examples.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/10926/reactions', 'total_count': 46, '+1': 9, '-1': 0, 'laugh': 7, 'hooray': 8, 'confused': 0, 'heart': 8, 'rocket': 7, 'eyes': 7}",https://api.github.com/repos/ultralytics/yolov5/issues/10926/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/10395,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/10395/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/10395/comments,https://api.github.com/repos/ultralytics/yolov5/issues/10395/events,https://github.com/ultralytics/yolov5/issues/10395,1474058646,I_kwDOD8jP_s5X3FmW,10395,YOLOv5 with PyTorch 2.0,"{'login': 'SkalskiP', 'id': 26109316, 'node_id': 'MDQ6VXNlcjI2MTA5MzE2', 'avatar_url': 'https://avatars.githubusercontent.com/u/26109316?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/SkalskiP', 'html_url': 'https://github.com/SkalskiP', 'followers_url': 'https://api.github.com/users/SkalskiP/followers', 'following_url': 'https://api.github.com/users/SkalskiP/following{/other_user}', 'gists_url': 'https://api.github.com/users/SkalskiP/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/SkalskiP/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/SkalskiP/subscriptions', 'organizations_url': 'https://api.github.com/users/SkalskiP/orgs', 'repos_url': 'https://api.github.com/users/SkalskiP/repos', 'events_url': 'https://api.github.com/users/SkalskiP/events{/privacy}', 'received_events_url': 'https://api.github.com/users/SkalskiP/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,17,2022-12-03T14:17:40Z,2024-10-20T18:44:39Z,,CONTRIBUTOR,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Did any of you tried to run YOLOv5 on PyTorch 2.0? Is it faster like they promised?

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/10395/reactions', 'total_count': 5, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 2, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 3}",https://api.github.com/repos/ultralytics/yolov5/issues/10395/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/10272,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/10272/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/10272/comments,https://api.github.com/repos/ultralytics/yolov5/issues/10272/events,https://github.com/ultralytics/yolov5/issues/10272,1462661681,I_kwDOD8jP_s5XLnIx,10272,>512 masks cv2 limitation on resize,"{'login': 'fanweiya', 'id': 11371707, 'node_id': 'MDQ6VXNlcjExMzcxNzA3', 'avatar_url': 'https://avatars.githubusercontent.com/u/11371707?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/fanweiya', 'html_url': 'https://github.com/fanweiya', 'followers_url': 'https://api.github.com/users/fanweiya/followers', 'following_url': 'https://api.github.com/users/fanweiya/following{/other_user}', 'gists_url': 'https://api.github.com/users/fanweiya/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/fanweiya/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/fanweiya/subscriptions', 'organizations_url': 'https://api.github.com/users/fanweiya/orgs', 'repos_url': 'https://api.github.com/users/fanweiya/repos', 'events_url': 'https://api.github.com/users/fanweiya/events{/privacy}', 'received_events_url': 'https://api.github.com/users/fanweiya/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,6,2022-11-24T02:27:04Z,2022-12-01T19:45:54Z,,NONE,,"https://github.com/ultralytics/yolov5/blob/7398d2d77cbac9f66259926d49c26bfa3c257a9b/utils/segment/general.py#L91

# System information (version):
         opencv-python == 4.1.0.25
# Detailed description:
         cv2 resize channel limited
         This bug is triggered when the number of masks exceeds 512, and the skimage resize function is recommended.  

#### refer to:https://github.com/opencv/opencv/issues/14770


",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/10272/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/10272/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/9877,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/9877/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/9877/comments,https://api.github.com/repos/ultralytics/yolov5/issues/9877/events,https://github.com/ultralytics/yolov5/issues/9877,1417066040,I_kwDOD8jP_s5UdrY4,9877,ClearML no auth training ValueError bug,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,3,2022-10-20T18:22:39Z,2024-10-20T18:32:13Z,,MEMBER,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Training

### Bug

@thepycoder ClearML raises ValueError when installed but not authenticated.

<img width=""788"" alt=""Screenshot 2022-10-20 at 20 23 40"" src=""https://user-images.githubusercontent.com/26833433/197028162-abc087a1-5ac6-4ee9-b92f-f992c08adb38.png"">

### Environment

Python 3.7
Ubuntu
Notebook

### Minimal Reproducible Example

```ipython
!git clone https://github.com/ultralytics/yolov5  # clone
%cd yolov5
%pip install -qr requirements.txt clearml # install

!python train.py
```

### Additional

Should probably handle as a console printout/warning, i.e. `ClearML: installed but not logged in. Please login to log training.`

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/9877/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/9877/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/9687,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/9687/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/9687/comments,https://api.github.com/repos/ultralytics/yolov5/issues/9687/events,https://github.com/ultralytics/yolov5/issues/9687,1395905778,I_kwDOD8jP_s5TM9Ty,9687,Cannot run parallel inference with DDP,"{'login': 'thomassajot', 'id': 15252203, 'node_id': 'MDQ6VXNlcjE1MjUyMjAz', 'avatar_url': 'https://avatars.githubusercontent.com/u/15252203?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/thomassajot', 'html_url': 'https://github.com/thomassajot', 'followers_url': 'https://api.github.com/users/thomassajot/followers', 'following_url': 'https://api.github.com/users/thomassajot/following{/other_user}', 'gists_url': 'https://api.github.com/users/thomassajot/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/thomassajot/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/thomassajot/subscriptions', 'organizations_url': 'https://api.github.com/users/thomassajot/orgs', 'repos_url': 'https://api.github.com/users/thomassajot/repos', 'events_url': 'https://api.github.com/users/thomassajot/events{/privacy}', 'received_events_url': 'https://api.github.com/users/thomassajot/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,13,2022-10-04T08:59:44Z,2023-11-14T17:44:19Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Validation, Detection

### Bug

I am trying to make predictions in parallel using multiple GPUs in order to speed up inference on large datasets. 
From what I gathered, the best way to go about it with Pytorch is to use `torch.nn.DataParallel`.
However, the model first gets created in `cuda:0` then is copied over to the desired gpus. This overloads `cuda:0` and if not (when the batch size is small) then the same model is present over multiple gpus. I then get the following exception: 
`RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.`

See full error: 

```
YOLOv5 🚀 v6.2-145-gf8b7463 Python-3.9.13 torch-1.12.1+cu102 CUDA:4 (NVIDIA GeForce RTX 2080 Ti, 11019MiB)

Fusing layers...
Model summary: 416 layers, 140038156 parameters, 0 gradients, 208.0 GFLOPs
Adding AutoShape...
Traceback (most recent call last):
  File ""/mnt/remote/data/users/thomasssajot/yolov5/notebooks/generate_classification_results.py"", line 152, in <module>
    main(device=2)
  File ""/mnt/remote/data/users/thomasssajot/yolov5/notebooks/generate_classification_results.py"", line 136, in main
    model = get_model(model_path).to(f'cuda:{device}')
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 927, in to
    return self._apply(convert)
  File ""/mnt/remote/data/users/thomasssajot/yolov5/models/common.py"", line 621, in _apply
    self = super()._apply(fn)
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 579, in _apply
    module._apply(fn)
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 579, in _apply
    module._apply(fn)
  File ""/mnt/remote/data/users/thomasssajot/yolov5/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 579, in _apply
    module._apply(fn)
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 579, in _apply
    module._apply(fn)
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 579, in _apply
    module._apply(fn)
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 602, in _apply
    param_applied = fn(param)
  File ""/home/thomassajot/miniconda3/envs/yolov5/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
```

### Environment

PyTorch version: 1.12.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 18.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~18.04) 9.4.0
Clang version: 13.0.1-++20220120110844+75e33f71c2da-1~exp1~20220120230854.66
CMake version: version 3.10.2
Libc version: glibc-2.27

### Minimal Reproducible Example
```python

import torch 
from torch.utils.data import DataLoader
from tqdm import tqdm

def get_model(path):
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s')
    model.eval()
    return model

def get_image_files():
    images= 'path/to/image.jpeg'
    return [image] * 64

def main():
    images = get_image_files()
    model = get_model()
    net = torch.nn.DataParallel(model, device_ids=[0, 1])

    loader = DataLoader(dataset=images[:64 * 4], batch_size=4, shuffle=False, num_workers=8) 

    with torch.no_grad():
        for batch in tqdm(loader, ncols=140, desc=f'Predictions'):
            res = net(batch, size=1280)


if __name__ == ""__main__"":
    main()
```

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/9687/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/9687/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/9627,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/9627/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/9627/comments,https://api.github.com/repos/ultralytics/yolov5/issues/9627/events,https://github.com/ultralytics/yolov5/issues/9627,1388800609,I_kwDOD8jP_s5Sx2ph,9627,"NVIDIA Jetson Nvidia Jetson Nano, Xavier NX, Orin Deployment tutorial","{'login': 'AyushExel', 'id': 15766192, 'node_id': 'MDQ6VXNlcjE1NzY2MTky', 'avatar_url': 'https://avatars.githubusercontent.com/u/15766192?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AyushExel', 'html_url': 'https://github.com/AyushExel', 'followers_url': 'https://api.github.com/users/AyushExel/followers', 'following_url': 'https://api.github.com/users/AyushExel/following{/other_user}', 'gists_url': 'https://api.github.com/users/AyushExel/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AyushExel/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AyushExel/subscriptions', 'organizations_url': 'https://api.github.com/users/AyushExel/orgs', 'repos_url': 'https://api.github.com/users/AyushExel/repos', 'events_url': 'https://api.github.com/users/AyushExel/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AyushExel/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'AyushExel', 'id': 15766192, 'node_id': 'MDQ6VXNlcjE1NzY2MTky', 'avatar_url': 'https://avatars.githubusercontent.com/u/15766192?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AyushExel', 'html_url': 'https://github.com/AyushExel', 'followers_url': 'https://api.github.com/users/AyushExel/followers', 'following_url': 'https://api.github.com/users/AyushExel/following{/other_user}', 'gists_url': 'https://api.github.com/users/AyushExel/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AyushExel/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AyushExel/subscriptions', 'organizations_url': 'https://api.github.com/users/AyushExel/orgs', 'repos_url': 'https://api.github.com/users/AyushExel/repos', 'events_url': 'https://api.github.com/users/AyushExel/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AyushExel/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'AyushExel', 'id': 15766192, 'node_id': 'MDQ6VXNlcjE1NzY2MTky', 'avatar_url': 'https://avatars.githubusercontent.com/u/15766192?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AyushExel', 'html_url': 'https://github.com/AyushExel', 'followers_url': 'https://api.github.com/users/AyushExel/followers', 'following_url': 'https://api.github.com/users/AyushExel/following{/other_user}', 'gists_url': 'https://api.github.com/users/AyushExel/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AyushExel/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AyushExel/subscriptions', 'organizations_url': 'https://api.github.com/users/AyushExel/orgs', 'repos_url': 'https://api.github.com/users/AyushExel/repos', 'events_url': 'https://api.github.com/users/AyushExel/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AyushExel/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,78,2022-09-28T06:25:43Z,2024-06-28T10:44:42Z,,CONTRIBUTOR,,"# Deploy on NVIDIA Jetson using TensorRT and DeepStream SDK

This guide explains how to deploy a trained model into NVIDIA Jetson Platform and perform inference using TensorRT and DeepStream SDK. Here we use TensorRT to maximize the inference performance on the Jetson platform. UPDATED 18 November 2022. 

## Hardware Verification

We have tested and verified this guide on the following Jetson devices

- [Seeed reComputer J1010 built with Jetson Nano module](https://www.seeedstudio.com/Jetson-10-1-A0-p-5336.html)
- [Seeed reComputer J2021 built with Jetson Xavier NX module](https://www.seeedstudio.com/reComputer-J2021-p-5438.html)

## Before You Start

Make sure you have properly installed **JetPack SDK** with all the **SDK Components** and **DeepStream SDK** on the Jetson device as this includes CUDA, TensorRT and DeepStream SDK which are needed for this guide.

JetPack SDK provides a full development environment for hardware-accelerated AI-at-the-edge development. All Jetson modules and developer kits are supported by JetPack SDK.

There are two major installation methods including,

1. SD Card Image Method
2. NVIDIA SDK Manager Method

You can find a very detailed installation guide from NVIDIA [official website](https://developer.nvidia.com/jetpack-sdk-461). Also you can find guides corresponding to the above-mentioned [reComputer J1010](https://wiki.seeedstudio.com/reComputer_J1010_J101_Flash_Jetpack) and [reComputer J2021](https://wiki.seeedstudio.com/reComputer_J2021_J202_Flash_Jetpack).


## Install Necessary Packages 

- **Step 1.** Access the terminal of Jetson device, install pip and upgrade it

```sh
sudo apt update
sudo apt install -y python3-pip
pip3 install --upgrade pip
```

- **Step 2.** Clone the following repo

```sh
git clone https://github.com/ultralytics/yolov5
```

- **Step 3.** Open **requirements.txt**

```sh
cd yolov5
vi requirements.txt
```

- **Step 5.** Edit the following lines. Here you need to press **i** first to enter editing mode. Press **ESC**, then type **:wq** to save and quit

```sh
# torch>=1.7.0
# torchvision>=0.8.1
```

**Note:** torch and torchvision are excluded for now because they will be installed later.

- **Step 6.** install the below dependency

```sh
sudo apt install -y libfreetype6-dev
```

- **Step 7.** Install the necessary packages

```sh
pip3 install -r requirements.txt
```

## Install PyTorch and Torchvision

We cannot install PyTorch and Torchvision from pip because they are not compatible to run on Jetson platform which is based on **ARM aarch64 architecture**. Therefore we need to manually install pre-built PyTorch pip wheel and compile/ install Torchvision from source.

Visit [this page](https://forums.developer.nvidia.com/t/pytorch-for-jetson) to access all the PyTorch and Torchvision links.

Here are some of the versions supported by JetPack 4.6 and above.

**PyTorch v1.10.0**

Supported by JetPack 4.4 (L4T R32.4.3) / JetPack 4.4.1 (L4T R32.4.4) / JetPack 4.5 (L4T R32.5.0) / JetPack 4.5.1 (L4T R32.5.1) / JetPack 4.6 (L4T R32.6.1) with Python 3.6

**file_name:** torch-1.10.0-cp36-cp36m-linux_aarch64.whl
**URL:** https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl

**PyTorch v1.12.0**

Supported by JetPack 5.0 (L4T R34.1.0) / JetPack 5.0.1 (L4T R34.1.1) / JetPack 5.0.2 (L4T R35.1.0) with Python 3.8 

**file_name:** torch-1.12.0a0+2c916ef.nv22.3-cp38-cp38-linux_aarch64.whl
**URL:** https://developer.download.nvidia.com/compute/redist/jp/v50/pytorch/torch-1.12.0a0+2c916ef.nv22.3-cp38-cp38-linux_aarch64.whl

- **Step 1.** Install torch according to your JetPack version in the following format

```sh
wget <URL> -O <file_name>
pip3 install <file_name>
```

For example, here we are running **JP4.6.1** and therefore we choose **PyTorch v1.10.0**

```sh
cd ~
sudo apt-get install -y libopenblas-base libopenmpi-dev
wget https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl -O torch-1.10.0-cp36-cp36m-linux_aarch64.whl
pip3 install torch-1.10.0-cp36-cp36m-linux_aarch64.whl
```

- **Step 2.** Install torchvision depending on the version of PyTorch that you have installed. For example, we chose **PyTorch v1.10.0**, which means, we need to choose **Torchvision v0.11.1**

```sh
sudo apt install -y libjpeg-dev zlib1g-dev
git clone --branch v0.11.1 https://github.com/pytorch/vision torchvision
cd torchvision
sudo python3 setup.py install 
```

Here a list of the corresponding torchvision version that you need to install according to the PyTorch version:

- PyTorch v1.10 - torchvision v0.11.1
- PyTorch v1.12 - torchvision v0.13.0

## DeepStream Configuration for YOLOv5

- **Step 1.** Clone the following repo

```sh
cd ~
git clone https://github.com/marcoslucianops/DeepStream-Yolo
```

- **Step 2.** Copy **gen_wts_yoloV5.py** from **DeepStream-Yolo/utils** into **yolov5** directory 

```sh
cp DeepStream-Yolo/utils/gen_wts_yoloV5.py yolov5
```

- **Step 3.** Inside the yolov5 repo, download **pt file** from YOLOv5 releases (example for YOLOv5s 6.1)

```sh
cd yolov5
wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt
```

- **Step 4.** Generate the **cfg** and **wts** files

```sh
python3 gen_wts_yoloV5.py -w yolov5s.pt
```

**Note**: To change the inference size (defaut: 640)

```sh
-s SIZE
--size SIZE
-s HEIGHT WIDTH
--size HEIGHT WIDTH

Example for 1280:

-s 1280
or
-s 1280 1280
```

- **Step 5.** Copy the generated **cfg** and **wts** files into the **DeepStream-Yolo** folder

```sh
cp yolov5s.cfg ~/DeepStream-Yolo
cp yolov5s.wts ~/DeepStream-Yolo
```

- **Step 6.** Open the **DeepStream-Yolo** folder and compile the library

```sh
cd ~/DeepStream-Yolo
CUDA_VER=11.4 make -C nvdsinfer_custom_impl_Yolo  # for DeepStream 6.1
CUDA_VER=10.2 make -C nvdsinfer_custom_impl_Yolo  # for DeepStream 6.0.1 / 6.0
```

- **Step 7.** Edit the **config_infer_primary_yoloV5.txt** file according to your model

```sh
[property]
...
custom-network-config=yolov5s.cfg
model-file=yolov5s.wts
...
```

- **Step 8.** Edit the **deepstream_app_config** file

```sh
...
[primary-gie]
...
config-file=config_infer_primary_yoloV5.txt
```

- **Step 9.** Change the video source in **deepstream_app_config** file. Here a default video file is loaded as you can see below

```sh
...
[source0]
...
uri=file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4
```

## Run the Inference

```sh
deepstream-app -c deepstream_app_config.txt
```

<div align=center><img width=1000 src=""https://files.seeedstudio.com/wiki/YOLOV5/FP32-yolov5s.gif""/></div>

The above result is running on **Jetson Xavier NX** with **FP32** and **YOLOv5s 640x640**. We can see that the **FPS** is around **30**.

## INT8 Calibration

If you want to use INT8 precision for inference, you need to follow the steps below 

- **Step 1.** Install OpenCV

```sh
sudo apt-get install libopencv-dev
```

- **Step 2.** Compile/recompile the **nvdsinfer_custom_impl_Yolo** library with OpenCV support

```sh
cd ~/DeepStream-Yolo
CUDA_VER=11.4 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo  # for DeepStream 6.1
CUDA_VER=10.2 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo  # for DeepStream 6.0.1 / 6.0
```

- **Step 3.** For COCO dataset, download the [val2017](https://drive.google.com/file/d/1gbvfn7mcsGDRZ_luJwtITL-ru2kK99aK/view?usp=sharing), extract, and move to **DeepStream-Yolo** folder

- **Step 4.** Make a new directory for calibration images

```sh
mkdir calibration
```

- **Step 5.** Run the following to select 1000 random images from COCO dataset to run calibration

```sh
for jpg in $(ls -1 val2017/*.jpg | sort -R | head -1000); do \
    cp ${jpg} calibration/; \
done
```

**Note:** NVIDIA recommends at least 500 images to get a good accuracy. On this example, 1000 images are chosen to get better accuracy (more images = more accuracy). Higher INT8_CALIB_BATCH_SIZE values will result in more accuracy and faster calibration speed. Set it according to you GPU memory. You can set it from **head -1000**. For example, for 2000 images, **head -2000**. This process can take a long time. 

- **Step 6.** Create the **calibration.txt** file with all selected images

```sh
realpath calibration/*jpg > calibration.txt
```

- **Step 7.** Set environment variables

```sh
export INT8_CALIB_IMG_PATH=calibration.txt
export INT8_CALIB_BATCH_SIZE=1
```

- **Step 8.** Update the **config_infer_primary_yoloV5.txt** file

From

```sh
...
model-engine-file=model_b1_gpu0_fp32.engine
#int8-calib-file=calib.table
...
network-mode=0
...
```

To

```sh
...
model-engine-file=model_b1_gpu0_int8.engine
int8-calib-file=calib.table
...
network-mode=1
...
```

- **Step 9.** Run the inference

```sh
deepstream-app -c deepstream_app_config.txt
```

<div align=center><img width=1000  src=""https://files.seeedstudio.com/wiki/YOLOV5/INT8-yolov5s.gif""/></div>

The above result is running on **Jetson Xavier NX** with **INT8** and **YOLOv5s 640x640**. We can see that the **FPS** is around **60**.

## Benchmark results

The following table summarizes how different models perform on **Jetson Xavier NX**. 

|Model Name | Precision |Inference Size |Inference Time (ms) | FPS |
|-------------|-----------|--------------|---------------------|-----|
|YOLOv5s     | FP32    |   320x320 |   16.66    | 60      |                    
|    | FP32    |   640x640 |   33.33    | 30     |                    
|    | INT8    |   640x640 |  16.66    | 60    |                    
| YOLOv5n  | FP32    |   640x640 |   16.66    | 60     |                    


### Additional

This tutorial is written by our friends at seeed @lakshanthad and Elaine
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/9627/reactions', 'total_count': 28, '+1': 19, '-1': 0, 'laugh': 1, 'hooray': 1, 'confused': 0, 'heart': 1, 'rocket': 3, 'eyes': 3}",https://api.github.com/repos/ultralytics/yolov5/issues/9627/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/9589,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/9589/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/9589/comments,https://api.github.com/repos/ultralytics/yolov5/issues/9589/events,https://github.com/ultralytics/yolov5/issues/9589,1385162747,I_kwDOD8jP_s5Sj-f7,9589,"Save your spot for #YOLOVISION22 on Tuesday, September 27th!","{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,2,2022-09-25T20:56:55Z,2022-10-11T13:44:12Z,,MEMBER,,"Hi everyone!

I'm [Glenn Jocher](https://www.linkedin.com/in/glenn-jocher/), author of [YOLOv5](https://github.com/ultralytics/yolov5) 🚀.

I'd like to invite you to attend the world's first-ever YOLO conference: [#YOLOVISION22](https://ultralytics.com/yolo-vision)!

This virtual event takes place on **September 27th, 2022** with talks from the world's leading vision AI experts from Google, SenseTime's MMLabs, Baidu's PaddlePaddle, Meituan's YOLOv6, Weight & Biases, Roboflow, Neural Magic, OctoML and of course Ultralytics YOLOv5 and many others.

Save your spot at https://ultralytics.com/yolo-vision

Thanks!

<a align=""center"" href=""https://ultralytics.com/yolo-vision"" target=""_blank"">
      <img width=""850"" src=""https://user-images.githubusercontent.com/26833433/192165285-a13a370c-60dc-4bf2-9d63-0573fb8e4d44.jpg""></a>",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/9589/reactions', 'total_count': 18, '+1': 3, '-1': 0, 'laugh': 3, 'hooray': 3, 'confused': 0, 'heart': 3, 'rocket': 3, 'eyes': 3}",https://api.github.com/repos/ultralytics/yolov5/issues/9589/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/8728,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/8728/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/8728/comments,https://api.github.com/repos/ultralytics/yolov5/issues/8728/events,https://github.com/ultralytics/yolov5/issues/8728,1318657055,I_kwDOD8jP_s5OmRwf,8728,Does YOLOV5 classification support the `resume training`,"{'login': 'AI-Passionner', 'id': 65562616, 'node_id': 'MDQ6VXNlcjY1NTYyNjE2', 'avatar_url': 'https://avatars.githubusercontent.com/u/65562616?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/AI-Passionner', 'html_url': 'https://github.com/AI-Passionner', 'followers_url': 'https://api.github.com/users/AI-Passionner/followers', 'following_url': 'https://api.github.com/users/AI-Passionner/following{/other_user}', 'gists_url': 'https://api.github.com/users/AI-Passionner/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/AI-Passionner/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/AI-Passionner/subscriptions', 'organizations_url': 'https://api.github.com/users/AI-Passionner/orgs', 'repos_url': 'https://api.github.com/users/AI-Passionner/repos', 'events_url': 'https://api.github.com/users/AI-Passionner/events{/privacy}', 'received_events_url': 'https://api.github.com/users/AI-Passionner/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,14,2022-07-26T19:19:51Z,2024-04-08T02:16:12Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

See above. 
Thanks. 

### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/8728/reactions', 'total_count': 1, '+1': 1, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/8728/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/8508,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/8508/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/8508/comments,https://api.github.com/repos/ultralytics/yolov5/issues/8508/events,https://github.com/ultralytics/yolov5/issues/8508,1297579324,I_kwDOD8jP_s5NV308,8508,The operator 'aten::nonzero' is not currently supported on the MPS backend,"{'login': 'abhimanyuchadha96', 'id': 37940438, 'node_id': 'MDQ6VXNlcjM3OTQwNDM4', 'avatar_url': 'https://avatars.githubusercontent.com/u/37940438?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/abhimanyuchadha96', 'html_url': 'https://github.com/abhimanyuchadha96', 'followers_url': 'https://api.github.com/users/abhimanyuchadha96/followers', 'following_url': 'https://api.github.com/users/abhimanyuchadha96/following{/other_user}', 'gists_url': 'https://api.github.com/users/abhimanyuchadha96/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/abhimanyuchadha96/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/abhimanyuchadha96/subscriptions', 'organizations_url': 'https://api.github.com/users/abhimanyuchadha96/orgs', 'repos_url': 'https://api.github.com/users/abhimanyuchadha96/repos', 'events_url': 'https://api.github.com/users/abhimanyuchadha96/events{/privacy}', 'received_events_url': 'https://api.github.com/users/abhimanyuchadha96/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758691, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njkx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/bug', 'name': 'bug', 'color': 'd73a4a', 'default': True, 'description': ""Something isn't working""}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,15,2022-07-07T14:49:21Z,2023-07-09T16:07:33Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar bug report.


### YOLOv5 Component

Detection

### Bug

![Screenshot 2022-07-07 at 10 49 06 AM](https://user-images.githubusercontent.com/37940438/177803216-ab927867-e27b-4ce6-ab02-0ce687ffff56.png)


### Environment

_No response_

### Minimal Reproducible Example

_No response_

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/8508/reactions', 'total_count': 2, '+1': 2, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/8508/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/8496,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/8496/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/8496/comments,https://api.github.com/repos/ultralytics/yolov5/issues/8496/events,https://github.com/ultralytics/yolov5/issues/8496,1295951711,I_kwDOD8jP_s5NPqdf,8496,Constant time with AutoShape,"{'login': 'marcimarc1', 'id': 24301948, 'node_id': 'MDQ6VXNlcjI0MzAxOTQ4', 'avatar_url': 'https://avatars.githubusercontent.com/u/24301948?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/marcimarc1', 'html_url': 'https://github.com/marcimarc1', 'followers_url': 'https://api.github.com/users/marcimarc1/followers', 'following_url': 'https://api.github.com/users/marcimarc1/following{/other_user}', 'gists_url': 'https://api.github.com/users/marcimarc1/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/marcimarc1/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/marcimarc1/subscriptions', 'organizations_url': 'https://api.github.com/users/marcimarc1/orgs', 'repos_url': 'https://api.github.com/users/marcimarc1/repos', 'events_url': 'https://api.github.com/users/marcimarc1/events{/privacy}', 'received_events_url': 'https://api.github.com/users/marcimarc1/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,8,2022-07-06T14:45:46Z,2024-11-03T20:59:47Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hi, 

I wanted to process 4K Images with yolov5s and did some experiments regarding resolution and size. 

I realized I get the best result of my network with images of input size 640x640 and splitting the 4k images, respectively.

For inference, I now did some experiments and I am not even close to 30 FPS when processing with AutoShape. 

This is probably due to the preprossessing of AutoShape, yet I do not find a way around that (neither with multiprocessing/treading or anything I can currently think of). I am quite sure that the problem is in AutoShape and wanted to ask if you have any idea how to accelerate that.

My current experiments show that if you are passing a torch tensor through the network, inference time seems to be more constant.
 
`import torch 
import numpy
import time

model = torch.hub.load('ultralytics/yolov5', ""yolov5s"", classes = 10)
model.eval()

input_image = numpy.random.rand(3840, 2160,3)
def split_images(img):
    dh, dw, _ = img.shape
    image_splits =[]
    height, width = 640, 640
    for i in range(dh//height):
        for j in range(dw//width):
            image_splits.append( (j*width, i*height, (j+1)*width, (i+1)*height))
    return image_splits

splits = split_images(input_image)
warmup = model([input_image])
t = time.time()
model([input_image])
print(f""Time for completing Single Frame: {time.time()-t}"")
cropped = []
for i in splits: 
    cropped.append(input_image[i[1]:i[3],i[0]:i[2]])

t = time.time()
model(cropped)
print(f""Time for completing 18 Cropped Frames: {time.time()-t}"")

inp = torch.rand(18,3,640,640) 
t = time.time()
model(inp)
print(f""Time for completing 18 Torch Frames: {time.time()-t}"")`
_Result:
...
Adding AutoShape...
Time for completing Single Frame: 1.4259703159332275
Time for completing 18 Cropped Frames: 0.5461986064910889
Time for completing 18 Torch Frames: 0.027060985565185547_


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/8496/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/8496/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/8480,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/8480/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/8480/comments,https://api.github.com/repos/ultralytics/yolov5/issues/8480/events,https://github.com/ultralytics/yolov5/issues/8480,1294284432,I_kwDOD8jP_s5NJTaQ,8480,Which version of TensorRT is usable for converting yolov5 model to tensorrt model and running it on docker container?,"{'login': 'mcagricaliskan', 'id': 18111855, 'node_id': 'MDQ6VXNlcjE4MTExODU1', 'avatar_url': 'https://avatars.githubusercontent.com/u/18111855?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mcagricaliskan', 'html_url': 'https://github.com/mcagricaliskan', 'followers_url': 'https://api.github.com/users/mcagricaliskan/followers', 'following_url': 'https://api.github.com/users/mcagricaliskan/following{/other_user}', 'gists_url': 'https://api.github.com/users/mcagricaliskan/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mcagricaliskan/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mcagricaliskan/subscriptions', 'organizations_url': 'https://api.github.com/users/mcagricaliskan/orgs', 'repos_url': 'https://api.github.com/users/mcagricaliskan/repos', 'events_url': 'https://api.github.com/users/mcagricaliskan/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mcagricaliskan/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,18,2022-07-05T13:12:49Z,2024-10-20T17:58:21Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

Hello Everyone,

These days i am trying to run Yolov5 with TensorRT on Docker. 

I didn't install TensorRT to my ubuntu because i want to run yolov5 on docker. I tried to use nvcr.io/nvidia/pytorch:22.06-py3 and ultralytics/yolov5 base images. I succesfly runned yolov5m on docker container. but i need more performance because i want to run huge number of video feed with yolov5 for these reason i decied trying to reach TensorRT yolov5 speed.

My graphic card is: RTX 3060

**My Question:**
Which TensorRT version is correct for converting yolov5 model to tensorrt model and running it on docker container?

**Why am i asking these:**
For using tensorRT i tryed to convert yolo model to tensorRt model. I used standart scripts from THIS COLAB codes on my docker container. When i tried I got same error everytime which is:
```
[07/05/2022-12:43:40] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[07/05/2022-12:43:40] [TRT] [E] parsers/onnx/ModelImporter.cpp:791: While parsing node number 203 [Resize -> ""onnx::Concat_370""]:
[07/05/2022-12:43:40] [TRT] [E] parsers/onnx/ModelImporter.cpp:792: --- Begin node ---
[07/05/2022-12:43:40] [TRT] [E] parsers/onnx/ModelImporter.cpp:793: input: ""onnx::Resize_365""
input: """"
input: ""onnx::Resize_607""
output: ""onnx::Concat_370""
name: ""Resize_203""
op_type: ""Resize""
attribute {
  name: ""coordinate_transformation_mode""
  s: ""asymmetric""
  type: STRING
}
attribute {
  name: ""cubic_coeff_a""
  f: -0.75
  type: FLOAT
}
attribute {
  name: ""mode""
  s: ""nearest""
  type: STRING
}
attribute {
  name: ""nearest_mode""
  s: ""floor""
  type: STRING
}

[07/05/2022-12:43:40] [TRT] [E] parsers/onnx/ModelImporter.cpp:794: --- End node ---
[07/05/2022-12:43:40] [TRT] [E] parsers/onnx/ModelImporter.cpp:796: ERROR: parsers/onnx/builtin_op_importers.cpp:3526 In function importResize:
[8] Assertion failed: scales.is_weights() && ""Resize scales must be an initializer!""

TensorRT: export failure: failed to load ONNX file: yolov5m.onnx
```

TensortRT version of container:  TensorRT 8.2.5.1...

used this commands
```

python export.py --weights yolov5m.pt --include onnx
python export.py --weights yolov5m.pt --include engine --imgsz 640 640 --device 0
```


After my research i tried to run this same commands on google colab. I used[ YOLOv5 Tutorial](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb#scrollTo=VTRwsvA9u7ln&line=2&uniqifier=1) and it worked and i got a yolov5m.engine file

TensortRT version on Colab: TensorRT 8.4.1.5...

I thought I had succeeded. And I got the following result from here, the reason why I can't translate is related to the tensorrt version. Please correct me if I am wrong.

But when i tried to run yolov5m.engine model on yolov5 container i get some error about engine version:
NVIDIA GeForce RTX 3060
```
YOLOv5 🚀 v6.1-277-gfdc9d91 Python-3.8.13 torch-1.13.0a0+340c412 CUDA:0 (NVIDIA GeForce RTX 3060, 12046MiB)

Loading model/yolov5m.engine for TensorRT inference...

[07/05/2022-12:55:51] [TRT] [I] [MemUsageChange] Init CUDA: CPU +472, GPU +0, now: CPU 568, GPU 784 (MiB)
[07/05/2022-12:55:51] [TRT] [I] Loaded engine size: 84 MiB
[07/05/2022-12:55:51] [TRT] [E] 1: [stdArchiveReader.cpp::StdArchiveReader::40] Error Code 1: Serialization (Serialization assertion stdVersionRead == serializationVersion failed.Version tag does not match. Note: Current Version: 205, Serialized Engine Version: 213)
[07/05/2022-12:55:51] [TRT] [E] 4: [runtime.cpp::deserializeCudaEngine::50] Error Code 4: Internal Error (Engine deserialization failed.)
Rise Model Excetion: 'NoneType' object has no attribute 'num_bindings'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
```

The result I have deduced from here is that I cannot run the yolov5.engine model with a lower version, since I perform the translation operations with a higher tensorRT version. Please correct me if I am wrong.

For now nvcr.io/nvidia/pytorch:XX.XX-py3 and ultralytics/yolov5 images dosen't have tensorrt version which higher than 8.2.5.1. 
So for these reasons i thought i need to find correct vesion for converting and deploying. or any other way to run tensorrt. Please correct me if I am wrong.



### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/8480/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/8480/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/7520,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/7520/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/7520/comments,https://api.github.com/repos/ultralytics/yolov5/issues/7520/events,https://github.com/ultralytics/yolov5/issues/7520,1211018974,I_kwDOD8jP_s5ILq7e,7520,Do Upsample with ConvTranspose2d,"{'login': 'Forever518', 'id': 57933485, 'node_id': 'MDQ6VXNlcjU3OTMzNDg1', 'avatar_url': 'https://avatars.githubusercontent.com/u/57933485?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Forever518', 'html_url': 'https://github.com/Forever518', 'followers_url': 'https://api.github.com/users/Forever518/followers', 'following_url': 'https://api.github.com/users/Forever518/following{/other_user}', 'gists_url': 'https://api.github.com/users/Forever518/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Forever518/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Forever518/subscriptions', 'organizations_url': 'https://api.github.com/users/Forever518/orgs', 'repos_url': 'https://api.github.com/users/Forever518/repos', 'events_url': 'https://api.github.com/users/Forever518/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Forever518/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, {'login': 'Forever518', 'id': 57933485, 'node_id': 'MDQ6VXNlcjU3OTMzNDg1', 'avatar_url': 'https://avatars.githubusercontent.com/u/57933485?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Forever518', 'html_url': 'https://github.com/Forever518', 'followers_url': 'https://api.github.com/users/Forever518/followers', 'following_url': 'https://api.github.com/users/Forever518/following{/other_user}', 'gists_url': 'https://api.github.com/users/Forever518/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Forever518/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Forever518/subscriptions', 'organizations_url': 'https://api.github.com/users/Forever518/orgs', 'repos_url': 'https://api.github.com/users/Forever518/repos', 'events_url': 'https://api.github.com/users/Forever518/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Forever518/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,22,2022-04-21T13:08:46Z,2024-10-20T17:33:54Z,,CONTRIBUTOR,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

The origin `nn.Upsample` layer may not be supported on some edge devices like Hi3559A.

I have trained YOLOv5s with `nn.ConvTranspose2d` which is compatible with Caffe 1.0 and Hi3559A's NNIE (#5397). The training process depends on 4xV100 GPU and I used the same config as the repo's pretrained checkpoints to validate the models.
```bash
# train
python -m torch.distributed.run --nproc_per_node 4 train.py --device 0,1,2,3 --data data/coco.yaml --hyp data/hyps/hyp.scratch-low.yaml  --cfg path/to/model.yaml --batch 512 --epochs 300 --weights ''
# val
python val.py --verbose --data data/coco.yaml --conf 0.001 --iou 0.65 --batch 1 --weights path/to/model.pt
```

Here is the val result on COCO val2017 dataset. It seems that with larger deconv kernel, the model reaches better performance. I only compare kernel size 2x2 and 4x4 while the model with **4x4 deconv kernel** got the best performance.

| Model          | deconv<br />kernel size | size<br />(pixels) | mAP<br />@0.5:0.95 | mAP<br />@0.5 | Speed V100 <br />b1(ms) | Speed V100 <br />b32(ms) | params<br />(M) | FLOPs<br />@640(B) |
| -------------- | ----------------------- | ------------------ | ------------------ | ------------- | ----------------------- | ------------------------ | --------------- | ------------------ |
| YOLOv5s        | -                       | 640                | 33.7               | 52.9          | **5.6**                 | **2.2**                  | **7.23**        | **16.5**           |
| YOLOv5s-deconv | 2                       | 640                | 33.4               | 52.5          | **5.6**                 | 2.4                      | 7.55            | 18.2               |
| YOLOv5s-deconv | 4                       | 640                | **34.7**           | **54.2**      | 5.8                     | 2.5                      | 8.54            | 23.2               |

I hope you can test it under your environment for fair comparison and if it works, it couldn't be better to add the `yolov5-deconv` to the model hub.

```yaml
# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']], # the origin nn.Upsample layer
   # [-1, 1, nn.ConvTranspose2d, [512, 2, 2]], # nn.ConvTransposed2d with 2x2 deconv kernel
   # [-1, 1, nn.ConvTranspose2d, [512, 4, 2, 1]], # nn.ConvTransposed2d with 4x4 deconv kernel
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']], # the origin nn.Upsample layer
   # [-1, 1, nn.ConvTranspose2d, [256, 2, 2]], # nn.ConvTransposed2d with 2x2 deconv kernel
   # [-1, 1, nn.ConvTranspose2d, [256, 4, 2, 1]], # nn.ConvTransposed2d with 4x4 deconv kernel
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
```

```python
# the parse_model of yolo.py should be changed from
# if m in [Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, MixConv2d, Focus, CrossConv,
#         BottleneckCSP, C3, C3TR, C3SPP, C3Ghost]:
# to
if m in [Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, MixConv2d, Focus, CrossConv,
         BottleneckCSP, C3, C3TR, C3SPP, C3Ghost, nn.ConvTranspose2d]:
```

### Use case

The `yolov5-deconv` is compatible with Caffe 1.0 and the NNIE of Hi3559A, making it easier to deploy the model on some edge devices.

### Additional

I have not test the `nn.ConvTranspose2d` under larger model like `yolov5l`. To get better performance, the deconv kernel size may be **even larger in large models** since there are more features during large model's forward process.

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/7520/reactions', 'total_count': 1, '+1': 1, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/7520/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/7220,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/7220/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/7220/comments,https://api.github.com/repos/ultralytics/yolov5/issues/7220/events,https://github.com/ultralytics/yolov5/issues/7220,1187594846,I_kwDOD8jP_s5GyUJe,7220,Sort images with low mAP score,"{'login': 'JISHNUSHAJI', 'id': 22237284, 'node_id': 'MDQ6VXNlcjIyMjM3Mjg0', 'avatar_url': 'https://avatars.githubusercontent.com/u/22237284?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/JISHNUSHAJI', 'html_url': 'https://github.com/JISHNUSHAJI', 'followers_url': 'https://api.github.com/users/JISHNUSHAJI/followers', 'following_url': 'https://api.github.com/users/JISHNUSHAJI/following{/other_user}', 'gists_url': 'https://api.github.com/users/JISHNUSHAJI/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/JISHNUSHAJI/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/JISHNUSHAJI/subscriptions', 'organizations_url': 'https://api.github.com/users/JISHNUSHAJI/orgs', 'repos_url': 'https://api.github.com/users/JISHNUSHAJI/repos', 'events_url': 'https://api.github.com/users/JISHNUSHAJI/events{/privacy}', 'received_events_url': 'https://api.github.com/users/JISHNUSHAJI/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,2,2022-03-31T06:45:07Z,2024-10-20T17:26:12Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

@glenn-jocher  Is it possible to see mAP on a per image basis , sort images by mAP and view the poorest performing images?


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/7220/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/7220/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/6998,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/6998/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/6998/comments,https://api.github.com/repos/ultralytics/yolov5/issues/6998/events,https://github.com/ultralytics/yolov5/issues/6998,1170533269,I_kwDOD8jP_s5FxOuV,6998,YOLOv5 (6.0/6.1) brief summary,"{'login': 'WZMIAOMIAO', 'id': 31005897, 'node_id': 'MDQ6VXNlcjMxMDA1ODk3', 'avatar_url': 'https://avatars.githubusercontent.com/u/31005897?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/WZMIAOMIAO', 'html_url': 'https://github.com/WZMIAOMIAO', 'followers_url': 'https://api.github.com/users/WZMIAOMIAO/followers', 'following_url': 'https://api.github.com/users/WZMIAOMIAO/following{/other_user}', 'gists_url': 'https://api.github.com/users/WZMIAOMIAO/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/WZMIAOMIAO/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/WZMIAOMIAO/subscriptions', 'organizations_url': 'https://api.github.com/users/WZMIAOMIAO/orgs', 'repos_url': 'https://api.github.com/users/WZMIAOMIAO/repos', 'events_url': 'https://api.github.com/users/WZMIAOMIAO/events{/privacy}', 'received_events_url': 'https://api.github.com/users/WZMIAOMIAO/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}]",open,False,"{'login': 'WZMIAOMIAO', 'id': 31005897, 'node_id': 'MDQ6VXNlcjMxMDA1ODk3', 'avatar_url': 'https://avatars.githubusercontent.com/u/31005897?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/WZMIAOMIAO', 'html_url': 'https://github.com/WZMIAOMIAO', 'followers_url': 'https://api.github.com/users/WZMIAOMIAO/followers', 'following_url': 'https://api.github.com/users/WZMIAOMIAO/following{/other_user}', 'gists_url': 'https://api.github.com/users/WZMIAOMIAO/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/WZMIAOMIAO/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/WZMIAOMIAO/subscriptions', 'organizations_url': 'https://api.github.com/users/WZMIAOMIAO/orgs', 'repos_url': 'https://api.github.com/users/WZMIAOMIAO/repos', 'events_url': 'https://api.github.com/users/WZMIAOMIAO/events{/privacy}', 'received_events_url': 'https://api.github.com/users/WZMIAOMIAO/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'WZMIAOMIAO', 'id': 31005897, 'node_id': 'MDQ6VXNlcjMxMDA1ODk3', 'avatar_url': 'https://avatars.githubusercontent.com/u/31005897?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/WZMIAOMIAO', 'html_url': 'https://github.com/WZMIAOMIAO', 'followers_url': 'https://api.github.com/users/WZMIAOMIAO/followers', 'following_url': 'https://api.github.com/users/WZMIAOMIAO/following{/other_user}', 'gists_url': 'https://api.github.com/users/WZMIAOMIAO/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/WZMIAOMIAO/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/WZMIAOMIAO/subscriptions', 'organizations_url': 'https://api.github.com/users/WZMIAOMIAO/orgs', 'repos_url': 'https://api.github.com/users/WZMIAOMIAO/repos', 'events_url': 'https://api.github.com/users/WZMIAOMIAO/events{/privacy}', 'received_events_url': 'https://api.github.com/users/WZMIAOMIAO/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,65,2022-03-16T04:39:06Z,2024-12-05T21:48:27Z,,NONE,,"# Content

+ [1. Model Structure](#1)
+ [2. Data Augmentation](#2)
+ [3. Training Strategies](#3)
+ [4. Others](#4)
    - [4.1 Compute Losses](#41)
    - [4.2 Balance Losses](#42)
    - [4.2 Eliminate Grid Sensitivity](#43)
    - [4.3 Build Targets](#44)


<a name=""1""></a>
## 1. Model Structure
YOLOv5 (v6.0/6.1) consists of:
- **Backbone**: `New CSP-Darknet53`
- **Neck**: `SPPF`, `New CSP-PAN`
- **Head**: `YOLOv3 Head`

Model structure (`yolov5l.yaml`):

![yolov5](https://user-images.githubusercontent.com/31005897/172404576-c260dcf9-76bb-4bc8-b6a9-f2d987792583.png)


Some minor changes compared to previous versions:
1. Replace the `Focus` structure with `6x6 Conv2d`(more efficient, refer #4825)  
2. Replace the `SPP` structure with `SPPF`(more than double the speed)

<details>
<summary>test code</summary>

```python
import time
import torch
import torch.nn as nn


class SPP(nn.Module):
    def __init__(self):
        super().__init__()
        self.maxpool1 = nn.MaxPool2d(5, 1, padding=2)
        self.maxpool2 = nn.MaxPool2d(9, 1, padding=4)
        self.maxpool3 = nn.MaxPool2d(13, 1, padding=6)

    def forward(self, x):
        o1 = self.maxpool1(x)
        o2 = self.maxpool2(x)
        o3 = self.maxpool3(x)
        return torch.cat([x, o1, o2, o3], dim=1)


class SPPF(nn.Module):
    def __init__(self):
        super().__init__()
        self.maxpool = nn.MaxPool2d(5, 1, padding=2)

    def forward(self, x):
        o1 = self.maxpool(x)
        o2 = self.maxpool(o1)
        o3 = self.maxpool(o2)
        return torch.cat([x, o1, o2, o3], dim=1)


def main():
    input_tensor = torch.rand(8, 32, 16, 16)
    spp = SPP()
    sppf = SPPF()
    output1 = spp(input_tensor)
    output2 = sppf(input_tensor)

    print(torch.equal(output1, output2))

    t_start = time.time()
    for _ in range(100):
        spp(input_tensor)
    print(f""spp time: {time.time() - t_start}"")

    t_start = time.time()
    for _ in range(100):
        sppf(input_tensor)
    print(f""sppf time: {time.time() - t_start}"")


if __name__ == '__main__':
    main()
```

result:
```
True
spp time: 0.5373051166534424
sppf time: 0.20780706405639648
```

</details>



<a name=""2""></a>
## 2. Data Augmentation
- Mosaic
<img src=""https://user-images.githubusercontent.com/31005897/159109235-c7aad8f2-1d4f-41f9-8d5f-b2fde6f2885e.png#pic_center"" width=80%>

- Copy paste
<img src=""https://user-images.githubusercontent.com/31005897/159116277-91b45033-6bec-4f82-afc4-41138866628e.png#pic_center"" width=80%>

- Random affine(Rotation, Scale, Translation and Shear)
<img src=""https://user-images.githubusercontent.com/31005897/159109326-45cd5acb-14fa-43e7-9235-0f21b0021c7d.png#pic_center"" width=80%>

- MixUp
<img src=""https://user-images.githubusercontent.com/31005897/159109361-3b24333b-f481-478b-ae00-df7838f0b5cd.png#pic_center"" width=80%>

- Albumentations
- Augment HSV(Hue, Saturation, Value)
<img src=""https://user-images.githubusercontent.com/31005897/159109407-83d100ba-1aba-4f4b-aa03-4f048f815981.png#pic_center"" width=80%>

- Random horizontal flip
<img src=""https://user-images.githubusercontent.com/31005897/159109429-0d44619a-a76a-49eb-bfc0-6709860c043e.png#pic_center"" width=80%>



<a name=""3""></a>
## 3. Training Strategies
- Multi-scale training(0.5~1.5x)
- AutoAnchor(For training custom data)
- Warmup and Cosine LR scheduler
- EMA(Exponential Moving Average)
- Mixed precision
- Evolve hyper-parameters



<a name=""4""></a>
## 4. Others
<a name=""41""></a>
### 4.1 Compute Losses
The YOLOv5 loss consists of three parts: 
- Classes loss(BCE loss)
- Objectness loss(BCE loss)
- Location loss(CIoU loss)

![loss](https://latex.codecogs.com/svg.image?Loss=\lambda_1L_{cls}+\lambda_2L_{obj}+\lambda_3L_{loc})

<a name=""42""></a>
### 4.2 Balance Losses
The objectness losses of the three prediction layers(`P3`, `P4`, `P5`) are weighted differently. The balance weights are `[4.0, 1.0, 0.4]` respectively.

![obj_loss](https://latex.codecogs.com/svg.image?L_{obj}=4.0\cdot&space;L_{obj}^{small}+1.0\cdot&space;L_{obj}^{medium}+0.4\cdot&space;L_{obj}^{large})

<a name=""43""></a>
### 4.3 Eliminate Grid Sensitivity
In YOLOv2 and YOLOv3, the formula for calculating the predicted target information is:  

![b_x](https://latex.codecogs.com/svg.image?b_x=\sigma(t_x)+c_x)  
![b_y](https://latex.codecogs.com/svg.image?b_y=\sigma(t_y)+c_y)  
![b_w](https://latex.codecogs.com/svg.image?b_w=p_w\cdot&space;e^{t_w})  
![b_h](https://latex.codecogs.com/svg.image?b_h=p_h\cdot&space;e^{t_h})

<img src=""https://user-images.githubusercontent.com/31005897/158508027-8bf63c28-8290-467b-8a3e-4ad09235001a.png#pic_center"" width=40%>



In YOLOv5, the formula is:  

![bx](https://latex.codecogs.com/svg.image?b_x=(2\cdot\sigma(t_x)-0.5)+c_x)  
![by](https://latex.codecogs.com/svg.image?b_y=(2\cdot\sigma(t_y)-0.5)+c_y)  
![bw](https://latex.codecogs.com/svg.image?b_w=p_w\cdot(2\cdot\sigma(t_w))^2)    
![bh](https://latex.codecogs.com/svg.image?b_h=p_h\cdot(2\cdot\sigma(t_h))^2)  

Compare the center point offset before and after scaling. The center point offset range is adjusted from (0, 1) to (-0.5, 1.5).
Therefore, offset can easily get 0 or 1.

<img src=""https://user-images.githubusercontent.com/31005897/158508052-c24bc5e8-05c1-4154-ac97-2e1ec71f582e.png#pic_center"" width=40%>

Compare the height and width scaling ratio(relative to anchor) before and after adjustment. The original yolo/darknet box equations have a serious flaw. Width and Height are completely unbounded as they are simply out=exp(in), which is dangerous, as it can lead to runaway gradients, instabilities, NaN losses and ultimately a complete loss of training. [refer this issue](https://github.com/ultralytics/yolov5/issues/471#issuecomment-662009779)

<img src=""https://user-images.githubusercontent.com/31005897/158508089-5ac0c7a3-6358-44b7-863e-a6e45babb842.png#pic_center"" width=40%>


<a name=""44""></a>
### 4.4 Build Targets
Match positive samples:
- Calculate the aspect ratio of GT and Anchor Templates

![rw](https://latex.codecogs.com/svg.image?r_w=w_{gt}/w_{at})

![rh](https://latex.codecogs.com/svg.image?r_h=h_{gt}/h_{at})

![rwmax](https://latex.codecogs.com/svg.image?r_w^{max}=max(r_w,1/r_w))

![rhmax](https://latex.codecogs.com/svg.image?r_h^{max}=max(r_h,1/r_h))

![rmax](https://latex.codecogs.com/svg.image?r^{max}=max(r_w^{max},r_h^{max}))

![match](https://latex.codecogs.com/svg.image?r^{max}<{\rm&space;anchor_t})

<img src=""https://user-images.githubusercontent.com/31005897/158508119-fbb2e483-7b8c-4975-8e1f-f510d367f8ff.png#pic_center"" width=70%>

- Assign the successfully matched Anchor Templates to the corresponding cells
<img src=""https://user-images.githubusercontent.com/31005897/158508771-b6e7cab4-8de6-47f9-9abf-cdf14c275dfe.png#pic_center"" width=70%>

- Because the center point offset range is adjusted from (0, 1) to (-0.5, 1.5). GT Box can be assigned to more anchors.
<img src=""https://user-images.githubusercontent.com/31005897/158508139-9db4e8c2-cf96-47e0-bc80-35d11512f296.png#pic_center"" width=70%>

## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/6998/reactions', 'total_count': 193, '+1': 109, '-1': 0, 'laugh': 13, 'hooray': 18, 'confused': 0, 'heart': 28, 'rocket': 17, 'eyes': 8}",https://api.github.com/repos/ultralytics/yolov5/issues/6998/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/6502,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/6502/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/6502/comments,https://api.github.com/repos/ultralytics/yolov5/issues/6502/events,https://github.com/ultralytics/yolov5/issues/6502,1121621977,I_kwDOD8jP_s5C2pfZ,6502,YOLOv5 container on AWS Marketplace,"{'login': 'g0lemXIV', 'id': 20084105, 'node_id': 'MDQ6VXNlcjIwMDg0MTA1', 'avatar_url': 'https://avatars.githubusercontent.com/u/20084105?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/g0lemXIV', 'html_url': 'https://github.com/g0lemXIV', 'followers_url': 'https://api.github.com/users/g0lemXIV/followers', 'following_url': 'https://api.github.com/users/g0lemXIV/following{/other_user}', 'gists_url': 'https://api.github.com/users/g0lemXIV/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/g0lemXIV/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/g0lemXIV/subscriptions', 'organizations_url': 'https://api.github.com/users/g0lemXIV/orgs', 'repos_url': 'https://api.github.com/users/g0lemXIV/repos', 'events_url': 'https://api.github.com/users/g0lemXIV/events{/privacy}', 'received_events_url': 'https://api.github.com/users/g0lemXIV/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,"{'login': 'g0lemXIV', 'id': 20084105, 'node_id': 'MDQ6VXNlcjIwMDg0MTA1', 'avatar_url': 'https://avatars.githubusercontent.com/u/20084105?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/g0lemXIV', 'html_url': 'https://github.com/g0lemXIV', 'followers_url': 'https://api.github.com/users/g0lemXIV/followers', 'following_url': 'https://api.github.com/users/g0lemXIV/following{/other_user}', 'gists_url': 'https://api.github.com/users/g0lemXIV/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/g0lemXIV/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/g0lemXIV/subscriptions', 'organizations_url': 'https://api.github.com/users/g0lemXIV/orgs', 'repos_url': 'https://api.github.com/users/g0lemXIV/repos', 'events_url': 'https://api.github.com/users/g0lemXIV/events{/privacy}', 'received_events_url': 'https://api.github.com/users/g0lemXIV/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'g0lemXIV', 'id': 20084105, 'node_id': 'MDQ6VXNlcjIwMDg0MTA1', 'avatar_url': 'https://avatars.githubusercontent.com/u/20084105?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/g0lemXIV', 'html_url': 'https://github.com/g0lemXIV', 'followers_url': 'https://api.github.com/users/g0lemXIV/followers', 'following_url': 'https://api.github.com/users/g0lemXIV/following{/other_user}', 'gists_url': 'https://api.github.com/users/g0lemXIV/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/g0lemXIV/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/g0lemXIV/subscriptions', 'organizations_url': 'https://api.github.com/users/g0lemXIV/orgs', 'repos_url': 'https://api.github.com/users/g0lemXIV/repos', 'events_url': 'https://api.github.com/users/g0lemXIV/events{/privacy}', 'received_events_url': 'https://api.github.com/users/g0lemXIV/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, {'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,24,2022-02-02T08:07:28Z,2024-10-20T17:08:55Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

I want to write an article about SageMaker model training especially Object Detection models. The choice fell on yolov5 because you've done fantastic work! Is it possible to make this a feature for the repository? 

I can make a complete pipeline for training the yolov5 model and deploying it as an endpoint/batch transform as containers available on AWS Marketplace.

### Use case

**Training:**
A user wants to train the yolov5 model on AWS Sagemaker but doesn't have experience. Users can ""fork"" ready-to-use containers from the marketplace and use them for training.

**Deploying:**
A user can use the yolov5 container to deploy a custom or pretrained model with a few clicks.


### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/6502/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/6502/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/6441,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/6441/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/6441/comments,https://api.github.com/repos/ultralytics/yolov5/issues/6441/events,https://github.com/ultralytics/yolov5/issues/6441,1115307219,I_kwDOD8jP_s5CejzT,6441,Add hash and security warning to autodownload scripts in custom yamls,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,0,2022-01-26T17:42:13Z,2022-01-26T17:42:14Z,,MEMBER,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

Add hash and security warning to autodownload scripts in custom yamls

### Use case

Custom yamls with autodownload keys populated

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/6441/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/6441/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/6382,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/6382/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/6382/comments,https://api.github.com/repos/ultralytics/yolov5/issues/6382/events,https://github.com/ultralytics/yolov5/issues/6382,1110497434,I_kwDOD8jP_s5CMNia,6382,How to get simple inference result as txt,"{'login': 'halzhen', 'id': 61091943, 'node_id': 'MDQ6VXNlcjYxMDkxOTQz', 'avatar_url': 'https://avatars.githubusercontent.com/u/61091943?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/halzhen', 'html_url': 'https://github.com/halzhen', 'followers_url': 'https://api.github.com/users/halzhen/followers', 'following_url': 'https://api.github.com/users/halzhen/following{/other_user}', 'gists_url': 'https://api.github.com/users/halzhen/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/halzhen/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/halzhen/subscriptions', 'organizations_url': 'https://api.github.com/users/halzhen/orgs', 'repos_url': 'https://api.github.com/users/halzhen/repos', 'events_url': 'https://api.github.com/users/halzhen/events{/privacy}', 'received_events_url': 'https://api.github.com/users/halzhen/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758698, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk4', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/question', 'name': 'question', 'color': 'd876e3', 'default': True, 'description': 'Further information is requested'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,6,2022-01-21T13:55:47Z,2024-10-20T17:06:01Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.


### Question

I am trying to inference on a batch of images in a directory. The basic inference code is the one used , I have already read the documentation for the Detections return, is there any way to get the detected objects as .txt ? In a similar way to result.print() , it shows the objects and the times they appear.

I am aware that detect.py can save as .txt but couldn't do inference on batch of images with it.

```# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

# Images
directory = 'keyframes/'

frames = [] # batch of images
for filename in os.listdir(directory):
    frame = Image.open('keyframes/'+filename)
    frames.append(frame)

# Inference
results = model(frames, size=640) 

# Results
results.print()
results.save()  ```

What I need is the objects detected in a .txt file without using detect.py, but if detect.py can be modified to work on batch of images from a directory that would also work. 


### Additional

_No response_",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/6382/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/6382/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/6006,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/6006/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/6006/comments,https://api.github.com/repos/ultralytics/yolov5/issues/6006/events,https://github.com/ultralytics/yolov5/issues/6006,1082031318,I_kwDOD8jP_s5AfnzW,6006,Attention imporved yolov5 performance,"{'login': '315386775', 'id': 12441747, 'node_id': 'MDQ6VXNlcjEyNDQxNzQ3', 'avatar_url': 'https://avatars.githubusercontent.com/u/12441747?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/315386775', 'html_url': 'https://github.com/315386775', 'followers_url': 'https://api.github.com/users/315386775/followers', 'following_url': 'https://api.github.com/users/315386775/following{/other_user}', 'gists_url': 'https://api.github.com/users/315386775/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/315386775/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/315386775/subscriptions', 'organizations_url': 'https://api.github.com/users/315386775/orgs', 'repos_url': 'https://api.github.com/users/315386775/repos', 'events_url': 'https://api.github.com/users/315386775/events{/privacy}', 'received_events_url': 'https://api.github.com/users/315386775/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2133190441, 'node_id': 'MDU6TGFiZWwyMTMzMTkwNDQx', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/TODO', 'name': 'TODO', 'color': 'fbca04', 'default': False, 'description': 'High priority items'}]",open,False,,[],,26,2021-12-16T10:38:30Z,2024-10-20T16:56:43Z,,NONE,,"### Search before asking

- [X] I have searched the YOLOv5 [issues](https://github.com/ultralytics/yolov5/issues) and found no similar feature requests.


### Description

Hi,
I really appreciate this great work for the cv community. Attention mechanism module can improve the performance of the model. Similar to the C3Ghost and C3SPP module. I have tested the C3-attention module with GCNet, named C3_GC module.
With C3_GC module achieves 36.12% map (ori map 35.35) with yolov5s. GFLOPs from 17,1 to 17.3. and Parameter from 7.3M to 7.6M
Paper :  <GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond>

`class C3_GC(nn.Module):
    # C3 module with ContextBlock2d()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(C3_GC, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.gc = ContextBlock2d(c1)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])

    def forward(self, x):
        out = torch.cat((self.m(self.cv1(x)), self.cv2(self.gc(x))), dim=1)
        out = self.cv3(out)
        return out`


### Use case

You need modify the yolov5s.yaml

`backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3_GC, [256, True]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3_GC, [512, True]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, C3_GC, [1024, False]],  # 9
  ]`

### Additional

_No response_

### Are you willing to submit a PR?

- [X] Yes I'd like to help by submitting a PR!",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/6006/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/6006/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/4975,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/4975/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/4975/comments,https://api.github.com/repos/ultralytics/yolov5/issues/4975/events,https://github.com/ultralytics/yolov5/issues/4975,1009795673,I_kwDOD8jP_s48MEJZ,4975,"Roboflow for Datasets, Labeling, and Active Learning 🌟","{'login': 'Jacobsolawetz', 'id': 8428198, 'node_id': 'MDQ6VXNlcjg0MjgxOTg=', 'avatar_url': 'https://avatars.githubusercontent.com/u/8428198?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Jacobsolawetz', 'html_url': 'https://github.com/Jacobsolawetz', 'followers_url': 'https://api.github.com/users/Jacobsolawetz/followers', 'following_url': 'https://api.github.com/users/Jacobsolawetz/following{/other_user}', 'gists_url': 'https://api.github.com/users/Jacobsolawetz/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Jacobsolawetz/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Jacobsolawetz/subscriptions', 'organizations_url': 'https://api.github.com/users/Jacobsolawetz/orgs', 'repos_url': 'https://api.github.com/users/Jacobsolawetz/repos', 'events_url': 'https://api.github.com/users/Jacobsolawetz/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Jacobsolawetz/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}]",open,False,"{'login': 'Jacobsolawetz', 'id': 8428198, 'node_id': 'MDQ6VXNlcjg0MjgxOTg=', 'avatar_url': 'https://avatars.githubusercontent.com/u/8428198?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Jacobsolawetz', 'html_url': 'https://github.com/Jacobsolawetz', 'followers_url': 'https://api.github.com/users/Jacobsolawetz/followers', 'following_url': 'https://api.github.com/users/Jacobsolawetz/following{/other_user}', 'gists_url': 'https://api.github.com/users/Jacobsolawetz/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Jacobsolawetz/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Jacobsolawetz/subscriptions', 'organizations_url': 'https://api.github.com/users/Jacobsolawetz/orgs', 'repos_url': 'https://api.github.com/users/Jacobsolawetz/repos', 'events_url': 'https://api.github.com/users/Jacobsolawetz/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Jacobsolawetz/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'Jacobsolawetz', 'id': 8428198, 'node_id': 'MDQ6VXNlcjg0MjgxOTg=', 'avatar_url': 'https://avatars.githubusercontent.com/u/8428198?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Jacobsolawetz', 'html_url': 'https://github.com/Jacobsolawetz', 'followers_url': 'https://api.github.com/users/Jacobsolawetz/followers', 'following_url': 'https://api.github.com/users/Jacobsolawetz/following{/other_user}', 'gists_url': 'https://api.github.com/users/Jacobsolawetz/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Jacobsolawetz/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Jacobsolawetz/subscriptions', 'organizations_url': 'https://api.github.com/users/Jacobsolawetz/orgs', 'repos_url': 'https://api.github.com/users/Jacobsolawetz/repos', 'events_url': 'https://api.github.com/users/Jacobsolawetz/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Jacobsolawetz/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, {'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,10,2021-09-28T14:00:45Z,2023-11-15T14:39:32Z,,CONTRIBUTOR,,"You can now use Roboflow to organize, label, prepare, version, and host your datasets for training YOLOv5 🚀 models. Roboflow is free to use with YOLOv5 if you make your workspace public. UPDATED 30 September 2021.
​
# Upload
You can upload your data to Roboflow via [web UI](https://docs.roboflow.com/adding-data), [rest API](https://docs.roboflow.com/adding-data/upload-api), or [python](https://docs.roboflow.com/python).
​
# Labeling
After uploading data to Roboflow, you can label your data and review previous labels.
​
[![Roboflow Annotate](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)](https://roboflow.com/annotate)
​
# Versioning
You can make versions of your dataset with different preprocessing and offline augmentation options. YOLOv5 does online augmentations natively, so be intentional when layering Roboflow's offline augs on top.
​
![Roboflow Preprocessing](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)
​
# Exporting Data
You can download your data in YOLOv5 format to quickly begin training.
​
```
from roboflow import Roboflow
rf = Roboflow(api_key=""YOUR API KEY HERE"")
project = rf.workspace().project(""YOUR PROJECT"")
dataset = project.version(""YOUR VERSION"").download(""yolov5"")
```
​
# Custom Training
We have released a custom training tutorial demonstrating all of the above capabilities. You can access the code here:
​
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb)
​
# Active Learning
The real world is messy and your model will invariably encounter situations your dataset didn't anticipate. Using [active learning](https://blog.roboflow.com/what-is-active-learning/) is an important strategy to iteratively improve your dataset and model. With the Roboflow and YOLOv5 integration, you can quickly make improvements on your model deployments by using a battle tested machine learning pipeline.
​
<p align=""""><a href=""https://roboflow.com/?ref=ultralytics""><img width=""1000"" src=""https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png""/></a></p>
​
Please let us know of any curiosities or requests below 👇",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/4975/reactions', 'total_count': 36, '+1': 21, '-1': 0, 'laugh': 3, 'hooray': 3, 'confused': 0, 'heart': 3, 'rocket': 4, 'eyes': 2}",https://api.github.com/repos/ultralytics/yolov5/issues/4975/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/2518,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/2518/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/2518/comments,https://api.github.com/repos/ultralytics/yolov5/issues/2518/events,https://github.com/ultralytics/yolov5/issues/2518,834734231,MDU6SXNzdWU4MzQ3MzQyMzE=,2518,Supervisely with YOLOv5 🌟,"{'login': 'mkolomeychenko', 'id': 12828725, 'node_id': 'MDQ6VXNlcjEyODI4NzI1', 'avatar_url': 'https://avatars.githubusercontent.com/u/12828725?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mkolomeychenko', 'html_url': 'https://github.com/mkolomeychenko', 'followers_url': 'https://api.github.com/users/mkolomeychenko/followers', 'following_url': 'https://api.github.com/users/mkolomeychenko/following{/other_user}', 'gists_url': 'https://api.github.com/users/mkolomeychenko/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mkolomeychenko/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mkolomeychenko/subscriptions', 'organizations_url': 'https://api.github.com/users/mkolomeychenko/orgs', 'repos_url': 'https://api.github.com/users/mkolomeychenko/repos', 'events_url': 'https://api.github.com/users/mkolomeychenko/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mkolomeychenko/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'mkolomeychenko', 'id': 12828725, 'node_id': 'MDQ6VXNlcjEyODI4NzI1', 'avatar_url': 'https://avatars.githubusercontent.com/u/12828725?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mkolomeychenko', 'html_url': 'https://github.com/mkolomeychenko', 'followers_url': 'https://api.github.com/users/mkolomeychenko/followers', 'following_url': 'https://api.github.com/users/mkolomeychenko/following{/other_user}', 'gists_url': 'https://api.github.com/users/mkolomeychenko/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mkolomeychenko/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mkolomeychenko/subscriptions', 'organizations_url': 'https://api.github.com/users/mkolomeychenko/orgs', 'repos_url': 'https://api.github.com/users/mkolomeychenko/repos', 'events_url': 'https://api.github.com/users/mkolomeychenko/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mkolomeychenko/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'mkolomeychenko', 'id': 12828725, 'node_id': 'MDQ6VXNlcjEyODI4NzI1', 'avatar_url': 'https://avatars.githubusercontent.com/u/12828725?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/mkolomeychenko', 'html_url': 'https://github.com/mkolomeychenko', 'followers_url': 'https://api.github.com/users/mkolomeychenko/followers', 'following_url': 'https://api.github.com/users/mkolomeychenko/following{/other_user}', 'gists_url': 'https://api.github.com/users/mkolomeychenko/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/mkolomeychenko/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/mkolomeychenko/subscriptions', 'organizations_url': 'https://api.github.com/users/mkolomeychenko/orgs', 'repos_url': 'https://api.github.com/users/mkolomeychenko/repos', 'events_url': 'https://api.github.com/users/mkolomeychenko/events{/privacy}', 'received_events_url': 'https://api.github.com/users/mkolomeychenko/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,7,2021-03-18T12:12:48Z,2024-10-20T15:29:01Z,,CONTRIBUTOR,,"📚 This guide explains how to use [**Supervisely**](https://supervise.ly/) with YOLOv5 🚀.

# Table of Contents

1. [About Supervisely](#-about-supervisely)
2. [Prerequisites](#Prerequisites)
3. [YOLOv5 Apps Collection](#-yolo-v5-apps-collection)
8. [For developers](#For-developers)
9. [Contact & Questions & Suggestions](#contact--questions--suggestions)

# 🔥 About Supervisely

You can think of [Supervisely](https://supervise.ly/) as an Operating System available via Web Browser to help you solve Computer Vision tasks. The idea is to unify all the relevant tools that may be needed to make the development process as smooth and fast as possible. 

More concretely, Supervisely includes the following functionality:
 - Data labeling for images, videos, 3D point cloud and volumetric medical images (dicom)
 - Data visualization and quality control
 - State-Of-The-Art Deep Learning models for segmentation, detection, classification and other tasks
 - Interactive tools for model performance analysis
 - Specialized Deep Learning models to speed up data labeling (aka AI-assisted labeling)
 - Synthetic data generation tools
 - Instruments to make it easier to collaborate for data scientists, data labelers, domain experts and software engineers

One challenge is to make it possible for everyone to train and apply SOTA Deep Learning models directly from the Web Browser. To address it, we introduce an open sourced Supervisely Agent. All you need to do is to execute a single command on your machine with the GPU that installs the Agent. After that, you keep working in the browser and all the GPU related computations will be performed on the connected machine(s).


# Prerequisites
You should connect computer with GPU to your Supervisely account. If you already have Supervisely Agent running on your computer, you can skip this step.

 Several tools have to be installed on your computer:

- Nvidia drives + [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)
- [Docker](https://docs.docker.com/engine/install/)
- [NVIDIA Container Toolkit](https://github.com/NVIDIA/nvidia-docker)

Once your computer is ready just add agent to your team and execute automatically generated running command in terminal. Watch how-to video:

<a data-key=""sly-embeded-video-link"" href=""https://youtu.be/aDqQiYycqyk"" data-video-code=""aDqQiYycqyk"">
    <img src=""https://i.imgur.com/X9NTc5X.png"" alt=""SLY_EMBEDED_VIDEO_LINK""  style=""width:50%;"">
</a>


# 🎉 YOLO v5 Apps Collection

YOLOv5 is one of the best available detectors. And we are proud to announce its full integrtion into [Supervisely Ecosystem](https://ecosystem.supervise.ly/). To learn more about how to use every app, please go to app's readme page (links are provided). Just add the apps to your team to start using them.

<img src=""https://i.imgur.com/az5sqvk.png""/>

 YOLOv5 Collection consists of the following apps: 

1. [Train YOLOv5](https://ecosystem.supervise.ly/apps/supervisely-ecosystem%252Fyolov5%252Fsupervisely%252Ftrain) - start training on your custom data. Just run app from the context menu of your project, choose classes of interest, train/val splits, configure training metaparameters and augmentations, and monitor training metrics in realtime. App automatically converts all labels to rectangles. All training artifacts including model weights will be saved to Team Files and can be easily downloaded. 

    <img data-key=""sly-module-link"" data-module-slug=""supervisely-ecosystem/yolov5/tree/master/supervisely/train"" src=""https://i.imgur.com/RkVzrLC.png"" width=""350px""/>

2. [Serve YOLOv5](https://ecosystem.supervise.ly/apps/supervisely-ecosystem%252Fyolov5%252Fsupervisely%252Fserve) - serve model as Rest API service. You can run pretrained model, use custom model weights trained in Supervisely as well as weights trained outside (just upload weights file to Team Files). Thus other apps from Ecosystem can get predictions from the deployed model. Also developers can send inference requiests in a few lines of python code.
   
    <img data-key=""sly-module-link"" data-module-slug=""supervisely-ecosystem/yolov5/tree/master/supervisely/serve"" src=""https://i.imgur.com/DVONwK8.png"" width=""350px""/>

3. [Apply NN to images project ](https://ecosystem.supervise.ly/apps/supervisely-ecosystem%252Fnn-image-labeling%252Fproject-dataset) - app allows to play with different inference options and visualize predictions in real time.  Once you choose inference settings you can apply model to all images in your project to visually analise predictions and perform automatic data pre-labeling.   
   
    <img data-key=""sly-module-link"" data-module-slug=""supervisely-ecosystem/nn-image-labeling/tree/master/project-dataset"" src=""https://i.imgur.com/M2Tp8lE.png"" width=""350px""/> 

4. [NN Image Labeling](https://ecosystem.supervise.ly/apps/supervisely-ecosystem%252Fnn-image-labeling%252Fannotation-tool) - integrate any deployd NN to Supervisely Image Labeling UI. Configure inference settings and model output classes. Press `Apply` button (or use hotkey) and detections with their confidences will immediately appear on the image. 
   
    <img data-key=""sly-module-link"" data-module-slug=""supervisely-ecosystem/nn-image-labeling/tree/master/annotation-tool"" src=""https://i.imgur.com/hYEucNt.png"" width=""350px""/> 

5. [Convert Supervisely to YOLO v5 format](https://ecosystem.supervise.ly/apps/convert-supervisely-to-yolov5-format) - export labeled images project in yolov5 compatible format. 
   
    <img data-key=""sly-module-link"" data-module-slug=""supervisely-ecosystem/convert-supervisely-to-yolov5-format"" src=""https://i.imgur.com/9cfB1m0.png"" width=""350px""/> 

6. [Convert YOLO v5 to Supervisely format](https://ecosystem.supervise.ly/apps/convert-yolov5-to-supervisely-format) - import images and yolov5 annotatons to Supervisely.

    <img data-key=""sly-module-link"" data-module-slug=""supervisely-ecosystem/convert-yolov5-to-supervisely-format"" src=""https://i.imgur.com/roiJIE8.png"" width=""350px""/> 

7. [Export weights](https://ecosystem.supervise.ly/apps/convert-yolov5-to-supervisely-format) - export weights to ONNX or TorchScript; also find python examples how to apply exported weights to an image and get predictions.

    <img data-key=""sly-module-link"" data-module-slug=""supervisely-ecosystem%252Fyolov5%252Fsupervisely%252Fexport_weights"" src=""https://i.imgur.com/6h0krdp.png"" width=""350px""/> 

# For Developers

- you can use sources of [Serve YOLOv5 app](https://github.com/supervisely-ecosystem/yolov5/tree/master/supervisely/serve) as example of how to prepare weights, initialize model and apply it to a folder with images (or to images URLs)
- This apps collection is based on the original YOLOv5 [release v5.0](https://github.com/ultralytics/yolov5/releases/tag/v5.0). Once a next official release is available, all apps will be synchronized with it and also released with the new versions. Before running any app you can choose what version to use. Also Supervisely Team will pull updates from original master branch from time to time.

# Contact & Questions & Suggestions

- for technical support please leave issues, questions or suggestions to original [YOLOv5 repo](https://github.com/ultralytics/yolov5/issues) with the prefix `[Supervisely]`. Our team will try to help.
- also we can chat in slack channel [![](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://supervise.ly/slack) ",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/2518/reactions', 'total_count': 18, '+1': 10, '-1': 0, 'laugh': 2, 'hooray': 1, 'confused': 0, 'heart': 1, 'rocket': 3, 'eyes': 1}",https://api.github.com/repos/ultralytics/yolov5/issues/2518/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/2258,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/2258/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/2258/comments,https://api.github.com/repos/ultralytics/yolov5/issues/2258/events,https://github.com/ultralytics/yolov5/issues/2258,812733242,MDU6SXNzdWU4MTI3MzMyNDI=,2258,🌟💶 Competition: pycocotools mAP Alignment  ,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2068758695, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/help%20wanted', 'name': 'help wanted', 'color': '008672', 'default': True, 'description': 'Extra attention is needed'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,4,2021-02-20T23:49:42Z,2021-12-03T16:26:54Z,,MEMBER,,"# 🌟💶 Ultralytics Competition: pycocotools mAP Alignment  

I'm super excited to announce our very first **Ultralytics AI Competition** 😃!! This is the first in a series of challenges that we are facing at Ultralytics that we want to share with the community to allow everyone to help with. Competition participants can contribute open-source solutions to receive prize money and to improve the YOLOv5 experience for everyone.


## Problem 🤔

Our local mAP results do not align as well as we'd like with [pycocotools](https://github.com/cocodataset/cocoapi) mAP results. They are similar to within about 1%, but we want to improve this further, to give better confidence in the metrics we produce on custom datasets where pycocotools-format JSON labels are unavailable. Below is an example of the problem from our Colab [notebook](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb?hl=en#scrollTo=WQPtK1QYVaD_), showing YOLOv5x COCO local **49.6** mAP@0.5:0.95 vs pycocotools **50.7** mAP@0.5:0.95.

<img width=""1000"" alt=""mAP Values"" src=""https://user-images.githubusercontent.com/26833433/142871109-30963d26-1838-426d-b6b5-b2d1d80f876c.png"">

YOLOv5 mAP is computed in val.py with functions from utils/metrics.py:
https://github.com/ultralytics/yolov5/blob/f17c86b7f0d2038288d7292cb82dec2433cc91e5/val.py#L237-L243

## Solution 💡

The winning solution must meet all of the following criteria:

1. **Local mAP@0.5** and **mAP@0.5:0.95** must match pycocotools mAP@0.5 and mAP@0.5:0.95 in all test cases to **< 0.1** difference. For example 50.0 vs 50.1 qualifies but not 49.9 vs 50.1.
2. `test.py` execution time must remain within 10% of current time for all test cases. If test.py currently runs in 60 seconds, a winning submission must run in <66 seconds. This will prevent a simple import of the pycocotools code, which itself is very slow, and is the reason we have not adopted it fully.
3. Solutions must be submitted in the form of a Pull Request to the [ultralytics/yolov5](https://github.com/ultralytics/yolov5) repository and pass all automatic [CI checks](https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml).
4. Test results below must accompany PRs (winning submissions will be independently verified by Ultralytics).

Test cases are below (8 different scenarios). This code can be copied and pasted into a Colab notebook, and the cell output should accompany competition submissions.

```python
# Run pycocotools mAP Alignment Competition tests
for weights in 'yolov5s.pt', 'yolov5x.pt':
  for img in 320, 640:
    for iou in 0.45, 0.65:
      !python test.py --weights {weights} --data coco.yaml --img {img} --iou {iou}
```


## 💶 Prize €1000.00

The first submission that meets all of the Solution requirements will claim the full prize funds of **€1000.00 (1000 EUR)** from Ultralytics. Funds will be converted to participant's local currency using the exchange rate on date of winning submission.


## 📅 Deadline

The deadline for submissions is **March 31st, 2022**. After this date the competition will be closed. If a winning submission is received before the deadline then the competition may be closed early.

If multiple submissions meet the Solution requirements the earliest dated submission will claim the full prize. If a PR is composed of multiple commits then the submission timestamp will be the time of the earliest commit in a PR that meets all of the Solution requirements.


## ✅ Participation Requirements

This competition is open to any individual or organization from **any country** 🇺🇳. There is no restrictions on citizenship, age, gender or location. To receive prize funds the winning participant must meet the eligibility requirements of our funds transfer [provider](https://transferwise.com/help/articles/2571942/what-countries-can-i-send-to) and provide name, address, phone number, email and bank info.
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/2258/reactions', 'total_count': 16, '+1': 4, '-1': 0, 'laugh': 2, 'hooray': 2, 'confused': 0, 'heart': 2, 'rocket': 4, 'eyes': 2}",https://api.github.com/repos/ultralytics/yolov5/issues/2258/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/2084,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/2084/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/2084/comments,https://api.github.com/repos/ultralytics/yolov5/issues/2084/events,https://github.com/ultralytics/yolov5/issues/2084,797216611,MDU6SXNzdWU3OTcyMTY2MTE=,2084,Amazon Web Services (AWS) Quickstart Tutorial,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,3,2021-01-29T21:25:32Z,2024-10-20T15:18:07Z,,MEMBER,,"This quickstart guide helps new users run YOLOv5 🚀 on an Amazon Web Services (AWS) Deep Learning instance ⭐. AWS offers a [Free Tier](https://aws.amazon.com/free/) and a [credit program](https://aws.amazon.com/activate/) to get started quickly and affordably. Other quickstart options for YOLOv5 include our [Colab Notebook](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb) <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a>, [GCP Deep Learning VM](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart) and our Docker image at https://hub.docker.com/r/ultralytics/yolov5 ![Docker Pulls](https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker).

## 1. Console Sign-in

Create and account or sign-in to the AWS console at https://aws.amazon.com/console/ and then select the **EC2** service.
<img width=""800"" alt=""Console"" src=""https://user-images.githubusercontent.com/26833433/106323804-debddd00-622c-11eb-997f-b8217dc0e975.png"">


## 2. Launch Instance

In the EC2 part of the AWS console, click the **Launch instance** button.
<img width=""800"" alt=""Launch"" src=""https://user-images.githubusercontent.com/26833433/106323950-204e8800-622d-11eb-915d-5c90406973ea.png"">


### Choose an Amazon Machine Image (AMI)
Enter 'Deep Learning' in the search field and select the most recent Ubuntu Deep Learning AMI (recommended), or select an alternative Deep Learning AMI. See [Choosing Your DLAMI](https://docs.aws.amazon.com/dlami/latest/devguide/options.html) for more information on selecting an AMI.
<img width=""800"" alt=""Choose AMI"" src=""https://user-images.githubusercontent.com/26833433/106326107-c9e34880-6230-11eb-97c9-3b5fc2f4e2ff.png"">

### Select an Instance Type

A GPU instance is recommended for most deep learning purposes. Training new models will be faster on a GPU instance than a CPU instance. You can scale sub-linearly when you have multi-GPU instances or if you use distributed training across many instances with GPUs. To set up distributed training, see [Distrbuted Training](https://docs.aws.amazon.com/dlami/latest/devguide/distributed-training.html).

Note: The size of your model should be a factor in selecting an instance. If your model exceeds an instance's available RAM, select a different instance type with enough memory for your application.

* [Amazon EC2 P3 Instances](https://aws.amazon.com/ec2/instance-types/p3/) have up to 8 NVIDIA Tesla V100 GPUs.
* [Amazon EC2 P2 Instances](https://aws.amazon.com/ec2/instance-types/p2/) have up to 16 NVIDIA NVIDIA K80 GPUs.
* [Amazon EC2 G3 Instances](https://aws.amazon.com/ec2/instance-types/g3/) have up to 4 NVIDIA Tesla M60 GPUs.
* [Amazon EC2 G4 Instances](https://aws.amazon.com/ec2/instance-types/g4/) have up to 4 NVIDIA T4 GPUs.
* [Amazon EC2 P4 Instances](https://aws.amazon.com/ec2/instance-types/p4/) have up to 8 NVIDIA Tesla A100 GPUs.

Check out [EC2 Instance Types](https://aws.amazon.com/ec2/instance-types/) and choose Accelerated Computing to see the different GPU instance options.

<img width=""800"" alt=""Choose Type"" src=""https://user-images.githubusercontent.com/26833433/106324624-52141e80-622e-11eb-9662-1a376d9c887d.png"">

DLAMI instances provide tooling to monitor and optimize your GPU processes. For more information on overseeing your GPU processes, see [GPU Monitoring and Optimization](https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-gpu.html). For pricing see [On Demand Pricing](https://aws.amazon.com/ec2/pricing/on-demand/) and [Spot Pricing](https://aws.amazon.com/ec2/spot/pricing/).


### Configure Instance Details

Amazon EC2 Spot Instances let you take advantage of unused EC2 capacity in the AWS cloud. Spot Instances are available at up to a 70% discount compared to On-Demand prices. We recommend a persistent spot instance, which will save your data and restart automatically when spot instance availability returns after spot instance termination. For full-price On-Demand instances leave these settings to their default values. 

<img width=""800"" alt=""Spot Request"" src=""https://user-images.githubusercontent.com/26833433/106324835-ac14e400-622e-11eb-8853-df5ec9b16dfc.png"">

Complete Steps 4-7 to finalize your instance hardware and security settings and then launch the instance.


## 3. Connect to Instance

Select the check box next to your running instance, and then click connect. You can copy paste the SSH terminal command into a terminal of your choice to connect to your instance.

<img width=""800"" alt=""Connect"" src=""https://user-images.githubusercontent.com/26833433/106325530-cf8c5e80-622f-11eb-9f64-5b313a9d57a1.png"">


## 4. Run YOLOv5 🚀
Once you have logged in to your instance, clone this repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) dependencies, including **Python>=3.8** and **PyTorch>=1.7**.

```bash
$ git clone https://github.com/ultralytics/yolov5  # clone repo
$ cd yolov5
$ pip install -r requirements.txt  # install dependencies
```

Then get started training, testing and detecting!
```bash
$ python train.py  # train a model
$ python test.py --weights yolov5s.pt  # test a model for Precision, Recall and mAP
$ python detect.py --weights yolov5s.pt --source path/to/images  # run inference on images and videos
```

## Optional Extras

Add 64GB of swap memory (to `--cache` large datasets).
```bash
sudo fallocate -l 64G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
free -h  # check memory
```",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/2084/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/2084/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/1314,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/1314/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/1314/comments,https://api.github.com/repos/ultralytics/yolov5/issues/1314/events,https://github.com/ultralytics/yolov5/issues/1314,737921129,MDU6SXNzdWU3Mzc5MjExMjk=,1314,Transfer Learning with Frozen Layers,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,62,2020-11-06T17:17:58Z,2024-10-20T14:57:51Z,,MEMBER,,"📚 This guide explains how to **freeze** YOLOv5 🚀 layers when **transfer learning**. Transfer learning is a useful way to quickly retrain a model on new data without having to retrain the entire network. Instead, part of the initial weights are frozen in place, and the rest of the weights are used to compute loss and are updated by the optimizer. This requires less resources than normal training and allows for faster training times, though it may also results in reductions to final trained accuracy. UPDATED 28 March 2023.


## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```

## Freeze Backbone

All layers that match the `freeze` list in train.py will be frozen by setting their gradients to zero before training starts.
https://github.com/ultralytics/yolov5/blob/771ac6c53ded79c408ed8bd99f7604b7077b7d77/train.py#L119-L126

To see a list of module names:
```python
for k, v in model.named_parameters():
    print(k)

# Output
model.0.conv.conv.weight
model.0.conv.bn.weight
model.0.conv.bn.bias
model.1.conv.weight
model.1.bn.weight
model.1.bn.bias
model.2.cv1.conv.weight
model.2.cv1.bn.weight
...
model.23.m.0.cv2.bn.weight
model.23.m.0.cv2.bn.bias
model.24.m.0.weight
model.24.m.0.bias
model.24.m.1.weight
model.24.m.1.bias
model.24.m.2.weight
model.24.m.2.bias
```

Looking at the model architecture we can see that the model backbone is layers 0-9:
https://github.com/ultralytics/yolov5/blob/58f8ba771e3712b525ca93a1ee66bc2b2df2092f/models/yolov5s.yaml#L12-L48

so we can define the freeze list to contain all modules with 'model.0.' - 'model.9.' in their names:
```bash
python train.py --freeze 10
```

## Freeze All Layers

To freeze the full model except for the final output convolution layers in Detect(), we set freeze list to contain all modules with 'model.0.' - 'model.23.' in their names:
```bash
python train.py --freeze 24
```

## Results

We train YOLOv5m on VOC on both of the above scenarios, along with a default model (no freezing), starting from the official COCO pretrained `--weights yolov5m.pt`:
```python
$ train.py --batch 48 --weights yolov5m.pt --data voc.yaml --epochs 50 --cache --img 512 --hyp hyp.finetune.yaml
```

### Accuracy Comparison

The results show that freezing speeds up training, but reduces final accuracy slightly.

![](https://user-images.githubusercontent.com/26833433/98394454-11579f80-205b-11eb-8e57-d8318e1cc2f8.png)

![](https://user-images.githubusercontent.com/26833433/98394459-13216300-205b-11eb-871b-49e20691a423.png)

<img width=""922"" alt=""Screenshot 2020-11-06 at 18 08 13"" src=""https://user-images.githubusercontent.com/26833433/98394485-22081580-205b-11eb-9e37-1f9869fe91d8.png"">

### GPU Utilization Comparison

Interestingly, the more modules are frozen the less GPU memory is required to train, and the lower GPU utilization. This indicates that larger models, or models trained at larger --image-size may benefit from freezing in order to train faster.

![](https://user-images.githubusercontent.com/26833433/98394920-c2f6d080-205b-11eb-9611-fd68522b4e0e.png)

![](https://user-images.githubusercontent.com/26833433/98394918-bf634980-205b-11eb-948d-311036ef9325.png)


## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/1314/reactions', 'total_count': 105, '+1': 64, '-1': 0, 'laugh': 5, 'hooray': 8, 'confused': 0, 'heart': 13, 'rocket': 10, 'eyes': 5}",https://api.github.com/repos/ultralytics/yolov5/issues/1314/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/1276,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/1276/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/1276/comments,https://api.github.com/repos/ultralytics/yolov5/issues/1276/events,https://github.com/ultralytics/yolov5/issues/1276,735508557,MDU6SXNzdWU3MzU1MDg1NTc=,1276,iOS iDetection Speed Table,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}, {'id': 2068758695, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk1', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/help%20wanted', 'name': 'help wanted', 'color': '008672', 'default': True, 'description': 'Extra attention is needed'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,21,2020-11-03T17:29:25Z,2023-11-19T21:24:24Z,,MEMBER,,"## 🚀 Feature
We'd like to create an iDetection Speed Table for each year's iPhone release, going back as far as iDetection will run, which may be around iPhone 5 or 6. Crowd-sourcing the table will help show real-world performance of the models on various hardware. 

**If you have an iOS device, you can contribute** by downloading [iDetection](https://apps.apple.com/us/app/idetection/id1452689527), testing your speeds, and then uploading your results here. We try to test near 100% battery at room temperature (about 25°C), and record the speed after about 10 seconds of inference for each model. 

Please help by uploading your results! Thank you!!

<img src=""https://user-images.githubusercontent.com/26833433/98019191-be36e000-1e01-11eb-97e0-69ca25c30531.jpg"" width=""800"">


## iDetection v7.8 Inference Speeds

&nbsp; | Year | ASIC<br>-process | ANE<br>(TOPS) || YOLOv5s<br>(ms)   |YOLOv5m<br>(ms)   |YOLOv5l<br>(ms)   |YOLOv5x<br>(ms)
--- |---  |---  |---  |-|---   |---   |---   |---
iPhone 6  | 2014  | [A8-20nm](https://en.wikipedia.org/wiki/Apple_A8)  |-  ||90  |180  |350  |500
iPhone 6s  | 2015  | [A9-16nm](https://en.wikipedia.org/wiki/Apple_A9)  |-  ||148  |216  |304  |475
iPhone 7  | 2016  | [A10-16nm](https://en.wikipedia.org/wiki/Apple_A10)  |-  ||94.7  |140.7  |216.7  |289.8
iPhone 8/X  | 2017  | [A11-10nm](https://en.wikipedia.org/wiki/Apple_A11)  |0.6  ||-  |-  |-  |-
iPhone XR/XS  | 2018  | [A12-7nm](https://en.wikipedia.org/wiki/Apple_A12)  |5.0  ||22.3  |25.8  |43.2 |57.7
iPhone 11 | 2019  | [A13-7nm](https://en.wikipedia.org/wiki/Apple_A13)  |6.0 ||17.4  |21.3  |27.8  |41.2
iPhone 12 | 2020  | [A14-5nm](https://en.wikipedia.org/wiki/Apple_A14)  |11.0  ||14.3  |16.5  |21.0  |28.8
iPhone 13 | 2021  | [A15-5nm](https://en.wikipedia.org/wiki/Apple_A15)  |15.8  ||  |  |  |

*CoreML models exported as FP8 320x192 with [release v3.1](https://github.com/ultralytics/yolov5/releases)
*Measured with [iDetection v7.8](https://apps.apple.com/us/app/idetection/id1452689527) at 100% battery at 25°C. Average speed after 10 seconds recorded.

","{'login': 'github-actions[bot]', 'id': 41898282, 'node_id': 'MDM6Qm90NDE4OTgyODI=', 'avatar_url': 'https://avatars.githubusercontent.com/in/15368?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/github-actions%5Bbot%5D', 'html_url': 'https://github.com/apps/github-actions', 'followers_url': 'https://api.github.com/users/github-actions%5Bbot%5D/followers', 'following_url': 'https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}', 'gists_url': 'https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/github-actions%5Bbot%5D/subscriptions', 'organizations_url': 'https://api.github.com/users/github-actions%5Bbot%5D/orgs', 'repos_url': 'https://api.github.com/users/github-actions%5Bbot%5D/repos', 'events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}', 'received_events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/received_events', 'type': 'Bot', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/1276/reactions', 'total_count': 14, '+1': 3, '-1': 0, 'laugh': 2, 'hooray': 3, 'confused': 0, 'heart': 2, 'rocket': 2, 'eyes': 2}",https://api.github.com/repos/ultralytics/yolov5/issues/1276/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/1044,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/1044/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/1044/comments,https://api.github.com/repos/ultralytics/yolov5/issues/1044/events,https://github.com/ultralytics/yolov5/issues/1044,709268069,MDU6SXNzdWU3MDkyNjgwNjk=,1044,iDetection v7.7 Release ,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,,[],,10,2020-09-25T20:36:16Z,2022-01-16T22:02:48Z,,MEMBER,,"## 🚀 Feature
We've released iDetection v7.7 on the iOS app store (https://apps.apple.com/app/id1452689527)! This release features all four v3.0 models YOLv5s/m/l/x running with hardswish activations for the first time.  This update also brings some supercool features we've been working on:

- Modify Confidence Threshold and NMS IoU Threshold in realtime user sliders and instantly see the effects:
<img src=""https://user-images.githubusercontent.com/26833433/94313196-2953e380-ff33-11ea-9b0a-f2d597ff0cce.jpg"" width=""400"">

- Rotation capability. device orientation is now passed in realtime to the inference handler, so the app is more robust to landscape and upside down inference than before. Vertical and upside down inference works best, as we export our models for vertical rectangular inference, so when used in landscape mode the app is resizing the horizontal video into the vertical inference, which is not ideal but still produces results.
<img src=""https://user-images.githubusercontent.com/26833433/94313235-353fa580-ff33-11ea-8ecb-9b5f328bb8bc.jpg"" width=""800"">","{'login': 'github-actions[bot]', 'id': 41898282, 'node_id': 'MDM6Qm90NDE4OTgyODI=', 'avatar_url': 'https://avatars.githubusercontent.com/in/15368?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/github-actions%5Bbot%5D', 'html_url': 'https://github.com/apps/github-actions', 'followers_url': 'https://api.github.com/users/github-actions%5Bbot%5D/followers', 'following_url': 'https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}', 'gists_url': 'https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/github-actions%5Bbot%5D/subscriptions', 'organizations_url': 'https://api.github.com/users/github-actions%5Bbot%5D/orgs', 'repos_url': 'https://api.github.com/users/github-actions%5Bbot%5D/repos', 'events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}', 'received_events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/received_events', 'type': 'Bot', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/1044/reactions', 'total_count': 5, '+1': 4, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 1, 'eyes': 0}",https://api.github.com/repos/ultralytics/yolov5/issues/1044/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/607,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/607/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/607/comments,https://api.github.com/repos/ultralytics/yolov5/issues/607/events,https://github.com/ultralytics/yolov5/issues/607,671675062,MDU6SXNzdWU2NzE2NzUwNjI=,607,Hyperparameter Evolution,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,204,2020-08-02T19:28:35Z,2024-10-20T14:41:34Z,,MEMBER,,"📚  This guide explains **hyperparameter evolution** for YOLOv5 🚀. Hyperparameter evolution is a method of [Hyperparameter Optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization) using a [Genetic Algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm) (GA) for optimization. UPDATED 28 March 2023.

Hyperparameters in ML control various aspects of training, and finding optimal values for them can be a challenge. Traditional methods like grid searches can quickly become intractable due to 1) the high dimensional search space 2) unknown correlations among the dimensions, and 3) expensive nature of evaluating the fitness at each point, making GA a suitable candidate for hyperparameter searches.


## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```


## 1. Initialize Hyperparameters

YOLOv5 has about 30 hyperparameters used for various training settings. These are defined in `*.yaml` files in the `/data` directory. Better initial guesses will produce better final results, so it is important to initialize these values properly before evolving. If in doubt, simply use the default values, which are optimized for YOLOv5 COCO training from scratch.

https://github.com/ultralytics/yolov5/blob/2da2466168116a9fa81f4acab744dc9fe8f90cac/data/hyps/hyp.scratch-low.yaml#L2-L34

## 2. Define Fitness

Fitness is the value we seek to maximize. In YOLOv5 we define a default fitness function as a weighted combination of metrics: `mAP@0.5` contributes 10% of the weight and `mAP@0.5:0.95` contributes the remaining 90%, with [Precision `P` and Recall `R`](https://en.wikipedia.org/wiki/Precision_and_recall) absent. You may adjust these as you see fit or use the default fitness definition (recommended).
https://github.com/ultralytics/yolov5/blob/4103ce9ad0393cc27f6c80457894ad7be0cb1f0d/utils/metrics.py#L12-L16

## 3. Evolve

Evolution is performed about a base scenario which we seek to improve upon. The base scenario in this example is finetuning COCO128 for 10 epochs using pretrained YOLOv5s. The base scenario training command is:
```bash
python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache
```
To evolve hyperparameters **specific to this scenario**, starting from our initial values defined in **Section 1.**, and maximizing the fitness defined in **Section 2.**, append `--evolve`:
```bash
# Single-GPU
python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache --evolve

# Multi-GPU
for i in 0 1 2 3 4 5 6 7; do
  sleep $(expr 30 \* $i) &&  # 30-second delay (optional)
  echo 'Starting GPU '$i'...' &&
  nohup python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache --device $i --evolve > evolve_gpu_$i.log &
done

# Multi-GPU bash-while (not recommended)
for i in 0 1 2 3 4 5 6 7; do
  sleep $(expr 30 \* $i) &&  # 30-second delay (optional)
  echo 'Starting GPU '$i'...' &&
  ""$(while true; do nohup python train.py... --device $i --evolve 1 > evolve_gpu_$i.log; done)"" &
done
```

The default evolution settings will run the base scenario 300 times, i.e. for 300 generations. You can modify generations via the `--evolve` argument, i.e. `python train.py --evolve 1000`.
https://github.com/ultralytics/yolov5/blob/6a3ee7cf03efb17fbffde0e68b1a854e80fe3213/train.py#L608

The main genetic operators are **crossover** and **mutation**. In this work mutation is used, with a 80% probability and a 0.04 variance to create new offspring based on a combination of the best parents from all previous generations. Results are logged to `runs/evolve/exp/evolve.csv`, and the highest fitness offspring is saved every generation as `runs/evolve/hyp_evolved.yaml`:
```yaml
# YOLOv5 Hyperparameter Evolution Results
# Best generation: 287
# Last generation: 300
#    metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss
#              0.54634,              0.55625,              0.58201,              0.33665,             0.056451,             0.042892,             0.013441

lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr
box: 0.05  # box loss gain
cls: 0.5  # cls loss gain
cls_pw: 1.0  # cls BCELoss positive_weight
obj: 1.0  # obj loss gain (scale with pixels)
obj_pw: 1.0  # obj BCELoss positive_weight
iou_t: 0.20  # IoU training threshold
anchor_t: 4.0  # anchor-multiple threshold
# anchors: 3  # anchors per output layer (0 to ignore)
fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
hsv_h: 0.015  # image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # image HSV-Value augmentation (fraction)
degrees: 0.0  # image rotation (+/- deg)
translate: 0.1  # image translation (+/- fraction)
scale: 0.5  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.5  # image flip left-right (probability)
mosaic: 1.0  # image mosaic (probability)
mixup: 0.0  # image mixup (probability)
copy_paste: 0.0  # segment copy-paste (probability)
```

We recommend a minimum of 300 generations of evolution for best results. Note that **evolution is generally expensive and time consuming**, as the base scenario is trained hundreds of times, possibly requiring hundreds or thousands of GPU hours.


## 4. Visualize

`evolve.csv` is plotted as `evolve.png` by `utils.plots.plot_evolve()` after evolution finishes with one subplot per hyperparameter showing fitness (y axis) vs hyperparameter values (x axis). Yellow indicates higher concentrations. Vertical distributions indicate that a parameter has been disabled and does not mutate. This is user selectable in the `meta` dictionary in train.py, and is useful for fixing parameters and preventing them from evolving.

![evolve](https://user-images.githubusercontent.com/26833433/89130469-f43e8e00-d4b9-11ea-9e28-f8ae3622516d.png)


## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/607/reactions', 'total_count': 169, '+1': 73, '-1': 0, 'laugh': 16, 'hooray': 20, 'confused': 0, 'heart': 27, 'rocket': 19, 'eyes': 14}",https://api.github.com/repos/ultralytics/yolov5/issues/607/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/475,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/475/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/475/comments,https://api.github.com/repos/ultralytics/yolov5/issues/475/events,https://github.com/ultralytics/yolov5/issues/475,663693859,MDU6SXNzdWU2NjM2OTM4NTk=,475,Multi-GPU Training 🌟,"{'login': 'NanoCode012', 'id': 9899957, 'node_id': 'MDQ6VXNlcjk4OTk5NTc=', 'avatar_url': 'https://avatars.githubusercontent.com/u/9899957?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/NanoCode012', 'html_url': 'https://github.com/NanoCode012', 'followers_url': 'https://api.github.com/users/NanoCode012/followers', 'following_url': 'https://api.github.com/users/NanoCode012/following{/other_user}', 'gists_url': 'https://api.github.com/users/NanoCode012/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/NanoCode012/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/NanoCode012/subscriptions', 'organizations_url': 'https://api.github.com/users/NanoCode012/orgs', 'repos_url': 'https://api.github.com/users/NanoCode012/repos', 'events_url': 'https://api.github.com/users/NanoCode012/events{/privacy}', 'received_events_url': 'https://api.github.com/users/NanoCode012/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'NanoCode012', 'id': 9899957, 'node_id': 'MDQ6VXNlcjk4OTk5NTc=', 'avatar_url': 'https://avatars.githubusercontent.com/u/9899957?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/NanoCode012', 'html_url': 'https://github.com/NanoCode012', 'followers_url': 'https://api.github.com/users/NanoCode012/followers', 'following_url': 'https://api.github.com/users/NanoCode012/following{/other_user}', 'gists_url': 'https://api.github.com/users/NanoCode012/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/NanoCode012/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/NanoCode012/subscriptions', 'organizations_url': 'https://api.github.com/users/NanoCode012/orgs', 'repos_url': 'https://api.github.com/users/NanoCode012/repos', 'events_url': 'https://api.github.com/users/NanoCode012/events{/privacy}', 'received_events_url': 'https://api.github.com/users/NanoCode012/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'NanoCode012', 'id': 9899957, 'node_id': 'MDQ6VXNlcjk4OTk5NTc=', 'avatar_url': 'https://avatars.githubusercontent.com/u/9899957?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/NanoCode012', 'html_url': 'https://github.com/NanoCode012', 'followers_url': 'https://api.github.com/users/NanoCode012/followers', 'following_url': 'https://api.github.com/users/NanoCode012/following{/other_user}', 'gists_url': 'https://api.github.com/users/NanoCode012/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/NanoCode012/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/NanoCode012/subscriptions', 'organizations_url': 'https://api.github.com/users/NanoCode012/orgs', 'repos_url': 'https://api.github.com/users/NanoCode012/repos', 'events_url': 'https://api.github.com/users/NanoCode012/events{/privacy}', 'received_events_url': 'https://api.github.com/users/NanoCode012/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,110,2020-07-22T11:36:27Z,2024-10-20T14:38:37Z,,CONTRIBUTOR,,"📚 This guide explains how to properly use **multiple** GPUs to train a dataset with YOLOv5 🚀 on single or multiple machine(s). UPDATED 25 December 2022.

## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```

💡 ProTip! **Docker Image** is recommended for all Multi-GPU trainings. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>
💡 ProTip! `torch.distributed.run` replaces `torch.distributed.launch` in **PyTorch>=1.9**. See [docs](https://pytorch.org/docs/stable/distributed.html) for details.

## Training

Select a pretrained model to start training from. Here we select [YOLOv5s](https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml), the smallest and fastest model available. See our README [table](https://github.com/ultralytics/yolov5#pretrained-checkpoints) for a full comparison of all models.  We will train this model with Multi-GPU on the [COCO](https://github.com/ultralytics/yolov5/blob/master/data/get_coco2017.sh) dataset.

<p align=""center""><img width=""700"" alt=""YOLOv5 Models"" src=""https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png""></p>


### Single GPU

```bash
$ python train.py  --batch 64 --data coco.yaml --weights yolov5s.pt --device 0
```

### Multi-GPU [DataParallel](https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel) Mode (⚠️ not recommended)

You can increase the `device` to use Multiple GPUs in DataParallel mode.
```bash
$ python train.py  --batch 64 --data coco.yaml --weights yolov5s.pt --device 0,1
```

This method is slow and barely speeds up training compared to using just 1 GPU.

### Multi-GPU [DistributedDataParallel](https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel) Mode (✅ recommended)

You will have to pass `python -m torch.distributed.run --nproc_per_node`, followed by the usual arguments.

```bash
$ python -m torch.distributed.run --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s.pt --device 0,1
```

`--nproc_per_node` specifies how many GPUs you would like to use. In the example above, it is 2.
`--batch ` is the total batch-size. It will be divided evenly to each GPU. In the example above, it is 64/2=32 per GPU.

The code above will use GPUs `0... (N-1)`.

<details>
    <summary>Use specific GPUs (click to expand)</summary><br>

You can do so by simply passing `--device` followed by your specific GPUs. For example, in the code below, we will use GPUs `2,3`.

```bash
$ python -m torch.distributed.run --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --device 2,3
```

</details>

<details>
    <summary>Use SyncBatchNorm (click to expand)</summary><br>


[SyncBatchNorm](https://pytorch.org/docs/master/generated/torch.nn.SyncBatchNorm.html) could increase accuracy for multiple gpu training, however, it will slow down training by a significant factor. It is **only** available for Multiple GPU DistributedDataParallel training. 

It is best used when the batch-size on **each** GPU is small (<= 8).

To use SyncBatchNorm, simple pass `--sync-bn` to the command like below, 

```bash
$ python -m torch.distributed.run --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --sync-bn
```
</details>

<details>
    <summary>Use Multiple machines (click to expand)</summary><br>

This is **only** available for Multiple GPU DistributedDataParallel training. 

Before we continue, make sure the files on all machines are the same, dataset, codebase, etc. Afterwards, make sure the machines can communicate to each other.

You will have to choose a master machine(the machine that the others will talk to). Note down its address(`master_addr`) and choose a port(`master_port`). I will use `master_addr = 192.168.1.1` and `master_port = 1234` for the example below.

To use it, you can do as the following,

```bash
# On master machine 0
$ python -m torch.distributed.run --nproc_per_node G --nnodes N --node_rank 0 --master_addr ""192.168.1.1"" --master_port 1234 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights ''
```
```bash
# On machine R
$ python -m torch.distributed.run --nproc_per_node G --nnodes N --node_rank R --master_addr ""192.168.1.1"" --master_port 1234 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights ''
```
where `G` is number of GPU per machine, `N` is the number of machines, and `R` is the machine number from `0...(N-1)`. 
Let's say I have two machines with two GPUs each, it would be `G = 2` , `N = 2`, and `R = 1` for the above.

Training will not start until <b>all </b> `N` machines are connected. Output will only be shown on master machine!

</details>


### Notes

- Windows support is untested, Linux is recommended.
- `--batch ` must be a multiple of the number of GPUs.
- GPU 0 will take slightly more memory than the other GPUs as it maintains EMA and is responsible for checkpointing etc.
- If you get `RuntimeError: Address already in use`, it could be because you are running multiple trainings at a time. To fix this, simply use a different port number by adding `--master_port` like below,

```bash
$ python -m torch.distributed.run --master_port 1234 --nproc_per_node 2 ...
```

## Results

DDP profiling results on an [AWS EC2 P4d instance](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart) with 8x A100 SXM4-40GB for YOLOv5l for 1 COCO epoch.

<details>
    <summary>Profiling code</summary>

```bash
# prepare
t=ultralytics/yolov5:latest && sudo docker pull $t && sudo docker run -it --ipc=host --gpus all -v ""$(pwd)""/coco:/usr/src/coco $t
pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html
cd .. && rm -rf app && git clone https://github.com/ultralytics/yolov5 -b master app && cd app
cp data/coco.yaml data/coco_profile.yaml

# profile
python train.py --batch-size 16 --data coco_profile.yaml --weights yolov5l.pt --epochs 1 --device 0 
python -m torch.distributed.run --nproc_per_node 2 train.py --batch-size 32 --data coco_profile.yaml --weights yolov5l.pt --epochs 1 --device 0,1   
python -m torch.distributed.run --nproc_per_node 4 train.py --batch-size 64 --data coco_profile.yaml --weights yolov5l.pt --epochs 1 --device 0,1,2,3  
python -m torch.distributed.run --nproc_per_node 8 train.py --batch-size 128 --data coco_profile.yaml --weights yolov5l.pt --epochs 1 --device 0,1,2,3,4,5,6,7
```

</details>

GPUs<br>A100 | batch-size  | CUDA_mem<br><sup>device0 (G)  |COCO<br><sup>train    |COCO<br><sup>val
---        |---    |---    |---  |--- 
1x      | 16 | 26GB |20:39             | 0:55 
2x      | 32 | 26GB |11:43             | 0:57
4x      | 64 | 26GB |5:57             | 0:55
8x      | 128 | 26GB |3:09             | 0:57

## FAQ

If an error occurs, please read the checklist below first! (It could save your time)

<details>
    <summary>Checklist (click to expand) </summary><br>

<ul>
    <li>Have you properly read this post?  </li>
    <li>Have you tried to reclone the codebase? The code changes <b>daily</b>.</li>
    <li>Have you tried to search for your error? Someone may have already encountered it in this repo or in another and have the solution. </li>
    <li>Have you installed all the requirements listed on top (including the correct Python and Pytorch versions)? </li>
    <li>Have you tried in other environments listed in the ""Environments"" section below? </li>
    <li>Have you tried with another dataset like coco128 or coco2017? It will make it easier to find the root cause. </li>
</ul>

If you went through all the above, feel free to raise an Issue by giving as much detail as possible following the template. <br>

</details>


## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.


## Credits

I would like to thank @MagicFrogSJTU, who did all the heavy lifting, and @glenn-jocher for guiding us along the way.","{'login': 'github-actions[bot]', 'id': 41898282, 'node_id': 'MDM6Qm90NDE4OTgyODI=', 'avatar_url': 'https://avatars.githubusercontent.com/in/15368?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/github-actions%5Bbot%5D', 'html_url': 'https://github.com/apps/github-actions', 'followers_url': 'https://api.github.com/users/github-actions%5Bbot%5D/followers', 'following_url': 'https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}', 'gists_url': 'https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/github-actions%5Bbot%5D/subscriptions', 'organizations_url': 'https://api.github.com/users/github-actions%5Bbot%5D/orgs', 'repos_url': 'https://api.github.com/users/github-actions%5Bbot%5D/repos', 'events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}', 'received_events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/received_events', 'type': 'Bot', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/475/reactions', 'total_count': 123, '+1': 100, '-1': 0, 'laugh': 3, 'hooray': 2, 'confused': 1, 'heart': 10, 'rocket': 4, 'eyes': 3}",https://api.github.com/repos/ultralytics/yolov5/issues/475/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/318,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/318/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/318/comments,https://api.github.com/repos/ultralytics/yolov5/issues/318/events,https://github.com/ultralytics/yolov5/issues/318,652705750,MDU6SXNzdWU2NTI3MDU3NTA=,318,Model Ensembling Tutorial,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,108,2020-07-07T22:39:30Z,2024-10-20T14:35:00Z,,MEMBER,,"📚  This guide explains how to use YOLOv5 🚀 **model ensembling** during testing and inference for improved mAP and Recall. UPDATED 25 September 2022.

From https://www.sciencedirect.com/topics/computer-science/ensemble-modeling:
> Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used. The approach seeks the wisdom of crowds in making a prediction. Even though the ensemble model has multiple base models within the model, it acts and performs as a single model.


## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```

## Test Normally

Before ensembling we want to establish the baseline performance of a single model. This command tests YOLOv5x on COCO val2017 at image size 640 pixels. `yolov5x.pt` is the largest and most accurate model available. Other options are `yolov5s.pt`, `yolov5m.pt` and `yolov5l.pt`, or you own checkpoint from training a custom dataset `./weights/best.pt`. For details on all available models please see our README [table](https://github.com/ultralytics/yolov5#pretrained-checkpoints).
```bash
$ python val.py --weights yolov5x.pt --data coco.yaml --img 640 --half
```

Output:
```shell
val: data=./data/coco.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True
YOLOv5 🚀 v5.0-267-g6a3ee7c torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)

Fusing layers... 
Model Summary: 476 layers, 87730285 parameters, 0 gradients

val: Scanning '../datasets/coco/val2017' images and labels...4952 found, 48 missing, 0 empty, 0 corrupted: 100% 5000/5000 [00:01<00:00, 2846.03it/s]
val: New cache created: ../datasets/coco/val2017.cache
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [02:30<00:00,  1.05it/s]
                 all       5000      36335      0.746      0.626       0.68       0.49
Speed: 0.1ms pre-process, 22.4ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)  # <--- baseline speed

Evaluating pycocotools mAP... saving runs/val/exp/yolov5x_predictions.json...
...
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504  # <--- baseline mAP
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681  # <--- baseline mAR
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826
```

## Ensemble Test

Multiple pretraind models may be ensembled togethor at test and inference time by simply appending extra models to the `--weights` argument in any existing val.py or detect.py command. This example tests an ensemble of 2 models togethor:
- YOLOv5x
- YOLOv5l6

```bash
python val.py --weights yolov5x.pt yolov5l6.pt --data coco.yaml --img 640 --half
```

Output:
```shell
val: data=./data/coco.yaml, weights=['yolov5x.pt', 'yolov5l6.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True
YOLOv5 🚀 v5.0-267-g6a3ee7c torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)

Fusing layers... 
Model Summary: 476 layers, 87730285 parameters, 0 gradients  # Model 1
Fusing layers... 
Model Summary: 501 layers, 77218620 parameters, 0 gradients  # Model 2
Ensemble created with ['yolov5x.pt', 'yolov5l6.pt']  # Ensemble notice

val: Scanning '../datasets/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupted: 100% 5000/5000 [00:00<00:00, 49695545.02it/s]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [03:58<00:00,  1.52s/it]
                 all       5000      36335      0.747      0.637      0.692      0.502
Speed: 0.1ms pre-process, 39.5ms inference, 2.0ms NMS per image at shape (32, 3, 640, 640)  # <--- ensemble speed

Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json...
...
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515  # <--- ensemble mAP
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.557
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689  # <--- ensemble mAR
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.844
```

## Ensemble Inference

Append extra models to the `--weights` argument to run ensemble inference:
```bash
python detect.py --weights yolov5x.pt yolov5l6.pt --img 640 --source data/images
```

Output:
```bash
detect: weights=['yolov5x.pt', 'yolov5l6.pt'], source=data/images, imgsz=640, conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False
YOLOv5 🚀 v5.0-267-g6a3ee7c torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)

Fusing layers... 
Model Summary: 476 layers, 87730285 parameters, 0 gradients
Fusing layers... 
Model Summary: 501 layers, 77218620 parameters, 0 gradients
Ensemble created with ['yolov5x.pt', 'yolov5l6.pt']

image 1/2 /content/yolov5/data/images/bus.jpg: 640x512 4 persons, 1 bus, 1 tie, Done. (0.063s)
image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 3 persons, 2 ties, Done. (0.056s)
Results saved to runs/detect/exp2
Done. (0.223s)
```
<img src=""https://user-images.githubusercontent.com/26833433/124489091-ea4f9a00-ddb0-11eb-8ef1-d6f335c97f6f.jpg"" width=""500"">


## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.","{'login': 'github-actions[bot]', 'id': 41898282, 'node_id': 'MDM6Qm90NDE4OTgyODI=', 'avatar_url': 'https://avatars.githubusercontent.com/in/15368?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/github-actions%5Bbot%5D', 'html_url': 'https://github.com/apps/github-actions', 'followers_url': 'https://api.github.com/users/github-actions%5Bbot%5D/followers', 'following_url': 'https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}', 'gists_url': 'https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/github-actions%5Bbot%5D/subscriptions', 'organizations_url': 'https://api.github.com/users/github-actions%5Bbot%5D/orgs', 'repos_url': 'https://api.github.com/users/github-actions%5Bbot%5D/repos', 'events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}', 'received_events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/received_events', 'type': 'Bot', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/318/reactions', 'total_count': 60, '+1': 39, '-1': 0, 'laugh': 5, 'hooray': 4, 'confused': 0, 'heart': 7, 'rocket': 4, 'eyes': 1}",https://api.github.com/repos/ultralytics/yolov5/issues/318/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/304,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/304/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/304/comments,https://api.github.com/repos/ultralytics/yolov5/issues/304/events,https://github.com/ultralytics/yolov5/issues/304,651144770,MDU6SXNzdWU2NTExNDQ3NzA=,304,Pruning/Sparsity Tutorial,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,55,2020-07-05T20:59:23Z,2024-10-20T14:34:41Z,,MEMBER,,"📚 This guide explains how to apply **pruning** to YOLOv5 🚀 models. UPDATED 25 September 2022.

## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```

## Test Normally

Before pruning we want to establish a baseline performance to compare to. This command tests YOLOv5x on COCO val2017 at image size 640 pixels. `yolov5x.pt` is the largest and most accurate model available. Other options are `yolov5s.pt`, `yolov5m.pt` and `yolov5l.pt`, or you own checkpoint from training a custom dataset `./weights/best.pt`. For details on all available models please see our README [table](https://github.com/ultralytics/yolov5#pretrained-checkpoints).
```bash
$ python val.py --weights yolov5x.pt --data coco.yaml --img 640 --half
```

Output:
```shell
val: data=/content/yolov5/data/coco.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False
YOLOv5 🚀 v6.0-224-g4c40933 torch 1.10.0+cu111 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)

Fusing layers... 
Model Summary: 444 layers, 86705005 parameters, 0 gradients
val: Scanning '/content/datasets/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100% 5000/5000 [00:00<?, ?it/s]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [01:12<00:00,  2.16it/s]
                 all       5000      36335      0.732      0.628      0.683      0.496
Speed: 0.1ms pre-process, 5.2ms inference, 1.7ms NMS per image at shape (32, 3, 640, 640)  # <--- base speed

Evaluating pycocotools mAP... saving runs/val/exp2/yolov5x_predictions.json...
...
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507  # <--- base mAP
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.381
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.829
Results saved to runs/val/exp
```

## Test YOLOv5x on COCO (0.30 sparsity)

We repeat the above test with a pruned model by using the `torch_utils.prune()` command. We update `val.py` to prune YOLOv5x to 0.3 sparsity:

<img width=""894"" alt=""Screenshot 2022-02-02 at 22 54 18"" src=""https://user-images.githubusercontent.com/26833433/152243799-b0ac2777-b1a8-47b1-801a-2e4c93c06ead.png"">

30% pruned output:
```bash
val: data=/content/yolov5/data/coco.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False
YOLOv5 🚀 v6.0-224-g4c40933 torch 1.10.0+cu111 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)

Fusing layers... 
Model Summary: 444 layers, 86705005 parameters, 0 gradients
Pruning model...  0.3 global sparsity
val: Scanning '/content/datasets/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100% 5000/5000 [00:00<?, ?it/s]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [01:11<00:00,  2.19it/s]
                 all       5000      36335      0.724      0.614      0.671      0.478
Speed: 0.1ms pre-process, 5.2ms inference, 1.7ms NMS per image at shape (32, 3, 640, 640)  # <--- prune mAP

Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json...
...
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489  # <--- prune mAP
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.537
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.334
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.542
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.722
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
Results saved to runs/val/exp3
```

In the results we can observe that we have achieved a **sparsity of 30%** in our model after pruning, which means that 30% of the model's weight parameters in `nn.Conv2d` layers are equal to 0. **Inference time is essentially unchanged**, while the model's **AP and AR scores a slightly reduced**.


## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.","{'login': 'github-actions[bot]', 'id': 41898282, 'node_id': 'MDM6Qm90NDE4OTgyODI=', 'avatar_url': 'https://avatars.githubusercontent.com/in/15368?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/github-actions%5Bbot%5D', 'html_url': 'https://github.com/apps/github-actions', 'followers_url': 'https://api.github.com/users/github-actions%5Bbot%5D/followers', 'following_url': 'https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}', 'gists_url': 'https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/github-actions%5Bbot%5D/subscriptions', 'organizations_url': 'https://api.github.com/users/github-actions%5Bbot%5D/orgs', 'repos_url': 'https://api.github.com/users/github-actions%5Bbot%5D/repos', 'events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}', 'received_events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/received_events', 'type': 'Bot', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/304/reactions', 'total_count': 22, '+1': 12, '-1': 0, 'laugh': 2, 'hooray': 2, 'confused': 0, 'heart': 1, 'rocket': 4, 'eyes': 1}",https://api.github.com/repos/ultralytics/yolov5/issues/304/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/303,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/303/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/303/comments,https://api.github.com/repos/ultralytics/yolov5/issues/303/events,https://github.com/ultralytics/yolov5/issues/303,651123483,MDU6SXNzdWU2NTExMjM0ODM=,303,Test-Time Augmentation (TTA) Tutorial,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,21,2020-07-05T18:43:52Z,2023-01-23T21:42:27Z,,MEMBER,,"📚 This guide explains how to use Test Time Augmentation (TTA) during testing and inference for improved mAP and Recall with YOLOv5 🚀. UPDATED 25 September 2022.

## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```

## Test Normally

Before trying TTA we want to establish a baseline performance to compare to. This command tests YOLOv5x on COCO val2017 at image size 640 pixels. `yolov5x.pt` is the largest and most accurate model available. Other options are `yolov5s.pt`, `yolov5m.pt` and `yolov5l.pt`, or you own checkpoint from training a custom dataset `./weights/best.pt`. For details on all available models please see our README [table](https://github.com/ultralytics/yolov5#pretrained-checkpoints).
```bash
$ python val.py --weights yolov5x.pt --data coco.yaml --img 640 --half
```

Output:
```shell
val: data=./data/coco.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True
YOLOv5 🚀 v5.0-267-g6a3ee7c torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)

Fusing layers... 
Model Summary: 476 layers, 87730285 parameters, 0 gradients

val: Scanning '../datasets/coco/val2017' images and labels...4952 found, 48 missing, 0 empty, 0 corrupted: 100% 5000/5000 [00:01<00:00, 2846.03it/s]
val: New cache created: ../datasets/coco/val2017.cache
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [02:30<00:00,  1.05it/s]
                 all       5000      36335      0.746      0.626       0.68       0.49
Speed: 0.1ms pre-process, 22.4ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)  # <--- baseline speed

Evaluating pycocotools mAP... saving runs/val/exp/yolov5x_predictions.json...
...
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504  # <--- baseline mAP
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681  # <--- baseline mAR
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826
```

## Test with TTA
Append `--augment` to any existing `val.py` command to enable TTA, and increase the image size by about 30% for improved results. Note that inference with TTA enabled will typically take about 2-3X the time of normal inference as the images are being left-right flipped and processed at 3 different resolutions, with the outputs merged before NMS. Part of the speed decrease is simply due to larger image sizes (832 vs 640), while part is due to the actual TTA operations.
```bash
$ python val.py --weights yolov5x.pt --data coco.yaml --img 832 --augment --half
```

Output:
```shell
val: data=./data/coco.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=832, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=True, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True
YOLOv5 🚀 v5.0-267-g6a3ee7c torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)

Fusing layers... 
/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Model Summary: 476 layers, 87730285 parameters, 0 gradients
val: Scanning '../datasets/coco/val2017' images and labels...4952 found, 48 missing, 0 empty, 0 corrupted: 100% 5000/5000 [00:01<00:00, 2885.61it/s]
val: New cache created: ../datasets/coco/val2017.cache
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [07:29<00:00,  2.86s/it]
                 all       5000      36335      0.718      0.656      0.695      0.503
Speed: 0.2ms pre-process, 80.6ms inference, 2.7ms NMS per image at shape (32, 3, 832, 832)  # <--- TTA speed

Evaluating pycocotools mAP... saving runs/val/exp2/yolov5x_predictions.json...
...
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516  # <--- TTA mAP
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.701
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.388
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.696  # <--- TTA mAR
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.744
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.833
```

## Inference with TTA

`detect.py` TTA inference operates identically to `val.py` TTA: simply append `--augment` to any existing `detect.py` command:
```bash
$ python detect.py --weights yolov5s.pt --img 832 --source data/images --augment
```

Output:
```bash
detect: weights=['yolov5s.pt'], source=data/images, imgsz=832, conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False
YOLOv5 🚀 v5.0-267-g6a3ee7c torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)

Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt to yolov5s.pt...
100% 14.1M/14.1M [00:00<00:00, 81.9MB/s]

Fusing layers... 
Model Summary: 224 layers, 7266973 parameters, 0 gradients
image 1/2 /content/yolov5/data/images/bus.jpg: 832x640 4 persons, 1 bus, 1 fire hydrant, Done. (0.029s)
image 2/2 /content/yolov5/data/images/zidane.jpg: 480x832 3 persons, 3 ties, Done. (0.024s)
Results saved to runs/detect/exp
Done. (0.156s)
```

<img src=""https://user-images.githubusercontent.com/26833433/124491703-dbb6b200-ddb3-11eb-8b57-ed0d58d0d8b4.jpg"" width=""500"">


### PyTorch Hub TTA

TTA is automatically integrated into all [YOLOv5 PyTorch Hub](https://pytorch.org/hub/ultralytics_yolov5) models, and can be accessed by passing `augment=True` at inference time.
```python
import torch

# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5x, custom

# Images
img = 'https://ultralytics.com/images/zidane.jpg'  # or file, PIL, OpenCV, numpy, multiple

# Inference
results = model(img, augment=True)  # <--- TTA inference

# Results
results.print()  # or .show(), .save(), .crop(), .pandas(), etc.
```

### Customize 

You can customize the TTA ops applied in the YOLOv5 `forward_augment()` method here:
https://github.com/ultralytics/yolov5/blob/8c6f9e15bfc0000d18b976a95b9d7c17d407ec91/models/yolo.py#L125-L137


## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.","{'login': 'github-actions[bot]', 'id': 41898282, 'node_id': 'MDM6Qm90NDE4OTgyODI=', 'avatar_url': 'https://avatars.githubusercontent.com/in/15368?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/github-actions%5Bbot%5D', 'html_url': 'https://github.com/apps/github-actions', 'followers_url': 'https://api.github.com/users/github-actions%5Bbot%5D/followers', 'following_url': 'https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}', 'gists_url': 'https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/github-actions%5Bbot%5D/subscriptions', 'organizations_url': 'https://api.github.com/users/github-actions%5Bbot%5D/orgs', 'repos_url': 'https://api.github.com/users/github-actions%5Bbot%5D/repos', 'events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}', 'received_events_url': 'https://api.github.com/users/github-actions%5Bbot%5D/received_events', 'type': 'Bot', 'user_view_type': 'public', 'site_admin': False}","{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/303/reactions', 'total_count': 49, '+1': 34, '-1': 0, 'laugh': 3, 'hooray': 5, 'confused': 0, 'heart': 1, 'rocket': 5, 'eyes': 1}",https://api.github.com/repos/ultralytics/yolov5/issues/303/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/251,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/251/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/251/comments,https://api.github.com/repos/ultralytics/yolov5/issues/251/events,https://github.com/ultralytics/yolov5/issues/251,648548660,MDU6SXNzdWU2NDg1NDg2NjA=,251,"TFLite, ONNX, CoreML, TensorRT Export","{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,409,2020-06-30T22:59:28Z,2024-10-20T14:33:34Z,,MEMBER,,"📚 This guide explains how to export a trained YOLOv5 🚀 model from PyTorch to ONNX and TorchScript formats. UPDATED 8 December 2022.

## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```

For [TensorRT](https://developer.nvidia.com/tensorrt) export example (requires GPU) see our Colab [notebook](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb#scrollTo=VTRwsvA9u7ln&line=2&uniqifier=1) appendix section. <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a>

## Formats

YOLOv5 inference is officially supported in 11 formats:

💡 ProTip: Export to ONNX or OpenVINO for up to 3x CPU speedup. See [CPU Benchmarks](https://github.com/ultralytics/yolov5/pull/6613).
💡 ProTip: Export to TensorRT for up to 5x GPU speedup. See [GPU Benchmarks](https://github.com/ultralytics/yolov5/pull/6963).

Format                      | `export.py --include`         | Model
:---                        | --:                           | :--
[PyTorch](https://pytorch.org/)                     | -                             | `yolov5s.pt`
[TorchScript](https://pytorch.org/docs/stable/jit.html)                 | `torchscript`                 | `yolov5s.torchscript`
[ONNX](https://onnx.ai/)                        | `onnx`                        | `yolov5s.onnx`
[OpenVINO](https://docs.openvino.ai/latest/index.html)                    | `openvino`                    | `yolov5s_openvino_model/`
[TensorRT](https://developer.nvidia.com/tensorrt)                    | `engine`                      | `yolov5s.engine`
[CoreML](https://github.com/apple/coremltools)                      | `coreml`                      | `yolov5s.mlmodel`
[TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model)       | `saved_model`                 | `yolov5s_saved_model/`
[TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph)         | `pb`                          | `yolov5s.pb`
[TensorFlow Lite](https://www.tensorflow.org/lite)             | `tflite`                      | `yolov5s.tflite`
[TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`                     | `yolov5s_edgetpu.tflite`
[TensorFlow.js](https://www.tensorflow.org/js)               | `tfjs`                        | `yolov5s_web_model/`
[PaddlePaddle](https://github.com/PaddlePaddle)               | `paddle`                        | `yolov5s_paddle_model/`


## Benchmarks

Benchmarks below run on a Colab Pro with the YOLOv5 tutorial notebook <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a>. To reproduce:
```bash
python benchmarks.py --weights yolov5s.pt --imgsz 640 --device 0
```

### Colab Pro V100 GPU

```
benchmarks: weights=/content/yolov5/yolov5s.pt, imgsz=640, batch_size=1, data=/content/yolov5/data/coco128.yaml, device=0, half=False, test=False
Checking setup...
YOLOv5 🚀 v6.1-135-g7926afc torch 1.10.0+cu111 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)
Setup complete ✅ (8 CPUs, 51.0 GB RAM, 46.7/166.8 GB disk)

Benchmarks complete (458.07s)
                   Format  mAP@0.5:0.95  Inference time (ms)
0                 PyTorch        0.4623                10.19
1             TorchScript        0.4623                 6.85
2                    ONNX        0.4623                14.63
3                OpenVINO           NaN                  NaN
4                TensorRT        0.4617                 1.89
5                  CoreML           NaN                  NaN
6   TensorFlow SavedModel        0.4623                21.28
7     TensorFlow GraphDef        0.4623                21.22
8         TensorFlow Lite           NaN                  NaN
9     TensorFlow Edge TPU           NaN                  NaN
10          TensorFlow.js           NaN                  NaN
```

### Colab Pro CPU

```
benchmarks: weights=/content/yolov5/yolov5s.pt, imgsz=640, batch_size=1, data=/content/yolov5/data/coco128.yaml, device=cpu, half=False, test=False
Checking setup...
YOLOv5 🚀 v6.1-135-g7926afc torch 1.10.0+cu111 CPU
Setup complete ✅ (8 CPUs, 51.0 GB RAM, 41.5/166.8 GB disk)

Benchmarks complete (241.20s)
                   Format  mAP@0.5:0.95  Inference time (ms)
0                 PyTorch        0.4623               127.61
1             TorchScript        0.4623               131.23
2                    ONNX        0.4623                69.34
3                OpenVINO        0.4623                66.52
4                TensorRT           NaN                  NaN
5                  CoreML           NaN                  NaN
6   TensorFlow SavedModel        0.4623               123.79
7     TensorFlow GraphDef        0.4623               121.57
8         TensorFlow Lite        0.4623               316.61
9     TensorFlow Edge TPU           NaN                  NaN
10          TensorFlow.js           NaN                  NaN
```

## Export a Trained YOLOv5 Model

This command exports a pretrained YOLOv5s model to TorchScript and ONNX formats. `yolov5s.pt` is the 'small' model, the second smallest model available. Other options are `yolov5n.pt`, `yolov5m.pt`, `yolov5l.pt` and `yolov5x.pt`, along with their P6 counterparts i.e. `yolov5s6.pt` or you own custom training checkpoint i.e. `runs/exp/weights/best.pt`. For details on all available models please see our README [table](https://github.com/ultralytics/yolov5#pretrained-checkpoints).
```bash
python export.py --weights yolov5s.pt --include torchscript onnx
```

💡 ProTip: Add `--half` to export models at FP16 half precision for smaller file sizes

Output:
```bash
export: data=data/coco128.yaml, weights=['yolov5s.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, train=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']
YOLOv5 🚀 v6.2-104-ge3e5122 Python-3.7.13 torch-1.12.1+cu113 CPU

Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...
100% 14.1M/14.1M [00:00<00:00, 274MB/s]

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients

PyTorch: starting from yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)

TorchScript: starting export with torch 1.12.1+cu113...
TorchScript: export success ✅ 1.7s, saved as yolov5s.torchscript (28.1 MB)

ONNX: starting export with onnx 1.12.0...
ONNX: export success ✅ 2.3s, saved as yolov5s.onnx (28.0 MB)

Export complete (5.5s)
Results saved to /content/yolov5
Detect:          python detect.py --weights yolov5s.onnx 
Validate:        python val.py --weights yolov5s.onnx 
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s.onnx')
Visualize:       https://netron.app/
```

The 3 exported models will be saved alongside the original PyTorch model:
<p align=""center""><img width=""700"" src=""https://user-images.githubusercontent.com/26833433/122827190-57a8f880-d2e4-11eb-860e-dbb7f9fc57fb.png""></p>

[Netron Viewer](https://github.com/lutzroeder/netron) is recommended for visualizing exported models:
<p align=""center""><img width=""850"" src=""https://user-images.githubusercontent.com/26833433/191003260-f94011a7-5b2e-4fe3-93c1-e1a935e0a728.png""></p>


## Exported Model Usage Examples

`detect.py` runs inference on exported models:
```bash
python detect.py --weights yolov5s.pt                 # PyTorch
                           yolov5s.torchscript        # TorchScript
                           yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                           yolov5s_openvino_model     # OpenVINO
                           yolov5s.engine             # TensorRT
                           yolov5s.mlmodel            # CoreML (macOS only)
                           yolov5s_saved_model        # TensorFlow SavedModel
                           yolov5s.pb                 # TensorFlow GraphDef
                           yolov5s.tflite             # TensorFlow Lite
                           yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                           yolov5s_paddle_model       # PaddlePaddle
```

`val.py` runs validation on exported models:
```bash
python val.py --weights yolov5s.pt                 # PyTorch
                        yolov5s.torchscript        # TorchScript
                        yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                        yolov5s_openvino_model     # OpenVINO
                        yolov5s.engine             # TensorRT
                        yolov5s.mlmodel            # CoreML (macOS Only)
                        yolov5s_saved_model        # TensorFlow SavedModel
                        yolov5s.pb                 # TensorFlow GraphDef
                        yolov5s.tflite             # TensorFlow Lite
                        yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                        yolov5s_paddle_model       # PaddlePaddle
```

Use PyTorch Hub with exported YOLOv5 models:
``` python
import torch

# Model
model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s.pt')
                                                       'yolov5s.torchscript ')       # TorchScript
                                                       'yolov5s.onnx')               # ONNX Runtime
                                                       'yolov5s_openvino_model')     # OpenVINO
                                                       'yolov5s.engine')             # TensorRT
                                                       'yolov5s.mlmodel')            # CoreML (macOS Only)
                                                       'yolov5s_saved_model')        # TensorFlow SavedModel
                                                       'yolov5s.pb')                 # TensorFlow GraphDef
                                                       'yolov5s.tflite')             # TensorFlow Lite
                                                       'yolov5s_edgetpu.tflite')     # TensorFlow Edge TPU
                                                       'yolov5s_paddle_model')       # PaddlePaddle

# Images
img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list

# Inference
results = model(img)

# Results
results.print()  # or .show(), .save(), .crop(), .pandas(), etc.
```

## OpenCV DNN inference

OpenCV inference with ONNX models:
```bash
python export.py --weights yolov5s.pt --include onnx

python detect.py --weights yolov5s.onnx --dnn  # detect
python val.py --weights yolov5s.onnx --dnn  # validate
```

## C++ Inference

YOLOv5 OpenCV DNN C++ inference on exported ONNX model examples:
- https://github.com/Hexmagic/ONNX-yolov5/blob/master/src/test.cpp
- https://github.com/doleron/yolov5-opencv-cpp-python

YOLOv5 OpenVINO C++ inference examples:
- https://github.com/dacquaviva/yolov5-openvino-cpp-python
- https://github.com/UNeedCryDear/yolov5-seg-opencv-dnn-cpp

## TensorFlow.js Web Browser Inference

- https://aukerul-shuvo.github.io/YOLOv5_TensorFlow-JS/

## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on macOS, Windows, and Ubuntu every 24 hours and on every commit.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/251/reactions', 'total_count': 212, '+1': 106, '-1': 0, 'laugh': 14, 'hooray': 22, 'confused': 0, 'heart': 35, 'rocket': 26, 'eyes': 9}",https://api.github.com/repos/ultralytics/yolov5/issues/251/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/36,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/36/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/36/comments,https://api.github.com/repos/ultralytics/yolov5/issues/36/events,https://github.com/ultralytics/yolov5/issues/36,636702522,MDU6SXNzdWU2MzY3MDI1MjI=,36,Load YOLOv5 from PyTorch Hub ⭐,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}, {'id': 2068758694, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njk0', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/enhancement', 'name': 'enhancement', 'color': 'a2eeef', 'default': True, 'description': 'New feature or request'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,317,2020-06-11T04:14:04Z,2024-10-20T14:28:58Z,,MEMBER,,"📚 This guide explains how to load YOLOv5 🚀 from PyTorch Hub https://pytorch.org/hub/ultralytics_yolov5. See YOLOv5 [Docs](https://docs.ultralytics.com) for additional details. UPDATED 26 March 2023.

## Before You Start

Install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt
```

💡 ProTip: Cloning [https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5) is **not** required 😃

## Load YOLOv5 with PyTorch Hub

### Simple Example

This example loads a pretrained YOLOv5s model from PyTorch Hub as `model` and passes an image for inference. `'yolov5s'` is the lightest and fastest YOLOv5 model. For details on all available models please see the [README](https://github.com/ultralytics/yolov5#pretrained-checkpoints).
```python
import torch

# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

# Image
im = 'https://ultralytics.com/images/zidane.jpg'

# Inference
results = model(im)

results.pandas().xyxy[0]
#      xmin    ymin    xmax   ymax  confidence  class    name
# 0  749.50   43.50  1148.0  704.5    0.874023      0  person
# 1  433.50  433.50   517.5  714.5    0.687988     27     tie
# 2  114.75  195.75  1095.0  708.0    0.624512      0  person
# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie
```


### Detailed Example

This example shows **batched inference** with **PIL** and **OpenCV** image sources. `results` can be **printed** to console, **saved** to `runs/hub`, **showed** to screen on supported environments, and returned as **tensors** or **pandas** dataframes.
```python
import cv2
import torch
from PIL import Image

# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

# Images
for f in 'zidane.jpg', 'bus.jpg':
    torch.hub.download_url_to_file('https://ultralytics.com/images/' + f, f)  # download 2 images
im1 = Image.open('zidane.jpg')  # PIL image
im2 = cv2.imread('bus.jpg')[..., ::-1]  # OpenCV image (BGR to RGB)

# Inference
results = model([im1, im2], size=640) # batch of images

# Results
results.print()  
results.save()  # or .show()

results.xyxy[0]  # im1 predictions (tensor)
results.pandas().xyxy[0]  # im1 predictions (pandas)
#      xmin    ymin    xmax   ymax  confidence  class    name
# 0  749.50   43.50  1148.0  704.5    0.874023      0  person
# 1  433.50  433.50   517.5  714.5    0.687988     27     tie
# 2  114.75  195.75  1095.0  708.0    0.624512      0  person
# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie
```
<img src=""https://user-images.githubusercontent.com/26833433/124915064-62a49e00-dff1-11eb-86b3-a85b97061afb.jpg"" width=""500"">  <img src=""https://user-images.githubusercontent.com/26833433/124915055-60424400-dff1-11eb-9055-24585b375a29.jpg"" width=""300"">

For all inference options see YOLOv5 `AutoShape()` forward method:
https://github.com/ultralytics/yolov5/blob/30e4c4f09297b67afedf8b2bcd851833ddc9dead/models/common.py#L243-L252

### Inference Settings
YOLOv5 models contain various inference attributes such as **confidence threshold**, **IoU threshold**, etc. which can be set by:
```python
model.conf = 0.25  # NMS confidence threshold
      iou = 0.45  # NMS IoU threshold
      agnostic = False  # NMS class-agnostic
      multi_label = False  # NMS multiple labels per box
      classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs
      max_det = 1000  # maximum number of detections per image
      amp = False  # Automatic Mixed Precision (AMP) inference

results = model(im, size=320)  # custom inference size
```


### Device
Models can be transferred to any device after creation:
```python
model.cpu()  # CPU
model.cuda()  # GPU
model.to(device)  # i.e. device=torch.device(0)
```

Models can also be created directly on any `device`:
```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', device='cpu')  # load on CPU
```

💡 ProTip: Input images are automatically transferred to the correct model device before inference.

### Silence Outputs
Models can be loaded silently with `_verbose=False`:
```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', _verbose=False)  # load silently
```

### Input Channels
To load a pretrained YOLOv5s model with 4 input channels rather than the default 3:
```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', channels=4)
```
In this case the model will be composed of pretrained weights **except for** the very first input layer, which is no longer the same shape as the pretrained input layer. The input layer will remain initialized by random weights.

### Number of Classes
To load a pretrained YOLOv5s model with 10 output classes rather than the default 80:
```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes=10)
```
In this case the model will be composed of pretrained weights **except for** the output layers, which are no longer the same shape as the pretrained output layers. The output layers will remain initialized by random weights.

### Force Reload
If you run into problems with the above steps, setting `force_reload=True` may help by discarding the existing cache and force a fresh download of the latest YOLOv5 version from PyTorch Hub.
```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # force reload
```

### Screenshot Inference
To run inference on your desktop screen:
```python
import torch
from PIL import ImageGrab

# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

# Image
im = ImageGrab.grab()  # take a screenshot

# Inference
results = model(im)
```

### Multi-GPU Inference

YOLOv5 models can be be loaded to multiple GPUs in parallel with threaded inference:

```python
import torch
import threading

def run(model, im):
  results = model(im)
  results.save()

# Models
model0 = torch.hub.load('ultralytics/yolov5', 'yolov5s', device=0)
model1 = torch.hub.load('ultralytics/yolov5', 'yolov5s', device=1)

# Inference
threading.Thread(target=run, args=[model0, 'https://ultralytics.com/images/zidane.jpg'], daemon=True).start()
threading.Thread(target=run, args=[model1, 'https://ultralytics.com/images/bus.jpg'], daemon=True).start()
```

### Training
To load a YOLOv5 model for training rather than inference, set `autoshape=False`. To load a model with randomly initialized weights (to train from scratch) use `pretrained=False`. You must provide your own training script in this case. Alternatively see  our YOLOv5 [Train Custom Data Tutorial](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data) for model training.
```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', autoshape=False)  # load pretrained
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', autoshape=False, pretrained=False)  # load scratch
```

### Base64 Results
For use with API services. See https://github.com/ultralytics/yolov5/pull/2291 and [Flask REST API](https://github.com/ultralytics/yolov5/tree/master/utils/flask_rest_api) example for details.
```python
results = model(im)  # inference

results.ims # array of original images (as np array) passed to model for inference
results.render()  # updates results.ims with boxes and labels
for im in results.ims:
    buffered = BytesIO()
    im_base64 = Image.fromarray(im)
    im_base64.save(buffered, format=""JPEG"")
    print(base64.b64encode(buffered.getvalue()).decode('utf-8'))  # base64 encoded image with results
```

### Cropped Results
Results can be returned and saved as detection crops:
```python
results = model(im)  # inference
crops = results.crop(save=True)  # cropped detections dictionary
```

### Pandas Results
Results can be returned as [Pandas DataFrames](https://pandas.pydata.org/):
```python
results = model(im)  # inference
results.pandas().xyxy[0]  # Pandas DataFrame
```
<details>
  <summary>Pandas Output (click to expand)</summary>

```python
print(results.pandas().xyxy[0])
#      xmin    ymin    xmax   ymax  confidence  class    name
# 0  749.50   43.50  1148.0  704.5    0.874023      0  person
# 1  433.50  433.50   517.5  714.5    0.687988     27     tie
# 2  114.75  195.75  1095.0  708.0    0.624512      0  person
# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie
```
</details>

### Sorted Results
Results can be sorted by column, i.e. to sort license plate digit detection left-to-right (x-axis):
```python
results = model(im)  # inference
results.pandas().xyxy[0].sort_values('xmin')  # sorted left-right
```

### Box-Cropped Results
Results can be returned and saved as detection crops:
```python
results = model(im)  # inference
crops = results.crop(save=True)  # cropped detections dictionary
```

### JSON Results
Results can be returned in JSON format once converted to `.pandas()` dataframes using the `.to_json()` method. The JSON format can be modified using the `orient` argument. See pandas `.to_json()` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html) for details.
```python
results = model(ims)  # inference
results.pandas().xyxy[0].to_json(orient=""records"")  # JSON img1 predictions
```
<details>
  <summary>JSON Output (click to expand)</summary>

```json
[
{""xmin"":749.5,""ymin"":43.5,""xmax"":1148.0,""ymax"":704.5,""confidence"":0.8740234375,""class"":0,""name"":""person""},
{""xmin"":433.5,""ymin"":433.5,""xmax"":517.5,""ymax"":714.5,""confidence"":0.6879882812,""class"":27,""name"":""tie""},
{""xmin"":115.25,""ymin"":195.75,""xmax"":1096.0,""ymax"":708.0,""confidence"":0.6254882812,""class"":0,""name"":""person""},
{""xmin"":986.0,""ymin"":304.0,""xmax"":1028.0,""ymax"":420.0,""confidence"":0.2873535156,""class"":27,""name"":""tie""}
]
  ```
</details>

## Custom Models
This example loads a custom 20-class [VOC](https://github.com/ultralytics/yolov5/blob/master/data/voc.yaml)-trained YOLOv5s model `'best.pt'` with PyTorch Hub.
```python
model = torch.hub.load('ultralytics/yolov5', 'custom', path='path/to/best.pt')  # local model
model = torch.hub.load('path/to/yolov5', 'custom', path='path/to/best.pt', source='local')  # local repo
```

## TensorRT, ONNX and OpenVINO Models

PyTorch Hub supports inference on most YOLOv5 export formats, including custom trained models. See [TFLite, ONNX, CoreML, TensorRT Export tutorial](https://github.com/ultralytics/yolov5/issues/251) for details on exporting models.

💡 ProTip: **TensorRT** may be up to 2-5X faster than PyTorch on [**GPU benchmarks**](https://github.com/ultralytics/yolov5/pull/6963)
💡 ProTip: **ONNX** and **OpenVINO** may be up to 2-3X faster than PyTorch on [**CPU benchmarks**](https://github.com/ultralytics/yolov5/pull/6613)

```python
model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5s.pt')  # PyTorch
                                                            'yolov5s.torchscript')  # TorchScript
                                                            'yolov5s.onnx')  # ONNX
                                                            'yolov5s_openvino_model/')  # OpenVINO
                                                            'yolov5s.engine')  # TensorRT
                                                            'yolov5s.mlmodel')  # CoreML (macOS-only)
                                                            'yolov5s.tflite')  # TFLite
                                                            'yolov5s_paddle_model/')  # PaddlePaddle
```

## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/google_cloud_quickstart_tutorial/)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/aws_quickstart_tutorial/)
- **Docker Image**. See [Docker Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/docker_image_quickstart_tutorial/) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/36/reactions', 'total_count': 297, '+1': 179, '-1': 0, 'laugh': 17, 'hooray': 25, 'confused': 0, 'heart': 34, 'rocket': 30, 'eyes': 12}",https://api.github.com/repos/ultralytics/yolov5/issues/36/timeline,,,,
https://api.github.com/repos/ultralytics/yolov5/issues/12,https://api.github.com/repos/ultralytics/yolov5,https://api.github.com/repos/ultralytics/yolov5/issues/12/labels{/name},https://api.github.com/repos/ultralytics/yolov5/issues/12/comments,https://api.github.com/repos/ultralytics/yolov5/issues/12/events,https://github.com/ultralytics/yolov5/issues/12,630186295,MDU6SXNzdWU2MzAxODYyOTU=,12,Train Custom Data Tutorial ⭐,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'id': 2068758692, 'node_id': 'MDU6TGFiZWwyMDY4NzU4Njky', 'url': 'https://api.github.com/repos/ultralytics/yolov5/labels/documentation', 'name': 'documentation', 'color': '0075ca', 'default': True, 'description': 'Improvements or additions to documentation'}]",open,False,"{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}","[{'login': 'glenn-jocher', 'id': 26833433, 'node_id': 'MDQ6VXNlcjI2ODMzNDMz', 'avatar_url': 'https://avatars.githubusercontent.com/u/26833433?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/glenn-jocher', 'html_url': 'https://github.com/glenn-jocher', 'followers_url': 'https://api.github.com/users/glenn-jocher/followers', 'following_url': 'https://api.github.com/users/glenn-jocher/following{/other_user}', 'gists_url': 'https://api.github.com/users/glenn-jocher/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/glenn-jocher/subscriptions', 'organizations_url': 'https://api.github.com/users/glenn-jocher/orgs', 'repos_url': 'https://api.github.com/users/glenn-jocher/repos', 'events_url': 'https://api.github.com/users/glenn-jocher/events{/privacy}', 'received_events_url': 'https://api.github.com/users/glenn-jocher/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}]",,214,2020-06-03T17:32:57Z,2024-12-10T09:10:07Z,,MEMBER,,"📚 This guide explains how to train your own **custom dataset** with YOLOv5 🚀. See YOLOv5 [Docs](https://docs.ultralytics.com/yolov5) for additional details. UPDATED 13 April 2023.


## Before You Start

Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) in a [**Python>=3.7.0**](https://www.python.org/) environment, including [**PyTorch>=1.7**](https://pytorch.org/get-started/locally/). [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data) download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).

```bash
git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
```

## Train On Custom Data

<a href=""https://bit.ly/ultralytics_hub"" target=""_blank"">
<img width=""100%"" src=""https://github.com/ultralytics/assets/raw/main/im/integrations-loop.png""></a>
<br>
<br>

Creating a custom model to detect your objects is an iterative process of collecting and organizing images, labeling your objects of interest, training a model, deploying it into the wild to make predictions, and then using that deployed model to collect examples of edge cases to repeat and improve.

### 1. Create Dataset

YOLOv5 models must be trained on labelled data in order to learn classes of objects in that data. There are two options for creating your dataset before you start training:

<details open markdown>
<summary>Use <a href=""https://roboflow.com/?ref=ultralytics"">Roboflow</a> to create your dataset in YOLO format  ⭐</summary>

### 1.1 Collect Images

Your model will learn by example. Training on images similar to the ones it will see in the wild is of the utmost importance. Ideally, you will collect a wide variety of images from the same configuration (camera, angle, lighting, etc.) as you will ultimately deploy your project.

If this is not possible, you can start from [a public dataset](https://universe.roboflow.com/?ref=ultralytics) to train your initial model and then [sample images from the wild during inference](https://blog.roboflow.com/computer-vision-active-learning-tips/?ref=ultralytics) to improve your dataset and model iteratively.

### 1.2 Create Labels

Once you have collected images, you will need to annotate the objects of interest to create a ground truth for your model to learn from.

<p align=""center""><a href=""https://app.roboflow.com/?model=yolov5&ref=ultralytics"" title=""Create a Free Roboflow Account""><img width=""450"" src=""https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/6152a275ad4b4ac20cd2e21a_roboflow-annotate.gif"" /></a></p>

[Roboflow Annotate](https://roboflow.com/annotate?ref=ultralytics) is a simple
web-based tool for managing and labeling your images with your team and exporting
them in [YOLOv5's annotation format](https://roboflow.com/formats/yolov5-pytorch-txt?ref=ultralytics).

### 1.3 Prepare Dataset for YOLOv5

Whether you [label your images with Roboflow](https://roboflow.com/annotate?ref=ultralytics) or not, you can use it to convert your dataset into YOLO format, create a YOLOv5 YAML configuration file, and host it for importing into your training script.

[Create a free Roboflow account](https://app.roboflow.com/?model=yolov5&ref=ultralytics)
and upload your dataset to a `Public` workspace, label any unannotated images,
then generate and export a version of your dataset in `YOLOv5 Pytorch` format.

Note: YOLOv5 does online augmentation during training, so we do not recommend
applying any augmentation steps in Roboflow for training with YOLOv5. But we
recommend applying the following preprocessing steps:

<p align=""center""><img width=""450"" src=""https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/6152a273477fccf42a0fd3d6_roboflow-preprocessing.png"" title=""Recommended Preprocessing Steps"" /></p>

* **Auto-Orient** - to strip EXIF orientation from your images.
* **Resize (Stretch)** - to the square input size of your model (640x640 is the YOLOv5 default).

Generating a version will give you a point in time snapshot of your dataset so
you can always go back and compare your future model training runs against it,
even if you add more images or change its configuration later.

<p align=""center""><img width=""450"" src=""https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/6152a2733fd1da943619934e_roboflow-export.png"" title=""Export in YOLOv5 Format"" /></p>

Export in `YOLOv5 Pytorch` format, then copy the snippet into your training
script or notebook to download your dataset.

<p align=""center""><img width=""450"" src=""https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/6152a273a92e4f5cb72594df_roboflow-snippet.png"" title=""Roboflow dataset download snippet"" /></p>

Now continue with `2. Select a Model`.
</details>

<details>
<summary>Or manually prepare your dataset</summary>

### 1.1 Create dataset.yaml

[COCO128](https://www.kaggle.com/ultralytics/coco128) is an example small tutorial dataset composed of the first 128 images in [COCO](http://cocodataset.org/#home) train2017. These same 128 images are used for both training and validation to verify our training pipeline is capable of overfitting. [data/coco128.yaml](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), shown below, is the dataset config file that defines 1) the dataset root directory `path` and relative paths to `train` / `val` / `test` image directories (or *.txt files with image paths) and 2) a class `names` dictionary:
```yaml
# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../datasets/coco128  # dataset root dir
train: images/train2017  # train images (relative to 'path') 128 images
val: images/train2017  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes (80 COCO classes)
names:
  0: person
  1: bicycle
  2: car
  ...
  77: teddy bear
  78: hair drier
  79: toothbrush
```

### 1.2 Create Labels

After using an annotation tool to label your images, export your labels to **YOLO format**, with one `*.txt` file per image (if no objects in image, no `*.txt` file is required). The `*.txt` file specifications are:

- One row per object
- Each row is `class x_center y_center width height` format.
- Box coordinates must be in **normalized xywh** format (from 0 - 1). If your boxes are in pixels, divide `x_center` and `width` by image width, and `y_center` and `height` by image height.
- Class numbers are zero-indexed (start from 0).

<p align=""center""><img width=""750"" src=""https://user-images.githubusercontent.com/26833433/91506361-c7965000-e886-11ea-8291-c72b98c25eec.jpg""></p>

The label file corresponding to the above image contains 2 persons (class `0`) and a tie (class `27`):

<p align=""center""><img width=""428"" src=""https://user-images.githubusercontent.com/26833433/112467037-d2568c00-8d66-11eb-8796-55402ac0d62f.png""></p>


### 1.3 Organize Directories

Organize your train and val images and labels according to the example below. YOLOv5 assumes  `/coco128` is inside a `/datasets` directory **next to** the `/yolov5` directory. **YOLOv5 locates labels automatically for each image** by replacing the last instance of `/images/` in each image path with `/labels/`. For example:
```bash
../datasets/coco128/images/im0.jpg  # image
../datasets/coco128/labels/im0.txt  # label
```

<p align=""center""><img width=""700"" src=""https://user-images.githubusercontent.com/26833433/134436012-65111ad1-9541-4853-81a6-f19a3468b75f.png""></p>

</details>

### 2. Select a Model

Select a pretrained model to start training from. Here we select [YOLOv5s](https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml), the second-smallest and fastest model available. See our README [table](https://github.com/ultralytics/yolov5#pretrained-checkpoints) for a full comparison of all models.

<p align=""center""><img width=""800"" alt=""YOLOv5 Models"" src=""https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png""></p>

### 3. Train

Train a YOLOv5s model on COCO128 by specifying dataset, batch-size, image size and either pretrained `--weights yolov5s.pt` (recommended), or randomly initialized `--weights '' --cfg yolov5s.yaml` (not recommended). Pretrained weights are auto-downloaded from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases).

```bash
# Train YOLOv5s on COCO128 for 3 epochs
$ python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt
```

💡 ProTip: Add `--cache ram` or `--cache disk` to speed up training (requires significant RAM/disk resources).  
💡 ProTip: Always train from a local dataset. Mounted or network drives like Google Drive will be very slow. 

All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc. For more details see the Training section of our tutorial notebook. <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>

### 4. Visualize

#### Comet Logging and Visualization 🌟 NEW

[Comet](https://bit.ly/yolov5-readme-comet) is now fully integrated with YOLOv5. Track and visualize model metrics in real time, save your hyperparameters, datasets, and model checkpoints, and visualize your model predictions with [Comet Custom Panels](https://bit.ly/yolov5-colab-comet-panels)! Comet makes sure you never lose track of your work and makes it easy to share results and collaborate across teams of all sizes! 

Getting started is easy:
```shell
pip install comet_ml  # 1. install
export COMET_API_KEY=<Your API Key>  # 2. paste API key
python train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt  # 3. train
```

To learn more about all of the supported Comet features for this integration, check out the [Comet Tutorial](https://github.com/ultralytics/yolov5/tree/master/utils/loggers/comet). If you'd like to learn more about Comet, head over to our [documentation](https://bit.ly/yolov5-colab-comet-docs). Get started by trying out the Comet Colab Notebook:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1RG0WOQyxlDlo5Km8GogJpIEJlg_5lyYO?usp=sharing)

<img width=""1920"" alt=""yolo-ui"" src=""https://user-images.githubusercontent.com/26833433/202851203-164e94e1-2238-46dd-91f8-de020e9d6b41.png"">

#### ClearML Logging and Automation 🌟 NEW

[ClearML](https://cutt.ly/yolov5-notebook-clearml) is completely integrated into YOLOv5 to track your experimentation, manage dataset versions and even remotely execute training runs. To enable ClearML:

- `pip install clearml`
- run `clearml-init` to connect to a ClearML server (**deploy your own open-source server [here](https://github.com/allegroai/clearml-server)**, or use our free hosted server [here](https://cutt.ly/yolov5-notebook-clearml))

You'll get all the great expected features from an experiment manager: live updates, model upload, experiment comparison etc. but ClearML also tracks uncommitted changes and installed packages for example. Thanks to that ClearML Tasks (which is what we call experiments) are also reproducible on different machines! With only 1 extra line, we can schedule a YOLOv5 training task on a queue to be executed by any number of ClearML Agents (workers).

You can use ClearML Data to version your dataset and then pass it to YOLOv5 simply using its unique ID. This will help you keep track of your data without adding extra hassle. Explore the [ClearML Tutorial](https://github.com/ultralytics/yolov5/tree/master/utils/loggers/clearml) for details!

<a href=""https://cutt.ly/yolov5-notebook-clearml"">
<img alt=""ClearML Experiment Management UI"" src=""https://github.com/thepycoder/clearml_screenshots/raw/main/scalars.jpg"" width=""1280""/></a>


#### Local Logging

Training results are automatically logged with [Tensorboard](https://www.tensorflow.org/tensorboard) and [CSV](https://github.com/ultralytics/yolov5/pull/4148) loggers to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc.

This directory contains train and val statistics, mosaics, labels, predictions and augmentated mosaics, as well as metrics and charts including precision-recall (PR) curves and confusion matrices. 

<img alt=""Local logging results"" src=""https://github.com/ultralytics/yolov5/releases/download/v1.0/image-local_logging.jpg"" width=""1280""/>

Results file `results.csv` is updated after each epoch, and then plotted as `results.png` (below) after training completes. You can also plot any `results.csv` file manually:

```python
from utils.plots import plot_results
plot_results('path/to/results.csv')  # plot 'results.csv' as 'results.png'
```

<p align=""center""><img width=""800"" alt=""results.png"" src=""https://github.com/ultralytics/yolov5/releases/download/v1.0/results.png""></p>



## Next Steps

Once your model is trained you can use your best checkpoint `best.pt` to:
* Run [CLI](https://github.com/ultralytics/yolov5#quick-start-examples) or [Python](https://github.com/ultralytics/yolov5/issues/36) inference on new images and videos
* [Validate](https://github.com/ultralytics/yolov5/blob/master/val.py) accuracy on train, val and test splits
* [Export](https://github.com/ultralytics/yolov5/issues/251) to TensorFlow, Keras, ONNX, TFlite, TF.js, CoreML and TensorRT formats
* [Evolve](https://github.com/ultralytics/yolov5/issues/607) hyperparameters to improve performance
* [Improve](https://docs.roboflow.com/adding-data/upload-api?ref=ultralytics) your model by sampling real-world images and adding them to your dataset


## Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Notebooks** with free GPU: <a href=""https://bit.ly/yolov5-paperspace-notebook""><img src=""https://assets.paperspace.io/img/gradient-badge.svg"" alt=""Run on Gradient""></a> <a href=""https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""></a> <a href=""https://www.kaggle.com/ultralytics/yolov5""><img src=""https://kaggle.com/static/images/open-in-kaggle.svg"" alt=""Open In Kaggle""></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/google_cloud_quickstart_tutorial/)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/aws_quickstart_tutorial/)
- **Docker Image**. See [Docker Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/docker_image_quickstart_tutorial/) <a href=""https://hub.docker.com/r/ultralytics/yolov5""><img src=""https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"" alt=""Docker Pulls""></a>


## Status

<a href=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml""><img src=""https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"" alt=""YOLOv5 CI""></a>

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py) and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.
",,"{'url': 'https://api.github.com/repos/ultralytics/yolov5/issues/12/reactions', 'total_count': 75, '+1': 52, '-1': 0, 'laugh': 5, 'hooray': 4, 'confused': 0, 'heart': 5, 'rocket': 4, 'eyes': 5}",https://api.github.com/repos/ultralytics/yolov5/issues/12/timeline,,,,
